"""
ITPF Legal System - DeepSeek API Integration
ÿ™ŸÉÿßŸÖŸÑ ŸÜÿ∏ÿßŸÖ ITPF ÿßŸÑŸÇÿßŸÜŸàŸÜŸä ŸÖÿπ DeepSeek API ŸÑŸÑÿ∞ŸÉÿßÿ° ÿßŸÑŸÖÿ™ŸÇÿØŸÖ
"""

import json
import os
import asyncio
import requests
from typing import Dict, Any, List, Optional

class DeepSeekIntegration:
    """ÿ™ŸÉÿßŸÖŸÑ ŸÖÿ™ŸÇÿØŸÖ ŸÖÿπ DeepSeek API ŸÑÿ™ÿ≠ŸÑŸäŸÑ ŸÇÿßŸÜŸàŸÜŸä ÿ∞ŸÉŸä"""
    
    def __init__(self):
        """ÿ™ŸáŸäÿ¶ÿ© ÿßŸÑŸÜÿ∏ÿßŸÖ ŸÖÿπ ŸÖŸÅÿßÿ™Ÿäÿ≠ API ÿßŸÑŸÖÿ™ÿπÿØÿØÿ© ŸÖÿπ ÿ™ÿ¥ÿÆŸäÿµ ÿ¥ÿßŸÖŸÑ"""
        self.api_keys = []
        
        # ÿßŸÑÿ™ÿ¥ÿÆŸäÿµ ÿßŸÑÿ¥ÿßŸÖŸÑ ŸÑŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿßŸÑÿ®Ÿäÿ¶ÿ©
        print("üîç === ÿ™ÿ¥ÿÆŸäÿµ ŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿßŸÑÿ®Ÿäÿ¶ÿ© ŸÅŸä Vercel ===")
        print(f"üìç ÿ•ÿ¨ŸÖÿßŸÑŸä ŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿßŸÑÿ®Ÿäÿ¶ÿ©: {len(os.environ)}")
        
        # ŸÅÿ≠ÿµ ÿ¨ŸÖŸäÿπ ŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿßŸÑÿ®Ÿäÿ¶ÿ© ÿßŸÑŸÖÿ≠ÿ™ŸÖŸÑÿ©
        potential_env_vars = ['DEEPSEEK_API_KEY', 'DEEPSEEK_API_KEY_1', 'DEEPSEEK_API_KEY_2', 'DEEPSEEK_API_KEY_3']
        
        # ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ os.environ.get() ÿ®ÿØŸÑÿßŸã ŸÖŸÜ os.getenv() ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ™ÿ¥ÿÆŸäÿµ ÿ£ŸÅÿ∂ŸÑ
        for var_name in potential_env_vars:
            value = os.environ.get(var_name)
            if value:
                print(f"‚úÖ {var_name}: {value[:12]}...{value[-6:]} (ÿ∑ŸàŸÑ: {len(value)})")
                # ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿµÿ≠ÿ© ÿßŸÑŸÖŸÅÿ™ÿßÿ≠
                if len(value) > 20 and value.startswith('sk-'):
                    self.api_keys.append(value)
                    print(f"üîë ÿ™ŸÖ ÿ•ÿ∂ÿßŸÅÿ© ŸÖŸÅÿ™ÿßÿ≠ ÿµÿßŸÑÿ≠: {var_name}")
                else:
                    print(f"‚ö†Ô∏è ŸÖŸÅÿ™ÿßÿ≠ ÿ∫Ÿäÿ± ÿµÿßŸÑÿ≠: {var_name} - ŸÑÿß Ÿäÿ®ÿØÿ£ ÿ®ŸÄ sk- ÿ£Ÿà ŸÇÿµŸäÿ± ÿ¨ÿØÿßŸã")
            else:
                print(f"‚ùå {var_name}: ÿ∫Ÿäÿ± ŸÖŸàÿ¨ŸàÿØ")
        
        # ŸÅÿ≠ÿµ ÿ•ÿ∂ÿßŸÅŸä ŸÑÿ£Ÿä ŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿ™ÿ≠ÿ™ŸàŸä ÿπŸÑŸâ "DEEP" ÿ£Ÿà "API"
        print("\nüîç ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿ£ÿÆÿ±Ÿâ ÿ™ÿ≠ÿ™ŸàŸä ÿπŸÑŸâ DEEP ÿ£Ÿà API:")
        relevant_vars = {}
        for key, value in os.environ.items():
            if any(keyword in key.upper() for keyword in ['DEEP', 'API', 'KEY']):
                masked_value = f"{value[:8]}...{value[-4:]}" if len(value) > 12 else value
                relevant_vars[key] = masked_value
                print(f"   {key} = {masked_value}")
        
        # ŸÖÿ≠ÿßŸàŸÑÿ© ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÖŸÅÿßÿ™Ÿäÿ≠ ŸÖÿ≠ÿ™ŸÖŸÑÿ© ÿ£ÿÆÿ±Ÿâ
        alternative_keys = [
            os.environ.get('API_KEY'),
            os.environ.get('OPENAI_API_KEY'),  # ŸÅŸä ÿ≠ÿßŸÑ ŸÉÿßŸÜ ŸáŸÜÿßŸÉ ŸÖŸÅÿ™ÿßÿ≠ ÿ®ÿØŸäŸÑ
        ]
        
        for alt_key in alternative_keys:
            if alt_key and len(alt_key) > 20:
                print(f"üîÑ ŸàŸèÿ¨ÿØ ŸÖŸÅÿ™ÿßÿ≠ ÿ®ÿØŸäŸÑ ŸÖÿ≠ÿ™ŸÖŸÑ: {alt_key[:8]}...{alt_key[-4:]}")
        
        if not self.api_keys:
            print("‚ùå ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ŸÖŸÅÿßÿ™Ÿäÿ≠ API ÿµÿßŸÑÿ≠ÿ©")
            print("üìù ÿßŸÑÿ™ÿ¥ÿÆŸäÿµ ÿßŸÑŸÉÿßŸÖŸÑ:")
            print(f"   - ÿπÿØÿØ ŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿßŸÑÿ®Ÿäÿ¶ÿ©: {len(os.environ)}")
            print(f"   - ŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿ∞ÿßÿ™ ÿµŸÑÿ©: {list(relevant_vars.keys())}")
            print("   - ÿ≥ÿ®ÿ® ŸÖÿ≠ÿ™ŸÖŸÑ: ŸÖŸÅÿßÿ™Ÿäÿ≠ API ÿ∫Ÿäÿ± ŸÖÿ≠ŸÖŸÑÿ© ŸÅŸä ÿ®Ÿäÿ¶ÿ© Vercel")
            
            # ÿ•ÿ∂ÿßŸÅÿ© ŸÖŸÅÿ™ÿßÿ≠ ŸàŸáŸÖŸä ŸÑŸÖŸÜÿπ ÿßŸÑÿ£ÿÆÿ∑ÿßÿ°
            self.api_keys = ['sk-dummy-key-for-testing']
        else:
            print(f"‚úÖ ÿ™ŸÖ ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ {len(self.api_keys)} ŸÖŸÅÿ™ÿßÿ≠ API ÿµÿßŸÑÿ≠")
        
        self.current_key_index = 0
        self.base_url = "https://api.deepseek.com/v1"
        self.client = None
        self._setup_client()
    
    def _setup_client(self):
        """ÿ•ÿπÿØÿßÿØ ÿπŸÖŸäŸÑ API ŸÖÿπ ÿ™ÿ®ÿØŸäŸÑ ÿßŸÑŸÖŸÅÿßÿ™Ÿäÿ≠ ÿßŸÑÿ™ŸÑŸÇÿßÿ¶Ÿä"""
        # Using requests instead of OpenAI client for better compatibility
        self.current_api_key = self.api_keys[self.current_key_index] if self.api_keys else None
    
    def _switch_api_key(self):
        """ÿ™ÿ®ÿØŸäŸÑ ŸÖŸÅÿ™ÿßÿ≠ API ŸÅŸä ÿ≠ÿßŸÑÿ© ÿßŸÑÿÆÿ∑ÿ£"""
        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        self._setup_client()
    
    def analyze_query_complexity(self, question: str) -> str:
        """ÿ™ÿ≠ŸÑŸäŸÑ ÿ™ÿπŸÇŸäÿØ ÿßŸÑÿ≥ÿ§ÿßŸÑ ŸÑÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÜŸÖÿ∑ ÿßŸÑŸÖŸÜÿßÿ≥ÿ®"""
        question_lower = question.lower()
        
        # ŸÖÿ§ÿ¥ÿ±ÿßÿ™ ÿßŸÑÿ™ÿπŸÇŸäÿØ ÿßŸÑÿπÿßŸÑŸä
        complex_indicators = [
            'ŸÇÿßÿ±ŸÜ', 'ÿßÿ±ÿ®ÿ∑', 'ÿ≠ŸÑŸÑ', 'ÿßÿ≥ÿ™ŸÜÿ™ÿ¨', 'ŸÖÿß ÿßŸÑŸÅÿ±ŸÇ', 'ŸÉŸäŸÅ Ÿäÿ§ÿ´ÿ±',
            'ŸÖÿß ÿßŸÑÿπŸÑÿßŸÇÿ©', 'ŸÅŸä ÿ£Ÿä ÿ≠ÿßŸÑÿ©', 'ŸÖÿ™Ÿâ Ÿäÿ¨ÿ®', 'ŸÉŸäŸÅ ŸäŸÖŸÉŸÜ',
            'compare', 'analyze', 'relate', 'difference', 'relationship'
        ]
        
        # ŸÖÿ§ÿ¥ÿ±ÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ®ÿ≥Ÿäÿ∑
        simple_indicators = [
            'ŸÖÿß ŸáŸä', 'ŸÖÿß ŸáŸà', 'ÿßÿ∞ŸÉÿ±', 'ÿπÿ±ŸÅ', 'what is', 'define', 'list'
        ]
        
        # ÿ£ÿ≥ÿ¶ŸÑÿ© ÿπŸÜ ÿßŸÑŸÖŸÑÿßÿ≠ŸÇ ÿ™ÿ≠ÿ™ÿßÿ¨ ÿ™ÿ≠ŸÑŸäŸÑ ŸÖÿ™ÿÆÿµÿµ
        if 'ŸÖŸÑÿ≠ŸÇ' in question_lower or 'appendix' in question_lower:
            return 'deepseek_reasoner'
        
        # ŸÅÿ≠ÿµ ŸÖÿ§ÿ¥ÿ±ÿßÿ™ ÿßŸÑÿ™ÿπŸÇŸäÿØ
        for indicator in complex_indicators:
            if indicator in question_lower:
                return 'deepseek_reasoner'
        
        for indicator in simple_indicators:
            if indicator in question_lower:
                return 'local_fast'
                
        # ÿßŸÅÿ™ÿ±ÿßÿ∂Ÿä ŸÑŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑŸÖÿ™Ÿàÿ≥ÿ∑ÿ©
        return 'deepseek_chat'
    
    def create_legal_prompt(self, question: str, context: List[Dict[str, Any]], mode: str, language: str = 'arabic') -> str:
        """ÿ•ŸÜÿ¥ÿßÿ° prompt ŸÖÿ™ÿÆÿµÿµ ŸÑŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä"""
        
        if mode == 'deepseek_reasoner':
            if language == 'english':
                system_prompt = """You are a legal expert specialized in the International Tent Pegging Federation (ITPF) rules.

Your task: Deep logical and graduated analysis of complex legal questions.

Required analysis methodology:
1. Understand the question and identify required legal elements
2. Review relevant legal texts
3. Analyze connections and relationships between different articles
4. Extract conclusions based on legal evidence
5. Provide comprehensive answer with specific citations

Important instructions:
- Use sequential and logical reasoning
- Connect between articles and appendices when needed
- Mention specific article and appendix numbers
- Provide practical examples when possible
- Answer ONLY in English using English legal texts"""
            else:
                system_prompt = """ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÇÿßŸÜŸàŸÜŸä ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ŸÇŸàÿßÿπÿØ ÿßŸÑÿßÿ™ÿ≠ÿßÿØ ÿßŸÑÿØŸàŸÑŸä ŸÑÿßŸÑÿ™ŸÇÿßÿ∑ ÿßŸÑÿ£Ÿàÿ™ÿßÿØ (ITPF).

ŸÖŸáŸÖÿ™ŸÉ: ÿ™ÿ≠ŸÑŸäŸÑ ŸÖŸÜÿ∑ŸÇŸä ÿπŸÖŸäŸÇ ŸàŸÖÿ™ÿØÿ±ÿ¨ ŸÑŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖÿπŸÇÿØÿ©.

ŸÖŸÜŸáÿ¨Ÿäÿ© ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©:
1. ŸÅŸáŸÖ ÿßŸÑÿ≥ÿ§ÿßŸÑ Ÿàÿ™ÿ≠ÿØŸäÿØ ÿßŸÑÿπŸÜÿßÿµÿ± ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©
2. ŸÖÿ±ÿßÿ¨ÿπÿ© ÿßŸÑŸÜÿµŸàÿµ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿ∞ÿßÿ™ ÿßŸÑÿµŸÑÿ©
3. ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ±Ÿàÿßÿ®ÿ∑ ŸàÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ÿ®ŸäŸÜ ÿßŸÑŸÖŸàÿßÿØ ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ©
4. ÿßÿ≥ÿ™ÿÆŸÑÿßÿµ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑÿ£ÿØŸÑÿ© ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ©
5. ÿ™ŸÇÿØŸäŸÖ ÿ•ÿ¨ÿßÿ®ÿ© ÿ¥ÿßŸÖŸÑÿ© ŸÖÿπ ÿßŸÑÿßÿ≥ÿ™ÿ¥ŸáÿßÿØ ÿßŸÑŸÖÿ≠ÿØÿØ

ÿ™ÿπŸÑŸäŸÖÿßÿ™ ŸÖŸáŸÖÿ©:
- ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿ™ŸÅŸÉŸäÿ± ÿßŸÑŸÖÿ™ÿ≥ŸÑÿ≥ŸÑ ŸàÿßŸÑŸÖŸÜÿ∑ŸÇŸä
- ÿßÿ±ÿ®ÿ∑ ÿ®ŸäŸÜ ÿßŸÑŸÖŸàÿßÿØ ŸàÿßŸÑŸÖŸÑÿßÿ≠ŸÇ ÿπŸÜÿØ ÿßŸÑÿ≠ÿßÿ¨ÿ©
- ÿßÿ∞ŸÉÿ± ÿ£ÿ±ŸÇÿßŸÖ ÿßŸÑŸÖŸàÿßÿØ ŸàÿßŸÑŸÖŸÑÿßÿ≠ŸÇ ÿßŸÑŸÖÿ≠ÿØÿØÿ©
- ŸÇÿØŸÖ ÿ£ŸÖÿ´ŸÑÿ© ÿπŸÖŸÑŸäÿ© ÿπŸÜÿØ ÿßŸÑÿ•ŸÖŸÉÿßŸÜ"""

        else:  # deepseek_chat
            if language == 'english':
                system_prompt = """You are a legal assistant specialized in the International Tent Pegging Federation (ITPF) rules.

Your task: Provide clear and accurate answers to legal inquiries.

Your methodology:
- Direct and helpful responses
- Citation of appropriate legal articles
- Answer ONLY in English using English legal texts
- Strict separation from Arabic content"""
            else:
                system_prompt = """ÿ£ŸÜÿ™ ŸÖÿ≥ÿßÿπÿØ ŸÇÿßŸÜŸàŸÜŸä ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ŸÇŸàÿßÿπÿØ ÿßŸÑÿßÿ™ÿ≠ÿßÿØ ÿßŸÑÿØŸàŸÑŸä ŸÑÿßŸÑÿ™ŸÇÿßÿ∑ ÿßŸÑÿ£Ÿàÿ™ÿßÿØ (ITPF).

ŸÖŸáŸÖÿ™ŸÉ: ÿ™ŸÇÿØŸäŸÖ ÿ•ÿ¨ÿßÿ®ÿßÿ™ Ÿàÿßÿ∂ÿ≠ÿ© ŸàÿØŸÇŸäŸÇÿ© ŸÑŸÑÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±ÿßÿ™ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ©.

ŸÖŸÜŸáÿ¨Ÿäÿ™ŸÉ:
- ÿ•ÿ¨ÿßÿ®ÿ© ŸÖÿ®ÿßÿ¥ÿ±ÿ© ŸàŸÖŸÅŸäÿØÿ©
- ÿßÿ≥ÿ™ÿ¥ŸáÿßÿØ ÿ®ÿßŸÑŸÖŸàÿßÿØ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖŸÜÿßÿ≥ÿ®ÿ©
- ŸÑÿ∫ÿ© Ÿàÿßÿ∂ÿ≠ÿ© ŸàŸÖŸÅŸáŸàŸÖÿ©
- ÿ™ÿ±ŸÉŸäÿ≤ ÿπŸÑŸâ ÿßŸÑÿ¨ŸàÿßŸÜÿ® ÿßŸÑÿπŸÖŸÑŸäÿ©"""

        # ÿ™ÿ≠ÿ∂Ÿäÿ± ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÇÿßŸÜŸàŸÜŸä
        context_text = ""
        if context:
            context_text = "\n\nÿßŸÑŸÖÿ±ÿßÿ¨ÿπ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖÿ™ÿßÿ≠ÿ©:\n"
            for i, ref in enumerate(context[:5], 1):
                context_text += f"{i}. ÿßŸÑŸÖÿßÿØÿ© {ref.get('article_number', 'ÿ∫Ÿäÿ± ŸÖÿ≠ÿØÿØ')}: {ref.get('title', '')}\n"
                context_text += f"   ÿßŸÑŸÜÿµ: {ref.get('content', '')[:300]}...\n\n"
        
        user_prompt = f"""ÿßŸÑÿ≥ÿ§ÿßŸÑ: {question}

{context_text}

Ÿäÿ±ÿ¨Ÿâ ÿ™ŸÇÿØŸäŸÖ ÿ•ÿ¨ÿßÿ®ÿ© ÿ¥ÿßŸÖŸÑÿ© ŸàÿØŸÇŸäŸÇÿ© ŸÖÿπ ÿßŸÑÿßÿ≥ÿ™ŸÜÿßÿØ ŸÑŸÑŸÖŸàÿßÿØ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÖÿ≠ÿØÿØÿ©."""

        return system_prompt, user_prompt
    
    async def get_deepseek_response(self, question: str, context: List[Dict[str, Any]], mode: str) -> Dict[str, Any]:
        """ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ© ŸÖŸÜ DeepSeek API"""
        try:
            system_prompt, user_prompt = self.create_legal_prompt(question, context, mode)
            
            model = "deepseek-reasoner" if mode == "deepseek_reasoner" else "deepseek-chat"
            
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=4000 if mode == "deepseek_chat" else 8000,
                temperature=0.1,
                stream=False
            )
            
            return {
                "success": True,
                "response": response.choices[0].message.content,
                "model_used": model,
                "tokens_used": response.usage.total_tokens if hasattr(response, 'usage') else 0
            }
            
        except Exception as e:
            # ŸÖÿ≠ÿßŸàŸÑÿ© ÿ™ÿ®ÿØŸäŸÑ ŸÖŸÅÿ™ÿßÿ≠ API
            self._switch_api_key()
            
            # ŸÖÿ≠ÿßŸàŸÑÿ© ÿ´ÿßŸÜŸäÿ©
            try:
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_tokens=4000 if mode == "deepseek_chat" else 8000,
                    temperature=0.1,
                    stream=False
                )
                
                return {
                    "success": True,
                    "response": response.choices[0].message.content,
                    "model_used": model,
                    "tokens_used": response.usage.total_tokens if hasattr(response, 'usage') else 0
                }
                
            except Exception as e2:
                return {
                    "success": False,
                    "error": f"ÿÆÿ∑ÿ£ ŸÅŸä API: {str(e2)}",
                    "fallback_needed": True
                }
    
    def enhance_arabic_text(self, text: str) -> str:
        """ÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑŸÜÿµ ÿßŸÑÿπÿ±ÿ®Ÿä ŸÑŸÑŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ£ŸÅÿ∂ŸÑ"""
        # ÿ™Ÿàÿ≠ŸäÿØ ÿßŸÑÿ≠ÿ±ŸàŸÅ ÿßŸÑÿπÿ±ÿ®Ÿäÿ©
        replacements = {
            'ÿ£': 'ÿß', 'ÿ•': 'ÿß', 'ÿ¢': 'ÿß',
            'ÿ©': 'Ÿá',
            'Ÿâ': 'Ÿä'
        }
        
        enhanced_text = text
        for old, new in replacements.items():
            enhanced_text = enhanced_text.replace(old, new)
        
        return enhanced_text
    
    def create_enhanced_summary(self, question: str, deepseek_response: str, local_results: List[Dict[str, Any]]) -> str:
        """ÿ•ŸÜÿ¥ÿßÿ° ŸÖŸÑÿÆÿµ ŸÖÿ≠ÿ≥ŸÜ Ÿäÿ¨ŸÖÿπ ÿ®ŸäŸÜ DeepSeek ŸàÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑŸÖÿ≠ŸÑŸäÿ©"""
        
        # ÿßÿ≥ÿ™ÿÆŸÑÿßÿµ ÿßŸÑŸÖÿ±ÿßÿ¨ÿπ ŸÖŸÜ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑŸÖÿ≠ŸÑŸäÿ©
        references = []
        for result in local_results[:3]:
            ref_num = result.get('article_number', '')
            ref_title = result.get('title', '')
            references.append(f"‚Ä¢ ÿßŸÑŸÖÿßÿØÿ© {ref_num}: {ref_title}")
        
        enhanced_summary = f"""üß† **ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ∞ŸÉŸä ÿßŸÑŸÖÿ™ŸÇÿØŸÖ:**

{deepseek_response}

**ÿßŸÑŸÖÿ±ÿßÿ¨ÿπ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©:**
{chr(10).join(references)}

**ÿ™ÿ£ŸÉŸäÿØ ÿßŸÑÿØŸÇÿ©:**
Ÿáÿ∞ÿß ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ŸÖÿ®ŸÜŸä ÿπŸÑŸâ ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑŸÇÿßŸÜŸàŸÜŸäÿ© ÿßŸÑŸÉÿßŸÖŸÑÿ© ŸÑŸÑÿßÿ™ÿ≠ÿßÿØ ÿßŸÑÿØŸàŸÑŸä ŸÑÿßŸÑÿ™ŸÇÿßÿ∑ ÿßŸÑÿ£Ÿàÿ™ÿßÿØÿå Ÿàÿ™ŸÖ ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿµÿ≠ÿ© ÿßŸÑŸÜÿµŸàÿµ ŸàÿßŸÑŸÖÿ±ÿßÿ¨ÿπ."""

        return enhanced_summary

    def generate_intelligent_legal_response(self, question: str, legal_context: List[Dict[str, Any]], language: str = 'arabic') -> str:
        """Generate intelligent legal response using DeepSeek API with real integration"""
        try:
            # Analyze question complexity to choose appropriate model
            mode = self.analyze_query_complexity(question)
            print(f"üîç Question complexity analysis: {mode}")
            
            # Get DeepSeek response with retry logic
            result = asyncio.run(self._get_deepseek_response_with_retry(question, legal_context, mode, language))
            
            if result.get("success"):
                print(f"‚úÖ DeepSeek API call successful, tokens used: {result.get('tokens_used', 'unknown')}")
                return result["response"]
            else:
                error_msg = result.get('error', 'Unknown error')
                print(f"‚ùå DeepSeek API call failed: {error_msg}")
                return f"AI analysis unavailable: {error_msg}"
                
        except Exception as e:
            print(f"‚ùå DeepSeek integration error: {str(e)}")
            return f"AI system error: {str(e)}"

    async def _get_deepseek_response_with_retry(self, question: str, context: List[Dict[str, Any]], mode: str, language: str = 'arabic') -> Dict[str, Any]:
        """Enhanced DeepSeek API call with retry logic using requests"""
        max_retries = len(self.api_keys) if self.api_keys else 1
        
        for attempt in range(max_retries):
            try:
                system_prompt, user_prompt = self.create_legal_prompt(question, context, mode, language)
                
                model = "deepseek-reasoner" if mode == "deepseek_reasoner" else "deepseek-chat"
                print(f"ü§ñ Calling DeepSeek API with model: {model} (attempt {attempt + 1}/{max_retries})")
                
                if not self.current_api_key:
                    raise Exception("No API key available")
                
                # Use requests for direct API call
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.current_api_key}"
                }
                
                payload = {
                    "model": model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "max_tokens": 4000 if mode == "deepseek_chat" else 8000,
                    "temperature": 0.1,
                    "stream": False
                }
                
                print(f"üîë Using API key: {self.current_api_key[:8]}...{self.current_api_key[-4:]}")
                
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=60
                )
                
                print(f"üì° HTTP Status: {response.status_code}")
                
                if response.status_code == 200:
                    result = response.json()
                    message_content = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                    
                    if message_content:
                        print("‚úÖ DeepSeek API call successful")
                        return {
                            "success": True,
                            "response": message_content,
                            "model_used": model,
                            "tokens_used": result.get('usage', {}).get('total_tokens', 0)
                        }
                    else:
                        raise Exception("Empty response from DeepSeek")
                        
                elif response.status_code == 401:
                    error_msg = f"Authentication failed with key {self.current_api_key[:8]}..."
                    print(f"‚ùå {error_msg}")
                    raise Exception(error_msg)
                    
                elif response.status_code == 402:
                    raise Exception("Insufficient balance - need to add funds")
                    
                else:
                    error_data = response.json() if response.content else {}
                    raise Exception(f"HTTP {response.status_code}: {error_data}")
                
            except Exception as e:
                print(f"‚ö†Ô∏è API call attempt {attempt + 1} failed: {str(e)}")
                
                # Try next API key if available
                if attempt < max_retries - 1 and self.api_keys:
                    self._switch_api_key()
                    print(f"üîÑ Switching to API key {self.current_key_index + 1}")
                else:
                    # All attempts failed
                    return {
                        "success": False,
                        "error": f"All API attempts failed. Last error: {str(e)}",
                        "fallback_needed": True
                    }

# ÿ•ŸÜÿ¥ÿßÿ° ŸÖÿ´ŸäŸÑ ÿπÿßŸÖ ŸÑŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ
deepseek_integration = DeepSeekIntegration()