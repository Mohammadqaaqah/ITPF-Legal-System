"""
ITPF Legal System - DeepSeek API Integration
ØªÙƒØ§Ù…Ù„ Ù†Ø¸Ø§Ù… ITPF Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…Ø¹ DeepSeek API Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
"""

import json
import os
import asyncio
from typing import Dict, Any, List, Optional
from openai import OpenAI

class DeepSeekIntegration:
    """ØªÙƒØ§Ù…Ù„ Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ DeepSeek API Ù„ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø°ÙƒÙŠ"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø¹ Ù…ÙØ§ØªÙŠØ­ API Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©"""
        self.api_keys = [
            os.getenv('DEEPSEEK_API_KEY_1'),
            os.getenv('DEEPSEEK_API_KEY_2'), 
            os.getenv('DEEPSEEK_API_KEY_3')
        ]
        self.current_key_index = 0
        self.base_url = "https://api.deepseek.com"
        self.client = None
        self._setup_client()
    
    def _setup_client(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø¹Ù…ÙŠÙ„ API Ù…Ø¹ ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
        if self.api_keys[self.current_key_index]:
            self.client = OpenAI(
                api_key=self.api_keys[self.current_key_index],
                base_url=self.base_url
            )
    
    def _switch_api_key(self):
        """ØªØ¨Ø¯ÙŠÙ„ Ù…ÙØªØ§Ø­ API ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£"""
        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        self._setup_client()
    
    def analyze_query_complexity(self, question: str) -> str:
        """ØªØ­Ù„ÙŠÙ„ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ù…Ù†Ø§Ø³Ø¨"""
        question_lower = question.lower()
        
        # Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø¹Ø§Ù„ÙŠ
        complex_indicators = [
            'Ù‚Ø§Ø±Ù†', 'Ø§Ø±Ø¨Ø·', 'Ø­Ù„Ù„', 'Ø§Ø³ØªÙ†ØªØ¬', 'Ù…Ø§ Ø§Ù„ÙØ±Ù‚', 'ÙƒÙŠÙ ÙŠØ¤Ø«Ø±',
            'Ù…Ø§ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø©', 'ÙÙŠ Ø£ÙŠ Ø­Ø§Ù„Ø©', 'Ù…ØªÙ‰ ÙŠØ¬Ø¨', 'ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†',
            'compare', 'analyze', 'relate', 'difference', 'relationship'
        ]
        
        # Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¨Ø³ÙŠØ·
        simple_indicators = [
            'Ù…Ø§ Ù‡ÙŠ', 'Ù…Ø§ Ù‡Ùˆ', 'Ø§Ø°ÙƒØ±', 'Ø¹Ø±Ù', 'what is', 'define', 'list'
        ]
        
        # Ø£Ø³Ø¦Ù„Ø© Ø¹Ù† Ø§Ù„Ù…Ù„Ø§Ø­Ù‚ ØªØ­ØªØ§Ø¬ ØªØ­Ù„ÙŠÙ„ Ù…ØªØ®ØµØµ
        if 'Ù…Ù„Ø­Ù‚' in question_lower or 'appendix' in question_lower:
            return 'deepseek_reasoner'
        
        # ÙØ­Øµ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        for indicator in complex_indicators:
            if indicator in question_lower:
                return 'deepseek_reasoner'
        
        for indicator in simple_indicators:
            if indicator in question_lower:
                return 'local_fast'
                
        # Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©
        return 'deepseek_chat'
    
    def create_legal_prompt(self, question: str, context: List[Dict[str, Any]], mode: str, language: str = 'arabic') -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ prompt Ù…ØªØ®ØµØµ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ"""
        
        if mode == 'deepseek_reasoner':
            if language == 'english':
                system_prompt = """You are a legal expert specialized in the International Tent Pegging Federation (ITPF) rules.

Your task: Deep logical and graduated analysis of complex legal questions.

Required analysis methodology:
1. Understand the question and identify required legal elements
2. Review relevant legal texts
3. Analyze connections and relationships between different articles
4. Extract conclusions based on legal evidence
5. Provide comprehensive answer with specific citations

Important instructions:
- Use sequential and logical reasoning
- Connect between articles and appendices when needed
- Mention specific article and appendix numbers
- Provide practical examples when possible
- Answer ONLY in English using English legal texts"""
            else:
                system_prompt = """Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ù„Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø£ÙˆØªØ§Ø¯ (ITPF).

Ù…Ù‡Ù…ØªÙƒ: ØªØ­Ù„ÙŠÙ„ Ù…Ù†Ø·Ù‚ÙŠ Ø¹Ù…ÙŠÙ‚ ÙˆÙ…ØªØ¯Ø±Ø¬ Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©.

Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:
1. ÙÙ‡Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
2. Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
4. Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
5. ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø© Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯

ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø©:
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„ ÙˆØ§Ù„Ù…Ù†Ø·Ù‚ÙŠ
- Ø§Ø±Ø¨Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ø¯ ÙˆØ§Ù„Ù…Ù„Ø§Ø­Ù‚ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
- Ø§Ø°ÙƒØ± Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯ ÙˆØ§Ù„Ù…Ù„Ø§Ø­Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
- Ù‚Ø¯Ù… Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù…ÙƒØ§Ù†"""

        else:  # deepseek_chat
            if language == 'english':
                system_prompt = """You are a legal assistant specialized in the International Tent Pegging Federation (ITPF) rules.

Your task: Provide clear and accurate answers to legal inquiries.

Your methodology:
- Direct and helpful responses
- Citation of appropriate legal articles
- Answer ONLY in English using English legal texts
- Strict separation from Arabic content"""
            else:
                system_prompt = """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ù„Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø£ÙˆØªØ§Ø¯ (ITPF).

Ù…Ù‡Ù…ØªÙƒ: ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª ÙˆØ§Ø¶Ø­Ø© ÙˆØ¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©.

Ù…Ù†Ù‡Ø¬ÙŠØªÙƒ:
- Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆÙ…ÙÙŠØ¯Ø©
- Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¨Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
- Ù„ØºØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙÙ‡ÙˆÙ…Ø©
- ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©"""

        # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ
        context_text = ""
        if context:
            context_text = "\n\nØ§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©:\n"
            for i, ref in enumerate(context[:5], 1):
                context_text += f"{i}. Ø§Ù„Ù…Ø§Ø¯Ø© {ref.get('article_number', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}: {ref.get('title', '')}\n"
                context_text += f"   Ø§Ù„Ù†Øµ: {ref.get('content', '')[:300]}...\n\n"
        
        user_prompt = f"""Ø§Ù„Ø³Ø¤Ø§Ù„: {question}

{context_text}

ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø© ÙˆØ¯Ù‚ÙŠÙ‚Ø© Ù…Ø¹ Ø§Ù„Ø§Ø³ØªÙ†Ø§Ø¯ Ù„Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©."""

        return system_prompt, user_prompt
    
    async def get_deepseek_response(self, question: str, context: List[Dict[str, Any]], mode: str) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† DeepSeek API"""
        try:
            system_prompt, user_prompt = self.create_legal_prompt(question, context, mode)
            
            model = "deepseek-reasoner" if mode == "deepseek_reasoner" else "deepseek-chat"
            
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=4000 if mode == "deepseek_chat" else 8000,
                temperature=0.1,
                stream=False
            )
            
            return {
                "success": True,
                "response": response.choices[0].message.content,
                "model_used": model,
                "tokens_used": response.usage.total_tokens if hasattr(response, 'usage') else 0
            }
            
        except Exception as e:
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ¨Ø¯ÙŠÙ„ Ù…ÙØªØ§Ø­ API
            self._switch_api_key()
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø«Ø§Ù†ÙŠØ©
            try:
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_tokens=4000 if mode == "deepseek_chat" else 8000,
                    temperature=0.1,
                    stream=False
                )
                
                return {
                    "success": True,
                    "response": response.choices[0].message.content,
                    "model_used": model,
                    "tokens_used": response.usage.total_tokens if hasattr(response, 'usage') else 0
                }
                
            except Exception as e2:
                return {
                    "success": False,
                    "error": f"Ø®Ø·Ø£ ÙÙŠ API: {str(e2)}",
                    "fallback_needed": True
                }
    
    def enhance_arabic_text(self, text: str) -> str:
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙØ¶Ù„"""
        # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        replacements = {
            'Ø£': 'Ø§', 'Ø¥': 'Ø§', 'Ø¢': 'Ø§',
            'Ø©': 'Ù‡',
            'Ù‰': 'ÙŠ'
        }
        
        enhanced_text = text
        for old, new in replacements.items():
            enhanced_text = enhanced_text.replace(old, new)
        
        return enhanced_text
    
    def create_enhanced_summary(self, question: str, deepseek_response: str, local_results: List[Dict[str, Any]]) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ù…Ø­Ø³Ù† ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† DeepSeek ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø­Ù„ÙŠØ©"""
        
        # Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø­Ù„ÙŠØ©
        references = []
        for result in local_results[:3]:
            ref_num = result.get('article_number', '')
            ref_title = result.get('title', '')
            references.append(f"â€¢ Ø§Ù„Ù…Ø§Ø¯Ø© {ref_num}: {ref_title}")
        
        enhanced_summary = f"""ðŸ§  **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…:**

{deepseek_response}

**Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:**
{chr(10).join(references)}

**ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø¯Ù‚Ø©:**
Ù‡Ø°Ø§ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ù„Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø£ÙˆØªØ§Ø¯ØŒ ÙˆØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹."""

        return enhanced_summary

    def generate_intelligent_legal_response(self, question: str, legal_context: List[Dict[str, Any]], language: str = 'arabic') -> str:
        """Generate intelligent legal response using DeepSeek - SAFE INTEGRATION"""
        try:
            # Analyze question complexity
            mode = self.analyze_query_complexity(question)
            
            # Get DeepSeek response with language support
            result = asyncio.run(self.get_deepseek_response(question, legal_context, mode, language))
            
            if result.get("success"):
                return result["response"]
            else:
                # Fallback message
                return f"AI analysis unavailable: {result.get('error', 'Unknown error')}"
                
        except Exception as e:
            return f"AI system error: {str(e)}"

    async def get_deepseek_response(self, question: str, context: List[Dict[str, Any]], mode: str, language: str = 'arabic') -> Dict[str, Any]:
        """Enhanced version with language parameter"""
        try:
            system_prompt, user_prompt = self.create_legal_prompt(question, context, mode, language)
            
            model = "deepseek-reasoner" if mode == "deepseek_reasoner" else "deepseek-chat"
            
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=4000 if mode == "deepseek_chat" else 8000,
                temperature=0.1,
                stream=False
            )
            
            return {
                "success": True,
                "response": response.choices[0].message.content,
                "model_used": model,
                "tokens_used": response.usage.total_tokens if hasattr(response, 'usage') else 0
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "fallback_needed": True
            }

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø¹Ø§Ù… Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
deepseek_integration = DeepSeekIntegration()