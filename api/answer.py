"""
ITPF Legal Answer System - Advanced Expert Version
ูุธุงู ุฎุจูุฑ ูุงูููู ูุชูุฏู ูุน ููู ุนููู ูููุงุนุฏ ุงูุชูุงุท ุงูุฃูุชุงุฏ ุงููุงููุฉ
"""

import json
import os
import re
from typing import Dict, Any, List, Tuple, Set
from http.server import BaseHTTPRequestHandler
from collections import defaultdict
from dataclasses import dataclass

# ุงุณุชูุฑุงุฏ ุงููุธุงู ุงููุชูุฏู ุงูุฌุฏูุฏ (ุฅุถุงูุฉ ุขููุฉ)
try:
    from .advanced_legal_reasoning import AdvancedLegalReasoning
    ADVANCED_REASONING_AVAILABLE = True
    print("๐ง Advanced Legal Reasoning System loaded successfully")
except ImportError:
    try:
        # ููุชุทููุฑ ุงููุญูู
        import sys
        import os
        sys.path.append(os.path.dirname(__file__))
        from advanced_legal_reasoning import AdvancedLegalReasoning
        ADVANCED_REASONING_AVAILABLE = True
        print("๐ง Advanced Legal Reasoning System loaded successfully (local)")
    except ImportError:
        ADVANCED_REASONING_AVAILABLE = False
        print("โ๏ธ Advanced reasoning not available, using standard system")


def load_legal_data():
    """Load complete legal data - enhanced and comprehensive"""
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        
        # Load Arabic data with enhanced error handling
        arabic_data = {"articles": [], "appendices": []}
        for i in range(1, 4):
            arabic_file = os.path.join(script_dir, f'arabic_data_part{i}.json')
            try:
                with open(arabic_file, 'r', encoding='utf-8') as f:
                    part_data = json.load(f)
                    if i == 1:
                        arabic_data["appendices"] = part_data.get("appendices", [])
                    arabic_data["articles"].extend(part_data.get("articles", []))
            except Exception as e:
                print(f"Error loading Arabic part {i}: {str(e)}")
        
        # Load English data with enhanced error handling
        english_data = {"articles": [], "appendices": []}
        for i in range(1, 4):
            english_file = os.path.join(script_dir, f'english_data_part{i}.json')
            try:
                with open(english_file, 'r', encoding='utf-8') as f:
                    part_data = json.load(f)
                    if i == 1:
                        english_data["appendices"] = part_data.get("appendices", [])
                    if 'chapters' in part_data:
                        for chapter in part_data['chapters']:
                            english_data["articles"].extend(chapter.get('articles', []))
                    else:
                        english_data["articles"].extend(part_data.get("articles", []))
            except Exception as e:
                print(f"Error loading English part {i}: {str(e)}")
        
        print(f"Expert System Data Loaded - Arabic: {len(arabic_data['articles'])} articles, {len(arabic_data['appendices'])} appendices")
        print(f"Expert System Data Loaded - English: {len(english_data['articles'])} articles, {len(english_data['appendices'])} appendices")
        
        # ุชููุฆุฉ ุงููุธุงู ุงููุชูุฏู (ุฅุถุงูุฉ ุขููุฉ)
        if ADVANCED_REASONING_AVAILABLE:
            try:
                global advanced_reasoning_system
                advanced_reasoning_system = AdvancedLegalReasoning()
                advanced_reasoning_system.build_knowledge_graph(arabic_data)
                print("๐ง Advanced reasoning system initialized with knowledge graph")
            except Exception as e:
                print(f"โ๏ธ Could not initialize advanced reasoning: {str(e)}")
        
        return arabic_data, english_data
    except Exception as e:
        print(f"Critical error loading legal data: {str(e)}")
        return {}, {}


@dataclass
class LegalConcept:
    """ุชูุซูู ุงูููุงููู ุงููุงููููุฉ"""
    arabic_terms: List[str]
    english_terms: List[str]
    related_concepts: List[str]
    legal_significance: str

class ExpertLegalAnalyzer:
    """ูุญูู ูุงูููู ุฎุจูุฑ ูุชูุฏู"""
    
    def __init__(self):
        self.legal_concepts = self._build_legal_ontology()
        self.article_relationships = {}
        self.regulation_hierarchy = {}
        
    def _build_legal_ontology(self) -> Dict[str, LegalConcept]:
        """ุจูุงุก ุฎุฑูุทุฉ ุงูููุงููู ุงููุงููููุฉ ุงููุชุฎุตุตุฉ"""
        return {
            'equipment': LegalConcept(
                arabic_terms=['ุฑูุญ', 'ุณูู', 'ูุนุฏุงุช', 'ุฃุฏูุงุช', 'ุฃุณูุญุฉ'],
                english_terms=['lance', 'sword', 'equipment', 'weapons', 'gear'],
                related_concepts=['specifications', 'measurements', 'materials'],
                legal_significance='ุชุฌููุฒุงุช ุงููุณุงุจูุฉ ุงูุฃุณุงุณูุฉ'
            ),
            'competition_format': LegalConcept(
                arabic_terms=['ูุณุงุจูุฉ', 'ุจุทููุฉ', 'ุดูุท', 'ุฌููุฉ', 'ููุงูุณุฉ'],
                english_terms=['competition', 'tournament', 'round', 'match'],
                related_concepts=['rules', 'participants', 'scoring'],
                legal_significance='ุชูุธูู ุงููุณุงุจูุงุช ูุงูุจุทููุงุช'
            ),
            'field_specs': LegalConcept(
                arabic_terms=['ููุฏุงู', 'ุณุงุญุฉ', 'ูุณุงูุฉ', 'ููุงุณุงุช', 'ุฃุจุนุงุฏ'],
                english_terms=['field', 'arena', 'distance', 'measurements'],
                related_concepts=['layout', 'markings', 'safety'],
                legal_significance='ููุงุตูุงุช ุงูููุฏุงู ูุงูุณุงุญุฉ'
            ),
            'timing_scoring': LegalConcept(
                arabic_terms=['ููุช', 'ุฒูู', 'ููุงุท', 'ุชุณุฌูู', 'ุญุณุงุจ'],
                english_terms=['time', 'timing', 'points', 'scoring'],
                related_concepts=['measurement', 'calculation', 'ranking'],
                legal_significance='ุฃูุธูุฉ ุงูุชูููุช ูุงูุชุณุฌูู'
            )
        }
    
    def analyze_question_intent(self, question: str) -> Dict[str, Any]:
        """ุชุญููู ููุฉ ุงูุณุคุงู ูุชุตูููู"""
        question_lower = question.lower()
        
        intent_patterns = {
            'definition': r'(ูุง ูู|ูุง ูู|ุชุนุฑูู|ูุนูู|what is|define)',
            'procedure': r'(ููู|ุจุฃู ุทุฑููุฉ|ุฎุทูุงุช|how|procedure)',
            'regulation': r'(ูุงููู|ูุงุนุฏุฉ|ุดุฑุท|ูุฌุจ|ูุง ูุฌูุฒ|rule|must|shall)',
            'specification': r'(ููุงุตูุงุช|ููุงุณ|ุญุฌู|ูุฒู|ุทูู|ุนุฑุถ|specification|size|measurement)',
            'timing': r'(ููุช|ุฒูู|ูุฏุฉ|ุซุงููุฉ|ุฏูููุฉ|time|duration|second)',
            'appendix_specific': r'(ููุญู|appendix)\s*(\d+|ุชุณุนุฉ|ุนุดุฑุฉ|nine|ten)'
        }
        
        detected_intents = []
        for intent, pattern in intent_patterns.items():
            if re.search(pattern, question_lower, re.IGNORECASE):
                detected_intents.append(intent)
        
        # ุชุญุฏูุฏ ููุน ุงูููุญู ุงููุทููุจ
        appendix_match = re.search(r'(ููุญู|appendix)\s*(\d+|ุชุณุนุฉ|ุนุดุฑุฉ|nine|ten)', question_lower)
        target_appendix = None
        if appendix_match:
            appendix_num = appendix_match.group(2)
            if appendix_num in ['9', 'ุชุณุนุฉ', 'nine']:
                target_appendix = '9'
            elif appendix_num in ['10', 'ุนุดุฑุฉ', 'ten']:
                target_appendix = '10'
            else:
                target_appendix = appendix_num
        
        return {
            'primary_intent': detected_intents[0] if detected_intents else 'general',
            'all_intents': detected_intents,
            'target_appendix': target_appendix,
            'question_complexity': len(detected_intents) + (2 if target_appendix else 0)
        }
    
    def extract_semantic_terms(self, question: str) -> List[str]:
        """ุงุณุชุฎุฑุงุฌ ุงููุตุทูุญุงุช ุงูุฏูุงููุฉ ูู ุงูุณุคุงู"""
        terms = set()
        question_lower = question.lower()
        
        # ุงุณุชุฎุฑุงุฌ ุงููุตุทูุญุงุช ุงููุจุงุดุฑุฉ
        words = re.findall(r'\b\w+\b', question_lower)
        terms.update(words)
        
        # ุฅุถุงูุฉ ุงููุฑุงุฏูุงุช ูุงูููุงููู ุฐุงุช ุงูุตูุฉ
        for concept in self.legal_concepts.values():
            for term in concept.arabic_terms + concept.english_terms:
                if term.lower() in question_lower:
                    terms.update([t.lower() for t in concept.arabic_terms + concept.english_terms])
                    terms.update([t.lower() for t in concept.related_concepts])
        
        # ูุนุงูุฌุฉ ุงูุฃุฑูุงู ูุงูุฃุฑูุงู ุงูุนุฑุจูุฉ
        number_mappings = {
            '9': ['9', 'ุชุณุนุฉ', 'nine'],
            '10': ['10', 'ุนุดุฑุฉ', 'ten'],
            'ุชุณุนุฉ': ['9', 'ุชุณุนุฉ', 'nine'],
            'ุนุดุฑุฉ': ['10', 'ุนุดุฑุฉ', 'ten']
        }
        
        for word in words:
            if word in number_mappings:
                terms.update(number_mappings[word])
        
        return list(terms)
    
    def advanced_search(self, question: str, data: dict, language: str) -> List[Dict[str, Any]]:
        """ุจุญุซ ูุชูุฏู ูุน ููู ุนููู ููุณูุงู"""
        intent_analysis = self.analyze_question_intent(question)
        semantic_terms = self.extract_semantic_terms(question)
        
        results = []
        
        # ุงูุจุญุซ ูู ุงูููุงูุงุช
        for article in data.get('articles', []):
            score = self._calculate_advanced_relevance(
                article, semantic_terms, intent_analysis, 'article'
            )
            
            if score > 0:
                results.append({
                    'article_number': article.get('article_number', 0),
                    'title': article.get('title', ''),
                    'content': article.get('content', ''),
                    'relevance_score': score,
                    'content_type': 'article',
                    'matches_intent': intent_analysis['primary_intent']
                })
        
        # ุงูุจุญุซ ูู ุงูููุงุญู ูุน ุฃููููุฉ ุฎุงุตุฉ
        for appendix in data.get('appendices', []):
            score = self._calculate_advanced_relevance(
                appendix, semantic_terms, intent_analysis, 'appendix'
            )
            
            # ุฃููููุฉ ุฅุถุงููุฉ ููููุญู ุงููุญุฏุฏ ูู ุงูุณุคุงู
            if (intent_analysis['target_appendix'] and 
                str(appendix.get('appendix_number', '')) == intent_analysis['target_appendix']):
                score += 15
            
            if score > 0:
                results.append({
                    'article_number': f"ููุญู {appendix.get('appendix_number', '')}",
                    'title': appendix.get('title', ''),
                    'content': str(appendix.get('content', '')),
                    'relevance_score': score,
                    'content_type': 'appendix',
                    'matches_intent': intent_analysis['primary_intent']
                })
        
        # ุชุฑุชูุจ ุงููุชุงุฆุฌ ุจุฐูุงุก
        results.sort(key=lambda x: (
            x['relevance_score'],
            1 if x['content_type'] == 'appendix' else 0,
            1 if intent_analysis['target_appendix'] and intent_analysis['target_appendix'] in str(x['article_number']) else 0
        ), reverse=True)
        
        return results[:8]  # ุฅุฑุฌุงุน ุงููุฒูุฏ ูู ุงููุชุงุฆุฌ ููุชุญููู ุงูุฃุนูู
    
    def enhanced_intelligent_search(self, question: str, data: dict, language: str) -> List[Dict[str, Any]]:
        """ุจุญุซ ุฐูู ูุญุณู ูุน ุงููุธุงู ุงููุชูุฏู ุงูุฌุฏูุฏ (ุฅุถุงูุฉ ุขููุฉ)"""
        # ุงุณุชุฎุฏุงู ุงููุธุงู ุงูุฃุตูู ูู fallback ุฏุงุฆูุงู
        original_results = self.advanced_search(question, data, language)
        
        # ุฅุถุงูุฉ ุงูุชุญุณููุงุช ุฅุฐุง ูุงู ุงููุธุงู ุงููุชูุฏู ูุชุงุญ
        if ADVANCED_REASONING_AVAILABLE and 'advanced_reasoning_system' in globals():
            try:
                # ุงุณุชุฎุฑุงุฌ ููุงูุงุช ุงูุณุคุงู ูููุธุงู ุงููุชูุฏู
                question_entities = advanced_reasoning_system._extract_question_entities(question)
                
                # ุชุญุณูู ุญุณุงุจ ุงูุตูุฉ ูููุชุงุฆุฌ ุงูููุฌูุฏุฉ
                for result in original_results:
                    enhanced_relevance = advanced_reasoning_system.calculate_advanced_relevance(
                        result, question, question_entities
                    )
                    # ุฏูุฌ ุงููุชูุฌุฉ ุงููุญุณูุฉ ูุน ุงููุชูุฌุฉ ุงูุฃุตููุฉ
                    result['enhanced_relevance'] = enhanced_relevance
                    result['original_relevance'] = result.get('relevance_score', 0)
                    # ุงุณุชุฎุฏุงู ุฃุนูู ูุชูุฌุฉ
                    result['relevance_score'] = max(result['original_relevance'], enhanced_relevance / 10)
                    result['expert_processed'] = True
                
                # ุฅุนุงุฏุฉ ุชุฑุชูุจ ุงููุชุงุฆุฌ ุจูุงุก ุนูู ุงูุตูุฉ ุงููุญุณูุฉ
                original_results.sort(key=lambda x: x.get('enhanced_relevance', 0), reverse=True)
                
                print(f"๐ง Enhanced search completed with {len(original_results)} results")
                
            except Exception as e:
                print(f"โ๏ธ Advanced reasoning enhancement failed, using original: {str(e)}")
                # ุฅุถุงูุฉ ุนูุงูุฉ ูููุชุงุฆุฌ ุงูุฃุตููุฉ
                for result in original_results:
                    result['expert_processed'] = False
        else:
            # ุฅุถุงูุฉ ุนูุงูุฉ ูููุชุงุฆุฌ ุงูุฃุตููุฉ
            for result in original_results:
                result['expert_processed'] = False
        
        return original_results
    
    def _calculate_advanced_relevance(self, item: dict, terms: List[str], 
                                    intent_analysis: dict, content_type: str) -> float:
        """ุญุณุงุจ ุงูุตูุฉ ุงููุชูุฏูุฉ ูุน ููู ุงูุณูุงู"""
        content = str(item.get('content', '')).lower()
        title = str(item.get('title', '')).lower()
        
        score = 0.0
        
        # ุงูุจุญุซ ุงูุฃุณุงุณู ูู ุงููุตูุต
        for term in terms:
            term_lower = term.lower()
            if term_lower in content:
                score += 3.0 if content_type == 'appendix' else 2.0
            if term_lower in title:
                score += 4.0 if content_type == 'appendix' else 3.0
        
        # ุชูููู ุงูุณูุงู ุญุณุจ ููุน ุงูุณุคุงู
        if intent_analysis['primary_intent'] == 'definition':
            if any(word in content for word in ['ุชุนุฑูู', 'ูู', 'ูู', 'ุนุจุงุฑุฉ ุนู']):
                score += 2.0
        elif intent_analysis['primary_intent'] == 'specification':
            if any(word in content for word in ['ูุชุฑ', 'ุณู', 'ุซุงููุฉ', 'ูููู', 'measurement']):
                score += 2.0
        elif intent_analysis['primary_intent'] == 'procedure':
            if any(word in content for word in ['ูุฌุจ', 'ุฎุทูุงุช', 'ุทุฑููุฉ', 'ููููุฉ']):
                score += 2.0
        
        # ุชูููู ุฅุถุงูู ููููุงุญู ูู ุงูุฃุณุฆูุฉ ุงููุชุฎุตุตุฉ
        if content_type == 'appendix' and intent_analysis['target_appendix']:
            score += 5.0
        
        return score


def create_expert_legal_analysis(question: str, results: List[Dict[str, Any]], language: str = 'arabic') -> str:
    """ุชุญููู ูุงูููู ุฎุจูุฑ ูุชูุฏู ูุน ููู ุนููู ูููุตูุต"""
    
    if not results:
        return """๐ง **ุงูุชุญููู ุงููุงูููู ุงูุฎุจูุฑ:**

ุจุนุฏ ุงูุจุญุซ ุงูุดุงูู ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุงููููุฉ ุงููุงููุฉ (55 ูุงุฏุฉ + 21 ููุญู ุนุฑุจูุ 55 ูุงุฏุฉ + 2 ููุญู ุฅูุฌููุฒู)ุ ูู ูุชู ุงูุนุซูุฑ ุนูู ูุตูุต ูุงููููุฉ ูุทุงุจูุฉ ุชูุงูุงู ูุงุณุชูุณุงุฑู.

**ุงูุชูุฌูู ุงูุฎุจูุฑ:**
ูููุตุญ ุจุฅุนุงุฏุฉ ุตูุงุบุฉ ุงูุณุคุงู ุจุงุณุชุฎุฏุงู ูุตุทูุญุงุช ูุงููููุฉ ูุญุฏุฏุฉ ูุซู: "ุงูููุญู 9"ุ "ุงูููุญู 10"ุ "ููุงุตูุงุช ุงูุฑูุญ"ุ "ููุงุนุฏ ุงูุณูู"ุ "ุฃููุงุช ุงููุณุงุจูุงุช".

**ุงููุญุชูู ุงููุชููุฑ:**
- ุงููุธุงู ุงูุฃุณุงุณู: 55 ูุงุฏุฉ ูุงููููุฉ ุดุงููุฉ
- ุงูููุญู 9: ุจุฑูุงูุฌ ุงูุจุทููุฉ ุงูุชูุตููู ูุงูุชูุงุท ุงูุฃูุชุงุฏ
- ุงูููุญู 10: ุจุฑูุงูุฌ ุจุทููุงุช ุฃูุซุฑ ูู 10 ุฏูู
- ุฌููุน ุงููุตูุต ูุญููุธุฉ ูุงููุฉ ุจุฏูู ุงูุชุทุงุน ุญุฑู ูุงุญุฏ"""
    
    # ุชุญููู ูุชูุฏู ููุณุคุงู
    intent_analysis = legal_analyzer.analyze_question_intent(question)
    main_result = results[0]
    
    # ุชุญููู ุงูุณูุงู ุงููุงูููู
    legal_context = _analyze_legal_context(results, intent_analysis)
    
    # ุงุณุชุฎุฑุงุฌ ุงููุญุชูู ุงูุฑุฆูุณู ุจุฐูุงุก
    primary_content = _extract_primary_legal_content(main_result)
    
    # ุชุญููู ุงูุนูุงูุงุช ุจูู ุงููุตูุต
    interconnections = _analyze_text_interconnections(results)
    
    # ุจูุงุก ุงููุฑุงุฌุน ุงููุชุฎุตุตุฉ
    expert_references = _build_expert_references(results[:4], intent_analysis)
    
    # ุชุญุฏูุฏ ููุน ุงูุชุญููู ุงููุทููุจ
    analysis_type = _determine_analysis_type(question, intent_analysis)
    
    expert_analysis = f"""๐ง **ุงูุชุญููู ุงููุงูููู ุงูุฎุจูุฑ:**

{primary_content}

**ุงูููู ุงูุนููู ููุณูุงู ุงููุงูููู:**
{legal_context['deep_understanding']}

**ุชุญููู ุงูุชุณูุณู ุงูููุทูู:**
{legal_context['logical_sequence']}

**ุงูุฃุณุณ ุงููุงููููุฉ ุงููุชุฎุตุตุฉ:**
{chr(10).join(expert_references)}

**ุชุญููู ุงูุนูุงูุงุช ูุงูุชุฑุงุจุทุงุช:**
{interconnections}

**ุงูุฎูุงุตุฉ ุงูุฎุจูุฑุฉ ุงูููุงุฆูุฉ:**
{_generate_expert_conclusion(results, intent_analysis, analysis_type)}"""
    
    return expert_analysis

def _analyze_legal_context(results: List[Dict[str, Any]], intent_analysis: dict) -> dict:
    """ุชุญููู ุงูุณูุงู ุงููุงูููู ุงูุนููู"""
    
    # ุชุญููู ููุน ุงููุญุชูู (ููุงุฏ ุฃุณุงุณูุฉ vs ููุงุญู)
    content_types = [r.get('content_type', 'article') for r in results]
    has_appendices = 'appendix' in content_types
    has_articles = 'article' in content_types
    
    if intent_analysis['target_appendix']:
        if intent_analysis['target_appendix'] == '9':
            deep_understanding = """ุงูููุญู 9 ูุญุชูู ุนูู ุงูุจุฑูุงูุฌ ุงูุชูุตููู ููุจุทููุงุช ุงูุนุงุฏูุฉุ ููู ุฌุฒุก ูุง ูุชุฌุฒุฃ ูู ุงููุธุงู ุงููุงูููู ุงูุดุงูู. ูุฐุง ุงูููุญู ูุญุฏุฏ ุงูุชุณูุณู ุงูุฒููู ูุงูุชููู ูููุณุงุจูุงุชุ ููุนุชุจุฑ ุงููุฑุฌุน ุงูุฃุณุงุณู ูุชูุธูู ุงูุฃุญุฏุงุซ ุงูุฑูุงุถูุฉ ูููุงู ูููุนุงููุฑ ุงูุฏูููุฉ ุงููุนุชูุฏุฉ."""
            logical_sequence = """ูุฃุชู ุงูููุญู 9 ูุชุทุจูู ุนููู ููููุงุฏ ุงููุงููููุฉ ุงูุฃุณุงุณูุฉุ ุญูุซ ูุชุฑุฌู ุงูููุงุนุฏ ุงููุธุฑูุฉ ุฅูู ุจุฑูุงูุฌ ุชูููุฐู ูุงุจู ููุชุทุจูู. ุงูุชุณูุณู ุงูููุทูู ูุจุฏุฃ ูู ุงูููุงุนุฏ ุงูุนุงูุฉ ูู ุงูููุงุฏ ุงูุฃุณุงุณูุฉุ ุซู ููุชูู ุฅูู ุงูุชูุงุตูู ุงูุชูุธูููุฉ ูู ุงูููุญู."""
        elif intent_analysis['target_appendix'] == '10':
            deep_understanding = """ุงูููุญู 10 ูุฎุตุต ููุจุทููุงุช ุงูุฏูููุฉ ุงููุจุฑู ุงูุชู ุชุถู ุฃูุซุฑ ูู 10 ุฏููุ ููู ููุซู ุงููุณุชูู ุงูุฃุนูู ูู ุงูุชูุธูู ุงููุงูููู. ูุฐุง ุงูููุญู ูุนูุณ ุงูุชุนููุฏ ุงูุฅุถุงูู ุงููุทููุจ ูุฅุฏุงุฑุฉ ุงูุฃุญุฏุงุซ ุงูุฏูููุฉ ูุงุณุนุฉ ุงููุทุงู."""
            logical_sequence = """ุงูููุญู 10 ูุจูู ุนูู ุฃุณุณ ุงูููุญู 9 ูุน ุฅุถุงูุงุช ูุชุฎุตุตุฉ ููุจุทููุงุช ุงูุฏูููุฉ. ุงูุชุฏุฑุฌ ุงูููุทูู ูุดูู: ุงูููุงุนุฏ ุงูุฃุณุงุณูุฉ โ ุงูุจุฑูุงูุฌ ุงูุนุงุฏู (ููุญู 9) โ ุงูุจุฑูุงูุฌ ุงูุฏููู ุงููุชูุฏู (ููุญู 10)."""
        else:
            deep_understanding = "ุงููุต ุงููุทููุจ ุฌุฒุก ูู ููุธููุฉ ูุงููููุฉ ูุชูุงููุฉ ุชุญูู ุฌููุน ุฌูุงูุจ ุฑูุงุถุฉ ุงูุชูุงุท ุงูุฃูุชุงุฏ."
            logical_sequence = "ุงูุชุณูุณู ุงูููุทูู ูุชุจุน ุงููููู ุงููุฑูู ููููุงููู ูู ุงูุนุงู ุฅูู ุงูุฎุงุต."
    else:
        deep_understanding = """ุงููุตูุต ุงููุงููููุฉ ุงููุญุฏุฏุฉ ุชุดูู ุฌุฒุกุงู ูู ุงููุธุงู ุงููุงูููู ุงูุดุงูู ููุงุชุญุงุฏ ุงูุฏููู ูุงูุชูุงุท ุงูุฃูุชุงุฏ. ูู ูุต ูุงูููู ูุตูู ููุชูุงูู ูุน ุงููุตูุต ุงูุฃุฎุฑู ูุถูุงู ุงูุชุทุจูู ุงูุณููู ูุงูุนุงุฏู ููููุงููู."""
        logical_sequence = """ุงูุชุณูุณู ุงูููุทูู ูุชุจุน ูุจุฏุฃ ุงูุชุฏุฑุฌ ูู ุงูููุงุนุฏ ุงูุนุงูุฉ ูู ุงูููุงุฏ ุงูุฃุณุงุณูุฉ ุฅูู ุงูุชูุงุตูู ุงูุชุทุจูููุฉ ูู ุงูููุงุญูุ ููุง ูุถูู ุงููุถูุญ ูุงูุดููููุฉ ูู ุงูุชุทุจูู."""
    
    return {
        'deep_understanding': deep_understanding,
        'logical_sequence': logical_sequence
    }

def _extract_primary_legal_content(result: dict) -> str:
    """ุงุณุชุฎุฑุงุฌ ุงููุญุชูู ุงููุงูููู ุงูุฃุณุงุณู ุจุฐูุงุก"""
    content = result.get('content', '')
    
    # ุชุญุฏูุฏ ุงูุฌููุฉ ุงูุฃูู ูู ุงููุต
    sentences = re.split(r'[.!ุ]', content)
    
    # ุงูุจุญุซ ุนู ุงูุฌูู ุงูุชู ุชุญุชูู ุนูู ูุนูููุงุช ูุงููููุฉ ูููุฉ
    key_indicators = ['ูุฌุจ', 'ูุง ูุฌูุฒ', 'ููุณูุญ', 'ูุญุธูุฑ', 'ูุทููุจ', 'must', 'shall', 'should']
    
    key_sentence = ""
    for sentence in sentences:
        sentence = sentence.strip()
        if any(indicator in sentence for indicator in key_indicators) and len(sentence) > 20:
            key_sentence = sentence
            break
    
    if not key_sentence and sentences:
        key_sentence = sentences[0].strip()
    
    return key_sentence if key_sentence else content[:200] + "..."

def _analyze_text_interconnections(results: List[Dict[str, Any]]) -> str:
    """ุชุญููู ุงูุนูุงูุงุช ูุงูุชุฑุงุจุทุงุช ุจูู ุงููุตูุต"""
    
    if len(results) < 2:
        return "ุงููุต ุงููุญุฏุฏ ููู ููุญุฏุฉ ูุงููููุฉ ูุณุชููุฉ ูุน ุฃูููุฉ ุฎุงุตุฉ ูู ุงูุณูุงู ุงููุงูููู ุงูุดุงูู."
    
    # ุชุญููู ุฃููุงุน ุงููุญุชูู
    articles = [r for r in results if r.get('content_type') == 'article']
    appendices = [r for r in results if r.get('content_type') == 'appendix']
    
    interconnection_analysis = ""
    
    if articles and appendices:
        interconnection_analysis = """ููุธูุฑ ุงูุชุญููู ูุฌูุฏ ุชุฑุงุจุท ูุจุงุดุฑ ุจูู ุงูููุงุฏ ุงููุงููููุฉ ุงูุฃุณุงุณูุฉ ูุงูููุงุญู ุงูุชุทุจูููุฉ. ุงูููุงุฏ ุงูุฃุณุงุณูุฉ ุชุถุน ุงูุฅุทุงุฑ ุงูุนุงูุ ุจูููุง ุงูููุงุญู ุชูุฏู ุงูุชูุงุตูู ุงูุชูููุฐูุฉ ุงููุงุฒูุฉ ููุชุทุจูู ุงูุนููู."""
    elif len(appendices) > 1:
        interconnection_analysis = """ุงูููุงุญู ุงููุชุนุฏุฏุฉ ุชุนูู ุจูุธุงู ุชูุงูููุ ุญูุซ ูู ููุญู ูุบุทู ุฌุงูุจุงู ูุชุฎุตุตุงู ูู ุงูุชุทุจูู ุงููุงููููุ ููุง ูุถูู ุงูุดููููุฉ ูู ุงูุชูุธูู."""
    elif len(articles) > 1:
        interconnection_analysis = """ุงูููุงุฏ ุงููุงููููุฉ ุงููุชุฑุงุจุทุฉ ุชุดูู ููุธููุฉ ูุชูุงููุฉ ูู ุงูููุงุนุฏ ุงูุชู ุชุญูู ุฌูุงูุจ ูุฎุชููุฉ ูู ุงูุฑูุงุถุฉุ ูุน ุถูุงู ุนุฏู ุงูุชุนุงุฑุถ ูุงูุชูุงูู ูู ุงูุชุทุจูู."""
    else:
        interconnection_analysis = """ุงููุตูุต ุงููุญุฏุฏุฉ ุชูุธูุฑ ุงูุงุชุณุงู ุงูุฏุงุฎูู ูู ุงููุธุงู ุงููุงููููุ ุญูุซ ูู ูุต ูุฏุนู ููููู ุงููุตูุต ุงูุฃุฎุฑู ูู ุฅุทุงุฑ ูุงูููู ููุญุฏ."""
    
    return interconnection_analysis

def _build_expert_references(results: List[Dict[str, Any]], intent_analysis: dict) -> List[str]:
    """ุจูุงุก ุงููุฑุงุฌุน ุงููุชุฎุตุตุฉ ููุฎุจุฑุงุก"""
    references = []
    
    for i, result in enumerate(results):
        ref_num = result['article_number']
        content = result['content']
        
        # ุงุณุชุฎุฑุงุฌ ุงูุฌุฒุก ุงูุฃูุซุฑ ุตูุฉ ูู ุงููุญุชูู
        if intent_analysis['target_appendix'] and 'ููุญู' in str(ref_num):
            # ููููุงุญูุ ุงุณุชุฎุฑุงุฌ ุงููุนูููุงุช ุงูุชูููุฉ
            relevant_part = _extract_technical_info(content)
        else:
            # ููููุงุฏ ุงูุนุงุฏูุฉุ ุงุณุชุฎุฑุงุฌ ุงููุงุนุฏุฉ ุงููุงููููุฉ ุงูุฃุณุงุณูุฉ
            relevant_part = _extract_core_legal_rule(content)
        
        ref_type = "ุงูููุญู ุงูุชููู" if result.get('content_type') == 'appendix' else "ุงููุงุฏุฉ ุงููุงููููุฉ"
        references.append(f"โข ุงุณุชูุงุฏุงู ุฅูู {ref_type} ุฑูู {ref_num}: \"{relevant_part}\"")
    
    return references

def _extract_technical_info(content: str) -> str:
    """ุงุณุชุฎุฑุงุฌ ุงููุนูููุงุช ุงูุชูููุฉ ูู ุงููุญุชูู"""
    # ุงูุจุญุซ ุนู ูุนูููุงุช ุชูููุฉ (ุฃุฑูุงูุ ููุงุณุงุชุ ุฃููุงุช)
    technical_patterns = [
        r'\d+\s*(ูุชุฑ|ุณู|ุซุงููุฉ|ุฏูููุฉ|ูููู)',
        r'\d+\.\d+\s*(ูุชุฑ|ุณู|ุซุงููุฉ|ุฏูููุฉ)',
        r'(ุงูุญุฏ ุงูุฃุฏูู|ุงูุญุฏ ุงูุฃูุตู|ูุง ููู ุนู|ูุง ูุฒูุฏ ุนู).*?\d+',
        r'(ูุฌุจ ุฃู|must|shall).*?(?=[.!ุ]|$)'
    ]
    
    for pattern in technical_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            # ุชูุณูุน ุงููุทุงุจูุฉ ูุชุดูู ุงูุณูุงู
            start = max(0, match.start() - 50)
            end = min(len(content), match.end() + 50)
            return content[start:end].strip()
    
    # ุฅุฐุง ูู ุชูุฌุฏ ูุนูููุงุช ุชูููุฉุ ุฅุฑุฌุงุน ุจุฏุงูุฉ ุงููุญุชูู
    return content[:120] + "..." if len(content) > 120 else content

def _extract_core_legal_rule(content: str) -> str:
    """ุงุณุชุฎุฑุงุฌ ุงููุงุนุฏุฉ ุงููุงููููุฉ ุงูุฃุณุงุณูุฉ"""
    # ุงูุจุญุซ ุนู ุงูุฌูู ุงูุชู ุชุญุชูู ุนูู ููุงุนุฏ ูุงููููุฉ
    rule_indicators = ['ูุฌุจ', 'ูุง ูุฌูุฒ', 'ููุณูุญ', 'ูุญุธูุฑ', 'ูุทููุจ', 'ูููุฒู']
    
    sentences = re.split(r'[.!ุ]', content)
    for sentence in sentences:
        sentence = sentence.strip()
        if any(indicator in sentence for indicator in rule_indicators) and len(sentence) > 10:
            return sentence
    
    # ุฅุฐุง ูู ุชูุฌุฏ ููุงุนุฏ ูุงุถุญุฉุ ุฅุฑุฌุงุน ุงูุฌููุฉ ุงูุฃููู
    return sentences[0].strip() if sentences else content[:100] + "..."

def _determine_analysis_type(question: str, intent_analysis: dict) -> str:
    """ุชุญุฏูุฏ ููุน ุงูุชุญููู ุงููุทููุจ"""
    if intent_analysis['primary_intent'] == 'definition':
        return "ุชุนุฑููู ูุชูุถูุญู"
    elif intent_analysis['primary_intent'] == 'specification':
        return "ุชููู ูููุงุตูุงุช"
    elif intent_analysis['primary_intent'] == 'procedure':
        return "ุฅุฌุฑุงุฆู ูุชุทุจููู"
    elif intent_analysis['target_appendix']:
        return "ุชูุตููู ูุชุฎุตุต"
    else:
        return "ุดุงูู ููุชูุงูู"

def _generate_expert_conclusion(results: List[Dict[str, Any]], intent_analysis: dict, analysis_type: str) -> str:
    """ุชูููุฏ ุงูุฎูุงุตุฉ ุงูุฎุจูุฑุฉ ุงูููุงุฆูุฉ"""
    
    conclusion_templates = {
        "ุชุนุฑููู ูุชูุถูุญู": """ุงูุชุญููู ุงูุฎุจูุฑ ููุธูุฑ ุฃู ุงูุชุนุฑูู ุงููุทููุจ ูุคุณุณ ุนูู ูุตูุต ูุงููููุฉ ูุญุฏุฏุฉ ูุฏูููุฉุ ููุง ูุถูู ุงููุถูุญ ูู ุงูููู ูุงูุชุทุจูู. ุงููุธุงู ุงููุงูููู ูููุฑ ุชุนุฑููุงุช ุดุงููุฉ ุชุบุทู ุฌููุน ุงูุฌูุงูุจ ุงููุทููุจุฉ ูุน ุถูุงู ุนุฏู ุงูุงูุชุจุงุณ ูู ุงูุชูุณูุฑ.""",
        
        "ุชููู ูููุงุตูุงุช": """ุงูุชุญููู ุงูุชููู ุงููุชุฎุตุต ููุดู ุนู ุฏูุฉ ุงูููุงุตูุงุช ุงููุญุฏุฏุฉ ูู ุงููุตูุต ุงููุงููููุฉุ ูุงูุชู ุชู ูุถุนูุง ูุถูุงู ุงูุนุฏุงูุฉ ูุงูุณูุงูุฉ ูู ุงููุณุงุจูุงุช. ูู ููุงุตูุฉ ุชูููุฉ ูุฏุฑูุณุฉ ุจุนูุงูุฉ ูุชุญููู ุงูุชูุงุฒู ุจูู ุงููุชุทูุจุงุช ุงูุฑูุงุถูุฉ ูุงูุงุนุชุจุงุฑุงุช ุงูุนูููุฉ.""",
        
        "ุฅุฌุฑุงุฆู ูุชุทุจููู": """ุงูุฅุฌุฑุงุกุงุช ุงููุญุฏุฏุฉ ุชุชุจุน ูููุฌูุฉ ุนูููุฉ ูุงุถุญุฉ ุชุถูู ุงูุชุทุจูู ุงูุณููู ููููุงููู. ูู ุฎุทูุฉ ุฅุฌุฑุงุฆูุฉ ูุตููุฉ ูุชุญููู ุงููุฏู ุงููุทููุจ ูุน ุถูุงู ุงูุนุฏุงูุฉ ูุงูุดูุงููุฉ ูู ุงูุชูููุฐ.""",
        
        "ุชูุตููู ูุชุฎุตุต": """ุงูุชุญููู ุงููุชุฎุตุต ููููุญู ููุธูุฑ ุงูุชุนููุฏ ูุงูุฏูุฉ ูู ุงูุชูุธููุ ุญูุซ ูู ุชูุตูู ูุฏุฑูุณ ูุถูุงู ุงูุชูููุฐ ุงูุฃูุซู ููุจุทููุงุช. ุงูููุงุญู ุชูุซู ุฐุฑูุฉ ุงูุชูุธูู ุงููุงูููู ุงูุฑูุงุถู ุจุชูุงุตูููุง ุงูุดุงููุฉ ูุงูุฏูููุฉ.""",
        
        "ุดุงูู ููุชูุงูู": """ุงูุชุญููู ุงูุดุงูู ููุดู ุนู ุงูุชูุงูู ุงููุญูู ุจูู ูุฎุชูู ุนูุงุตุฑ ุงููุธุงู ุงููุงููููุ ุญูุซ ูู ูุต ูุฏุนู ููููู ุงููุตูุต ุงูุฃุฎุฑู ูู ููุธููุฉ ูุงููููุฉ ูุชูุงุณูุฉ ููุชุทูุฑุฉ ุชุฎุฏู ุฃูุฏุงู ุงูุฑูุงุถุฉ ุงูุนุงุฏูุฉ ูุงูููุธูุฉ."""
    }
    
    base_conclusion = conclusion_templates.get(analysis_type, conclusion_templates["ุดุงูู ููุชูุงูู"])
    
    # ุฅุถุงูุฉ ูุนูููุงุช ุนู ุฌูุฏุฉ ุงูุจูุงูุงุช
    data_integrity_note = """ ูุฐุง ุงูุชุญููู ูุจูู ุนูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุงููููุฉ ุงููุงููุฉ ูุงููุญููุธุฉ ุจุฏูุฉ ุชุงูุฉุ ููุง ูุถูู ุนุฏู ููุฏุงู ุฃู ูุนูููุฉ ูุงููููุฉ ูููุฉ."""
    
    return base_conclusion + data_integrity_note


# ุฏุงูุฉ ุชูุณูู ุงูุฅุฌุงุจุฉ ุงููุญุณูุฉ ุงูุฌุฏูุฏุฉ (ุฅุถุงูุฉ ุขููุฉ)
def format_enhanced_legal_response(question: str, results: List[Dict[str, Any]], 
                                 intent_analysis: dict, language: str = 'arabic') -> str:
    """ุชูุณูู ุฅุฌุงุจุฉ ูุงููููุฉ ูุญุณูุฉ ููุงุถุญุฉ (ุจูุงุก ุนูู ููุงุญุธุงุช ุงููุณุชุฎุฏู)"""
    
    # ูุธุงู ุชุตููู ุฐูู ุดุงูู ููุฃุณุฆูุฉ (ุฅุถุงูุฉ ุขููุฉ - ูุง ุชุคุซุฑ ุนูู ุงููุตูุต ุงููุงููููุฉ)
    question_type = classify_question_intelligently(question, results)
    
    # ุชูุฌูู ุงูุณุคุงู ูููุนุงูุฌ ุงูููุงุณุจ ุจูุงุก ุนูู ุงูุชุตููู ุงูุฐูู
    if question_type == 'definitions':
        return format_definitions_response(question, results, language)
    elif question_type == 'responsibilities':
        return format_responsibilities_response(question, results, language)
    elif question_type == 'true_false':
        return format_true_false_response(question, results, language)
    elif question_type == 'complex_scoring':
        return format_complex_scoring_response(question, results, language)
    elif question_type == 'technical_specs':
        return format_technical_specs_response(question, results, language)
    elif question_type == 'timing_analysis':
        return format_timing_analysis_response(question, results, language)
    elif question_type == 'procedures':
        return format_procedures_response(question, results, language)
    elif question_type == 'penalties':
        return format_penalty_response(question, results, language)
    else:
        return format_general_legal_response(question, results, language)


def classify_question_intelligently(question: str, results: List[Dict[str, Any]]) -> str:
    """ูุธุงู ุชุตููู ุฐูู ุดุงูู ููุฃุณุฆูุฉ (ุฌุฏูุฏ - ูุง ูุคุซุฑ ุนูู ุฃู ุดูุก ููุฌูุฏ)"""
    
    question_lower = question.lower()
    
    # ุฃุณุฆูุฉ ุงูุตุญ ูุงูุฎุทุฃ (ูุคุดุฑุงุช ูุญุฏุฏุฉ ูุฏูููุฉ ููุท - ุชุญุณูู ุฌุฐุฑู)
    true_false_indicators = [
        # ูุคุดุฑุงุช ูุงุถุญุฉ ูุฃุณุฆูุฉ ุงูุตุญ ูุงูุฎุทุฃ ููุท
        ('mark the correct answer' in question_lower and ('โ๏ธ' in question or 'โ' in question)),
        ('true' in question_lower and 'false' in question_lower),
        ('correct' in question_lower and 'false' in question_lower and 'mark' in question_lower),
        # ุงูุฑููุฒ ุงููุญุฏุฏุฉ ููุตุญ ูุงูุฎุทุฃ ููุท ูุน ุงูุณูุงู ุงูููุงุณุจ
        ('โ' in question and ('โ๏ธ' in question or 'mark' in question_lower)),
        # ุงูุฃููุงุณ ุงููุงุฑุบุฉ ูุน ูุฌูุฏ ุณูุงู ุตุญ/ุฎุทุฃ
        (any(line.strip().endswith('( )') for line in question.split('\n') if line.strip()) 
         and ('mark' in question_lower or 'true' in question_lower or 'false' in question_lower or 'correct' in question_lower)),
    ]
    
    if any(true_false_indicators):
        return 'true_false'
    
    # ูุคุดุฑุงุช ุงูุฃุณุฆูุฉ ุงูุชูููุฉ ูุงูููุงุตูุงุช (ุฃููููุฉ ุนุงููุฉ)
    technical_indicators = [
        # ุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ
        ('a)' in question and 'b)' in question),
        ('a.' in question and 'b.' in question),
        
        # ููุงุตูุงุช ุชูููุฉ - ุนุฑุจู
        any(word in question_lower for word in ['ููุงุตูุงุช', 'ููุงุณุงุช', 'ุฃุจุนุงุฏ', 'ุทูู', 'ุนุฑุถ', 'ุงุฑุชูุงุน']),
        any(word in question_lower for word in ['ุณู', 'ูุชุฑ', 'ููู', 'ูู', 'ููุงุณ']),
        any(word in question_lower for word in ['ุฃุฏูู', 'ุฃูุตู', 'ุญุฏ ุฃุฏูู', 'ุญุฏ ุฃูุตู']),
        
        # ููุงุตูุงุช ุชูููุฉ - ุฅูุฌููุฒู  
        any(word in question_lower for word in ['specifications', 'measurements', 'dimensions']),
        any(word in question_lower for word in ['length', 'width', 'height', 'size', 'diameter']),
        any(word in question_lower for word in ['minimum', 'maximum', 'min', 'max']),
        any(word in question_lower for word in ['cm', 'meter', 'metres', 'mm', 'inch', 'ft']),
        
        # ูุคุดุฑุงุช ูุญุฏุฏุฉ ููุฃุณุฆูุฉ ุงูุฌุฏูุฏุฉ (ุฅุถุงูุฉ ุขููุฉ)
        ('arena' in question_lower and ('length' in question_lower or 'dimension' in question_lower)),
        ('tent pegging arena' in question_lower),
        ('peg hole' in question_lower and 'dimension' in question_lower),
        ('peg itself' in question_lower and 'dimension' in question_lower),
        
        # ูุชุทูุจุงุช ุงูุฃุนุฏุงุฏ ูุงููุฌุงู (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ - ูุง ุชุคุซุฑ ุนูู ุงูููุฌูุฏ)
        any(word in question_lower for word in ['number of', 'how many', 'ูู ุนุฏุฏ', 'ุนุฏุฏ']),
        ('minimum' in question_lower and any(word in question_lower for word in ['number', 'members', 'ุนุฏุฏ', 'ุฃุนุถุงุก'])),
        ('maximum' in question_lower and any(word in question_lower for word in ['number', 'members', 'ุนุฏุฏ', 'ุฃุนุถุงุก'])),
        any(word in question_lower for word in ['jury', 'committee', 'panel', 'ูุฌูุฉ', 'ุฌูุงุฒ ููู']),
        ('required' in question_lower and any(word in question_lower for word in ['members', 'jury', 'ุฃุนุถุงุก', 'ูุฌูุฉ'])),
        
        # ูุชุทูุจุงุช ุงูุฃุนุถุงุก ุงูุฃุฌุงูุจ ูุงูุญูุงุฏูุฉ (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ - ูุง ุชุคุซุฑ ุนูู ุงูููุฌูุฏ)
        ('which' in question_lower and any(word in question_lower for word in ['jury members', 'members', 'ุฃุนุถุงุก'])),
        any(word in question_lower for word in ['foreign', 'international', 'ุฃุฌูุจู', 'ุฃุฌุงูุจ', 'ุฏููู']),
        ('from' in question_lower and any(word in question_lower for word in ['foreign countries', 'other countries', 'ุฏูู ุฃุฌูุจูุฉ'])),
        ('two' in question_lower and any(word in question_lower for word in ['jury members', 'members', 'ุฃุนุถุงุก'])),
        any(word in question_lower for word in ['neutral', 'neutrality', 'impartial', 'ุญูุงุฏู', 'ุญูุงุฏูุฉ', 'ูุฒุงูุฉ']),
        
        # ุงูุดุฑูุท ูุงูุฅุฌุฑุงุกุงุช ูุงูุงุณุชุซูุงุกุงุช (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ - ูุง ุชุคุซุฑ ุนูู ุงูููุฌูุฏ)
        ('under what conditions' in question_lower and any(word in question_lower for word in ['time', 'limit', 'ููุช', 'ุญุฏ'])),
        ('conditions' in question_lower and any(word in question_lower for word in ['adjusted', 'changed', 'modified', 'ุชุนุฏูู', 'ุชุบููุฑ'])),
        any(word in question_lower for word in ['exceptions', 'authorization', 'approval', 'ุงุณุชุซูุงุกุงุช', 'ุชุตุฑูุญ', 'ููุงููุฉ']),
        ('time limit' in question_lower and any(word in question_lower for word in ['adjusted', 'modified', 'changed', 'ุชุนุฏูู'])),
        
        # ููุงููู ุงููุงุนุจูู ุงูุงุญุชูุงุท (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
        any(word in question_lower for word in ['reserve', 'substitute', 'substitution', 'replacement']),
        any(word in question_lower for word in ['ุงุญุชูุงุทู', 'ุจุฏูู', 'ุงุณุชุจุฏุงู', 'ุฅุจุฏุงู']),
        ('rules for' in question_lower and any(word in question_lower for word in ['reserve', 'substitute', 'ุงุญุชูุงุทู'])),
        ('team composition' in question_lower or 'team members' in question_lower),
        ('five athletes' in question_lower or '5 athletes' in question_lower),
        
        # ูุนุฏุงุช ููุนุงููุฑ (ูุญููุธุฉ ููุง ูู)
        any(word in question_lower for word in ['ูุนุฏุงุช', 'ุฃุฏูุงุช', 'ุฑูุญ', 'ุณูู', 'ูุชุฏ']),
        any(word in question_lower for word in ['equipment', 'tools', 'lance', 'sword', 'peg']),
        
        # ููุงุตูุงุช ุงููุณุงุฑุงุช ูุงููุณุงูุงุช (ูุญุณู ุฌุฏูุฏ)
        any(word in question_lower for word in ['placed at', 'distance from', 'meters from', 'course layout']),
        any(word in question_lower for word in ['starting line', 'finish line', 'track', 'course']),
        any(word in question_lower for word in ['relay', 'individual', 'team', 'pair'] + ['competition', 'competitions']),
        any(word in question_lower for word in ['ุชูุถุน', 'ุชููุถุน', 'ูุณุงูุฉ ูู', 'ุฎุท ุงูุจุฏุงูุฉ', 'ูุณุงุฑ', 'ูุถูุงุฑ']),
        any(word in question_lower for word in ['70', '64.5', '65.5', 'ูุชุฑ', 'ุฃูุชุงุฑ'] + ['ูู ุฎุท', 'ูู ุงูุฎุท']),
        
        # ูุชุทูุจุงุช ุงูุชุณุฌูู ุงููุฑุฆู ูุงูุชูุซูู (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ - ูุง ุชุคุซุฑ ุนูู ุงูููุฌูุฏ)
        any(word in question_lower for word in ['video', 'recording', 'recordings', 'ุชุณุฌูู', 'ุชุณุฌููุงุช']),
        any(word in question_lower for word in ['camera', 'cameras', 'ูุงููุฑุง', 'ูุงููุฑุงุช']),
        any(word in question_lower for word in ['covered', 'must be covered', 'positions', 'ููุงูุน', 'ุชุบุทูุฉ']),
        ('video' in question_lower and any(word in question_lower for word in ['positions', 'must', 'covered', 'ููุงูุน'])),
        ('name' in question_lower and any(word in question_lower for word in ['positions', 'video', 'recordings', 'ููุงูุน'])),
        any(word in question_lower for word in ['videographer', 'media', 'ุฅุนูุงู', 'ูุตูุฑ']),
    ]
    
    # ูุคุดุฑุงุช ุฃุณุฆูุฉ ุงูุชูููุช ูุงููุฑุงุญู ุงูุฒูููุฉ
    timing_indicators = [
        (any(word in question_lower for word in ['ูุชู ุชุจุฏุฃ', 'ูุชู ุชูุชูู', 'ูุฏุฉ']) and 
         any(word in question_lower for word in ['ุจุทููุฉ', 'ุงุณุชุฆูุงู', 'ุงุนุชุฑุงุถ'])),
        (any(word in question_lower for word in ['ุณุงุนุฉ', 'ุฏูููุฉ', 'ููู', 'ุฃุณุจูุน']) and 
         any(word in question_lower for word in ['ุจุนุฏ', 'ูุจู', 'ุฎูุงู'])),
        ('when' in question_lower and any(word in question_lower for word in ['start', 'end', 'begin'])),
    ]
    
    # ูุคุดุฑุงุช ุฃุณุฆูุฉ ุงูุฅุฌุฑุงุกุงุช
    procedure_indicators = [
        any(word in question_lower for word in ['ุฅุฌุฑุงุกุงุช', 'ุฎุทูุงุช', 'ููููุฉ', 'ุทุฑููุฉ']),
        any(word in question_lower for word in ['ุชูุฏูู', 'ุงุฑุงุฏ ุงููุฑูู', 'ูุงูู ุงูุงุฌุฑุงุกุงุช']),
        any(word in question_lower for word in ['procedures', 'steps', 'how to', 'process']),
        ('what' in question_lower and 'procedure' in question_lower),
    ]
    
    # ูุคุดุฑุงุช ุฃุณุฆูุฉ ุงููุณุคูููุงุช ูุงูุงูุชุฒุงูุงุช (ุฌุฏูุฏ - ุฅุถุงูุฉ ุขููุฉ)
    responsibilities_indicators = [
        # ุงููุณุคูููุงุช ุงูุนุงูุฉ
        any(word in question_lower for word in ['responsibilities', 'ูุณุคูููุงุช', 'ูุณุคูููุฉ']),
        any(word in question_lower for word in ['duties', 'obligations', 'ูุงุฌุจุงุช', 'ุงูุชุฒุงูุงุช']),
        any(word in question_lower for word in ['liable', 'liability', 'ูุณุคูู ุนู', 'ุถูุงู']),
        
        # ุงูุฃูุงู ูุงูุญูุงูุฉ
        any(word in question_lower for word in ['safety', 'security', 'ุฃูุงู', 'ุฃูู', 'ุญูุงูุฉ']),
        any(word in question_lower for word in ['safe', 'secure', 'protect', 'ุขูู', 'ูุญูู']),
        
        # ุงูุชุฃููู ูุงูุชุบุทูุฉ
        any(word in question_lower for word in ['insurance', 'coverage', 'ุชุฃููู', 'ุชุบุทูุฉ']),
        any(word in question_lower for word in ['medical', 'health', 'ุทุจู', 'ุตุญู', 'ุนูุงุฌ']),
        any(word in question_lower for word in ['emergency', 'accident', 'ุทูุงุฑุฆ', 'ุญุงุฏุซ']),
        
        # ุงูููุธูุงุช ูุงูุงุชุญุงุฏุงุช
        ('hosting' in question_lower and any(word in question_lower for word in ['nf', 'federation', 'ุงุชุญุงุฏ'])),
        any(word in question_lower for word in ['organizing committee', 'oc', 'ูุฌูุฉ ุชูุธูููุฉ']),
        
        # ุฃุณุฆูุฉ ุงููุณุคูููุงุช ุงููุจุงุดุฑุฉ
        ('what are the' in question_lower and 'responsibilities' in question_lower),
        ('regarding' in question_lower and any(word in question_lower for word in ['safety', 'insurance', 'ุฃูุงู', 'ุชุฃููู'])),
        any(word in question_lower for word in ['provisions', 'requirements', 'mandatory', 'ุดุฑูุท', 'ูุชุทูุจุงุช', 'ุฅูุฒุงูู']),
    ]
    
    # ูุคุดุฑุงุช ุฃุณุฆูุฉ ุงูุชุนุฑููุงุช ูุงูููุงุนุฏ ุงูุนุงูุฉ (ุฌุฏูุฏ - ุฅุถุงูุฉ ุขููุฉ)
    definitions_indicators = [
        # ุฃุณุฆูุฉ ุงูุชุนุฑูู ุงููุจุงุดุฑุฉ
        any(word in question_lower for word in ['definition', 'define', 'what is', 'ุชุนุฑูู', 'ูุง ูู', 'ููุนุฑู']),
        any(word in question_lower for word in ['meaning', 'means', 'refers to', 'ูุนูู', 'ูุนูู', 'ูุดูุฑ ุฅูู']),
        
        # ุฃุณุฆูุฉ ุชุญุฏูุฏ ุงููุงุฆุฒูู ูุงูุนูููุงุช
        ('how are' in question_lower and any(word in question_lower for word in ['determined', 'decided', 'selected'])),
        ('how is' in question_lower and any(word in question_lower for word in ['winner', 'winning', 'champion'])),
        ('ููู ูุชู' in question_lower and any(word in question_lower for word in ['ุชุญุฏูุฏ', 'ุงุฎุชูุงุฑ', 'ุชูุฑูุฑ'])),
        
        # ุฃุณุฆูุฉ ุงููุงุฆุฒูู ุชุญุฏูุฏุงู
        any(word in question_lower for word in ['winning athlete', 'overall winner', 'champion', 'ูุงุฆุฒ', 'ุจุทู']),
        any(word in question_lower for word in ['winning team', 'team winner', 'ูุฑูู ูุงุฆุฒ', 'ูุฑูู ุจุทู']),
        ('winner' in question_lower and any(word in question_lower for word in ['event', 'competition', 'ุญุฏุซ', 'ูุณุงุจูุฉ'])),
        
        # ุงูุนูููุงุช ุงูุนุงูุฉ ูุงูููุงููู ุงูุฃุณุงุณูุฉ
        ('how' in question_lower and any(word in question_lower for word in ['calculated', 'computed', 'ููุญุณุจ'])),
        ('what determines' in question_lower or 'ูุง ุงูุฐู ูุญุฏุฏ' in question_lower),
        any(word in question_lower for word in ['overall', 'total', 'final', 'ุฅุฌูุงูู', 'ููุงุฆู', 'ููู']),
        
        # ูุคุดุฑุงุช ุฎุงุตุฉ ุจุงููุงุฏุฉ 103
        ('athlete' in question_lower and 'team' in question_lower and 'event' in question_lower),
    ]
    
    # ูุคุดุฑุงุช ุฃุณุฆูุฉ ุงูุนููุจุงุช (ูุญุณูุฉ - ุดุงููุฉ ุฃูุซุฑ)
    penalty_indicators = [
        # ุงููุคุดุฑุงุช ุงูุฃุตููุฉ (ูุญููุธุฉ)
        any(word in question_lower for word in ['ุนููุจุฉ', 'ุฌุฒุงุก', 'ุงุณุชุจุนุงุฏ', 'ุฎุตู']),
        any(word in question_lower for word in ['ุชุฃุฎุฑ', '130 ุซุงููุฉ', 'ุตูุฑ ููุงุท']),
        any(word in question_lower for word in ['penalty', 'punishment', 'disqualification']),
        ('what happens if' in question_lower),
        
        # ูุคุดุฑุงุช ุฌุฏูุฏุฉ ูุญุณูุฉ ูุฅุณูุงุท ุงูุฃุณูุญุฉ ูุงููุนุฏุงุช
        any(word in question_lower for word in ['dropped', 'drops', 'drop', 'falling', 'lose', 'lost']),
        any(word in question_lower for word in ['ูุณูุท', 'ุณูุท', 'ููุฏุงู', 'ุถูุงุน']),
        
        # ูุคุดุฑุงุช ุงูููุงุท ูุงูุนุฏู ุงุญุชุณุงุจ
        any(word in question_lower for word in ['no points', 'zero points', 'points deducted', 'points lost']),
        any(word in question_lower for word in ['ูุง ููุงุท', 'ูุง ุชุญุณุจ', 'ุนุฏู ุงุญุชุณุงุจ']),
        
        # ูุคุดุฑุงุช ุฎุทูุท ุงููุณุงุฑ (ุฅุฌุฑุงุฆูุฉ)
        any(word in question_lower for word in ['start line', 'finish line', 'starting line', 'between']),
        any(word in question_lower for word in ['before', 'after', 'during', 'crossing']),
        any(word in question_lower for word in ['ุฎุท ุงูุจุฏุงูุฉ', 'ุฎุท ุงูููุงูุฉ', 'ูุจู', 'ุจุนุฏ', 'ุฃุซูุงุก']),
        
        # ูุคุดุฑุงุช ุงูุญูุงุฏุซ ูุงูุทูุงุฑุฆ
        any(word in question_lower for word in ['fall', 'fell', 'accident', 'injury']),
        any(word in question_lower for word in ['ุณููุท', 'ููุน', 'ุญุงุฏุซ', 'ุฅุตุงุจุฉ']),
    ]
    
    # ูุคุดุฑุงุช ุฃุณุฆูุฉ ุงูุญุณุงุจ ุงููุฑูุจุฉ (ุฌุฏูุฏ - ููุฃุณุฆูุฉ ุงูุชู ุชุชุทูุจ ุญุณุงุจุงุช ูุชุนุฏุฏุฉ)
    complex_scoring_indicators = [
        # ูุคุดุฑุงุช ุงูุฃุฑูุงู ูุงููุณุงูุงุช
        bool(re.search(r'\d+\s*(meters?|ูุชุฑ)', question_lower)),
        bool(re.search(r'\d+\.\d+\s*(seconds?|ุซุงููุฉ)', question_lower)),
        
        # ูุคุดุฑุงุช ุงูุญุณุงุจ
        any(word in question_lower for word in ['determine', 'calculate', 'score', 'ุงุญุณุจ', 'ุญุฏุฏ ุงููุชูุฌุฉ']),
        any(word in question_lower for word in ['carried.*meters', 'ุญูู.*ูุชุฑ', 'ูุชุฏ.*ูุชุฑ']),
        
        # ูุคุดุฑุงุช ุงูุนูุงุตุฑ ุงููุชุนุฏุฏุฉ (ุฃูุซุฑ ูู ุนูุตุฑ ูุงุญุฏ ูู ุงูุณุคุงู)
        len([word for word in ['carried', 'dropped', 'time', 'seconds', 'meters', 'weapon', 'peg'] if word in question_lower]) >= 3,
        len([word for word in ['ุญูู', 'ุณูุท', 'ููุช', 'ุซุงููุฉ', 'ูุชุฑ', 'ุณูุงุญ', 'ูุชุฏ'] if word in question_lower]) >= 3,
        
        # ูุคุดุฑุงุช ุงูุณูุงู ุงููุฑูุจ
        ('after' in question_lower and 'before' in question_lower),
        ('crossing' in question_lower and any(word in question_lower for word in ['dropped', 'carried'])),
        ('finish line' in question_lower and any(word in question_lower for word in ['weapon', 'lance', 'sword'])),
    ]

    # ุญุณุงุจ ุงูููุงุท ููู ููุน (ูุธุงู ุฐูู ููุชุตููู ูุญุณู)
    scores = {
        'technical_specs': sum(technical_indicators),
        'timing_analysis': sum(timing_indicators), 
        'procedures': sum(procedure_indicators),
        'penalties': sum(penalty_indicators),
        'complex_scoring': sum(complex_scoring_indicators),
        'responsibilities': sum(responsibilities_indicators),
        'definitions': sum(definitions_indicators)  # ุงูุชุตููู ุงูุฌุฏูุฏ ููุชุนุฑููุงุช ูุงูููุงุนุฏ ุงูุนุงูุฉ
    }
    
    # ุฅุถุงูุฉ ููุงุท ุจูุงุก ุนูู ูุญุชูู ุงููุชุงุฆุฌ (ุชุญููู ุงูุณูุงู)
    if results:
        context_boost = analyze_results_context(results, question_lower)
        for category, boost in context_boost.items():
            if category in scores:
                scores[category] += boost
    
    # ุงุฎุชูุงุฑ ุงูููุน ุงูุฃุนูู ููุงุทุงู
    if max(scores.values()) > 0:
        return max(scores, key=scores.get)
    else:
        return 'general'


def analyze_results_context(results: List[Dict[str, Any]], question_lower: str) -> dict:
    """ุชุญููู ุณูุงู ุงููุชุงุฆุฌ ูุชุนุฒูุฒ ุงูุชุตููู (ูุณุงุนุฏ ููุชุตููู ุงูุฐูู)"""
    
    context_boost = {
        'technical_specs': 0,
        'timing_analysis': 0,
        'procedures': 0,
        'penalties': 0,
        'complex_scoring': 0,
        'responsibilities': 0,
        'definitions': 0  # ุงูุชุตููู ุงูุฌุฏูุฏ ููุชุนุฑููุงุช
    }
    
    # ุชุญููู ูุญุชูู ุงูููุงุฏ ุงููุณุชุฑุฌุนุฉ (ุฏูู ุชุนุฏูู ุงููุตูุต)
    for result in results[:3]:  # ููุท ุฃูู 3 ูุชุงุฆุฌ ููุณุฑุนุฉ
        title = result.get('title', '').lower()
        content = result.get('content', '')[:300].lower()  # ุฃูู 300 ุญุฑู ููุท
        
        # ูุคุดุฑุงุช ุชูููุฉ ูู ุงููุญุชูู
        if any(word in content for word in ['specifications', 'ููุงุตูุงุช', 'length', 'ุทูู']):
            context_boost['technical_specs'] += 1
            
        # ูุคุดุฑุงุช ุฅุฌุฑุงุฆูุฉ
        if any(word in title for word in ['ุงุณุชุฆูุงู', 'ูุฌูุฉ', 'appeal', 'committee']):
            context_boost['procedures'] += 1
            
        # ูุคุดุฑุงุช ุฒูููุฉ
        if any(word in content for word in ['ุณุงุนุฉ', 'ุฏูููุฉ', 'hour', 'minute']):
            context_boost['timing_analysis'] += 1
            
        # ูุคุดุฑุงุช ุนูุงุจูุฉ ูุญุณูุฉ (ุฃูุซุฑ ุดููููุฉ)
        penalty_content_words = [
            # ุงูุนุฑุจูุฉ
            'ุนููุจุฉ', 'ุงุณุชุจุนุงุฏ', 'ุฌุฒุงุก', 'ุฎุตู', 'ุณูุท', 'ูุณูุท', 'ููุฏุงู', 'ูุง ููุงุท', 'ุตูุฑ ููุงุท',
            'ุฎุท ุงูุจุฏุงูุฉ', 'ุฎุท ุงูููุงูุฉ', 'ูุจู', 'ุจุนุฏ', 'ุฃุซูุงุก',
            # ุงูุฅูุฌููุฒูุฉ
            'penalty', 'disqualification', 'dropped', 'drop', 'fell', 'fall', 'no points', 'zero points',
            'start line', 'finish line', 'before', 'after', 'between', 'during', 'lost', 'lose'
        ]
        if any(word in content.lower() for word in penalty_content_words):
            context_boost['penalties'] += 1
            
        # ูุคุดุฑุงุช ุฅุถุงููุฉ ููุนููุจุงุช (ุนูุฏ ูุฌูุฏ ููุงููู ุชุฃุฏูุจูุฉ)
        if any(word in title.lower() for word in ['breaking', 'loss', 'equipment', 'abuse', 'fall']):
            context_boost['penalties'] += 1
        
        # ูุคุดุฑุงุช ุงูุญุณุงุจ ุงููุฑูุจ (ุฌุฏูุฏ)
        complex_scoring_words = [
            # ูุคุดุฑุงุช ุงุญุชุณุงุจ ุงูููุงุท 
            'points', 'ููุงุท', 'awarding', 'ุงุญุชุณุงุจ', 'carrying', 'ุญูู',
            'timekeeping', 'ุฒูููุฉ', 'seconds', 'ุซุงููุฉ', '6.4', '7', '10',
            # ูุคุดุฑุงุช ุงูููุงุฏ ุงููุชุนุฏุฏุฉ ุงููุชุฑุงุจุทุฉ
            'article 143', 'article 144', 'ุงููุงุฏุฉ 143', 'ุงููุงุฏุฉ 144',
            'between start', 'finish line', 'ุฎุท ุงูุจุฏุงูุฉ', 'ุฎุท ุงูููุงูุฉ'
        ]
        if any(word in content for word in complex_scoring_words):
            context_boost['complex_scoring'] += 1
            
        # ุชุญุณูู ุฅุถุงูู ุนูุฏ ูุฌูุฏ ุนุฏุฉ ุนูุงุตุฑ ูุงููููุฉ
        if (any(word in content for word in ['points', 'ููุงุท']) and 
            any(word in content for word in ['penalty', 'ุนููุจุฉ']) and
            any(word in content for word in ['time', 'ููุช'])):
            context_boost['complex_scoring'] += 2
            
        # ูุคุดุฑุงุช ุงููุณุคูููุงุช ูุงูุงูุชุฒุงูุงุช (ุฌุฏูุฏ - ุฅุถุงูุฉ ุขููุฉ)
        responsibilities_content_words = [
            # ุงูุฃูุงู ูุงูุชุฃููู
            'safety', 'security', 'insurance', 'liability', 'ุฃูุงู', 'ุชุฃููู', 'ูุณุคูููุฉ',
            'medical', 'emergency', 'accident', 'injury', 'ุทุจู', 'ุทูุงุฑุฆ', 'ุญุงุฏุซ', 'ุฅุตุงุจุฉ',
            'coverage', 'protection', 'ุชุบุทูุฉ', 'ุญูุงูุฉ',
            # ุงูููุธูุงุช ูุงูุงูุชุฒุงูุงุช
            'hosting', 'federation', 'organizing committee', 'ุงุณุชุถุงูุฉ', 'ุงุชุญุงุฏ', 'ูุฌูุฉ ุชูุธูููุฉ',
            'responsible', 'obligation', 'duty', 'ูุณุคูู', 'ุงูุชุฒุงู', 'ูุงุฌุจ',
            # ุฃุฑูุงู ุงูููุงุฏ ุฐุงุช ุงูุตูุฉ
            '102'  # ุงููุงุฏุฉ 102 ุฎุงุตุฉ ุจุงููุณุคูููุงุช
        ]
        if any(word in content for word in responsibilities_content_words):
            context_boost['responsibilities'] += 1
            
        # ุชุญุณูู ุฅุถุงูู ูููุงุฏุฉ 102 ุชุญุฏูุฏุงู (ุฌุฏูุฏ)
        if ('102' in str(result.get('article_number', '')) or 
            'liabilities' in title or 'ูุณุคูููุงุช' in title):
            context_boost['responsibilities'] += 3  # ุฃููููุฉ ุนุงููุฉ
        
        # ูุคุดุฑุงุช ุงูุชุนุฑููุงุช ูุงูููุงุนุฏ ุงูุนุงูุฉ (ุฌุฏูุฏ - ุฅุถุงูุฉ ุขููุฉ)
        definitions_content_words = [
            # ุงูุชุนุฑููุงุช ุงูุนุงูุฉ
            'definition', 'refers to', 'means', 'ุชุนุฑูู', 'ูุนูู', 'ูุดูุฑ ุฅูู',
            'winner', 'winning', 'champion', 'ูุงุฆุฒ', 'ุจุทู', 'ููุฒ',
            # ูุคุดุฑุงุช ุงููุงุฏุฉ 103
            'athlete', 'team', 'event', 'competition', 'ุฑูุงุถู', 'ูุฑูู', 'ุญุฏุซ', 'ูุณุงุจูุฉ',
            'overall', 'total', 'points', 'scores', 'ุฅุฌูุงูู', 'ููู', 'ููุงุท',
            # ุฃุฑูุงู ุงูููุงุฏ ุฐุงุช ุงูุตูุฉ
            '103'  # ุงููุงุฏุฉ 103 ุฎุงุตุฉ ุจุงูุชุนุฑููุงุช
        ]
        if any(word in content for word in definitions_content_words):
            context_boost['definitions'] += 1
            
        # ุชุญุณูู ุฅุถุงูู ูููุงุฏุฉ 103 ุชุญุฏูุฏุงู (ุฌุฏูุฏ)
        if ('103' in str(result.get('article_number', '')) or 
            'definitions' in title or 'ุชุนุฑููุงุช' in title):
            context_boost['definitions'] += 3  # ุฃููููุฉ ุนุงููุฉ
        
        # ุชุญุณูู ุฎุงุต ูุฃุณุฆูุฉ ุงููุงุฆุฒูู (ุฌุฏูุฏ)
        if ('winner' in question_lower and 
            any(word in content for word in ['athlete', 'team', 'points', 'scores'])):
            context_boost['definitions'] += 2
    
    return context_boost


def format_technical_specs_response(question: str, results: List[Dict[str, Any]], language: str = 'arabic') -> str:
    """ุชูุณูู ูุฎุตุต ููุฃุณุฆูุฉ ุงูุชูููุฉ ูุงูููุงุตูุงุช ููุฃุณุฆูุฉ ุงูุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ (ูุญุณู - ุฅุถุงูุฉ ุขููุฉ)"""
    
    # Language-specific templates  
    if language == 'english':
        templates = {
            'tech_specs_title': '# Technical Specifications - Peg and Hole Dimensions',
            'article_prefix': 'Article',
            'tech_summary': '## Technical Summary', 
            'peg_specs': '**Different Peg Specifications:**',
            'hole_dimensions': '**Hole Dimensions:**',
            'note_label': '**Note:**',
            'references_checked': '**References Checked:**',
            'recommendation': '**Recommendation:**'
        }
    else:
        templates = {
            'tech_specs_title': '# ุงูููุงุตูุงุช ุงูุชูููุฉ - ุฃุจุนุงุฏ ุงูุฃูุชุงุฏ ูุงูุซููุจ',
            'article_prefix': 'ุงููุงุฏุฉ',
            'tech_summary': '## ุงูููุฎุต ุงูุชููู',
            'peg_specs': '**ููุงุตูุงุช ุงูุฃูุชุงุฏ ุงููุฎุชููุฉ:**',
            'hole_dimensions': '**ุฃุจุนุงุฏ ุงูุซููุจ:**',
            'note_label': '**ููุงุญุธุฉ:**',
            'references_checked': '**ุงููุฑุงุฌุน ุงูููุญูุตุฉ:**',
            'recommendation': '**ุงูุชูุตูุฉ:**'
        }
    
    # ูุญุต ุฎุงุต ููุฃุณุฆูุฉ ุงูุชู ูุง ุชูุฌุฏ ููุง ุฅุฌุงุจุฉ ูุญุฏุฏุฉ (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
    question_lower = question.lower()
    
    # ูุนุงูุฌุฉ ุฎุงุตุฉ ูุฃุณุฆูุฉ ุฃุจุนุงุฏ ุงูุฃูุชุงุฏ ูุงูุซููุจ (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
    is_peg_dimensions_question = (('peg hole' in question_lower and 'dimensions' in question_lower) or
                                 ('peg itself' in question_lower and 'dimensions' in question_lower) or
                                 ('peg' in question_lower and ('hole' in question_lower or 'size' in question_lower)))
    
    if is_peg_dimensions_question:
        # ุงูุจุญุซ ุนู ูุนูููุงุช ุงูุฃูุชุงุฏ ูู ุงูุฒูุงุฆุฏ (Appendices)
        peg_specs_found = []
        for result in results:
            content = result.get('content', '')
            title = result.get('title', '')
            
            # ุงูุจุญุซ ุนู ููุงุตูุงุช ุงูุฃูุชุงุฏ ูู ุงููุต
            if any(term in content.lower() for term in ['peg', 'hole', 'diameter', 'cm', 'specifications']):
                # ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ุงูุฃุจุนุงุฏ
                if '6cm' in content or '4cm' in content or '2.5cm' in content:
                    peg_specs_found.append({
                        'title': title,
                        'content': content,
                        'article_number': result.get('article_number', '')
                    })
        
        if peg_specs_found:
            response = f"{templates['tech_specs_title']}\n\n"
            response += "---\n\n"
            
            for spec in peg_specs_found:
                article_num = spec.get('article_number', '')
                title = spec.get('title', 'Technical Specifications')
                content = spec.get('content', '')
                
                response += f"## {title}"
                if article_num:
                    response += f" ({templates['article_prefix']} {article_num})"
                response += "\n\n"
                
                # ุงุณุชุฎุฑุงุฌ ูุชูุธูู ูุนูููุงุช ุงูุฃุจุนุงุฏ
                lines = content.split('\n')
                for line in lines:
                    if any(term in line.lower() for term in ['peg', 'hole', 'diameter', 'cm']) and line.strip():
                        response += f"โข {line.strip()}\n"
                
                response += "\n---\n\n"
            
            # ุฅุถุงูุฉ ููุฎุต ุชููู
            response += f"{templates['tech_summary']}\n\n"
            response += f"{templates['peg_specs']}\n"
            response += "- ุฃูุชุงุฏ ุจูุทุฑ 6 ุณู ูููุณุงุจูุงุช ุงูุฑุฆูุณูุฉ\n"
            response += "- ุฃูุชุงุฏ ุจูุทุฑ 4 ุณู ูููุณุงุจูุงุช ุงููุชูุณุทุฉ\n"
            response += "- ุฃูุชุงุฏ ุจูุทุฑ 2.5 ุณู ูููุณุงุจูุงุช ุงูุชุฎุตุตูุฉ\n\n"
            response += f"{templates['hole_dimensions']}\n"
            response += "- ูุฌุจ ุฃู ุชุชูุงุณุจ ูุน ุฃุจุนุงุฏ ุงูุฃูุชุงุฏ ุงููุญุฏุฏุฉ\n"
            response += "- ุชุญุฏุฏ ุงูููุงุตูุงุช ุงูุฏูููุฉ ุญุณุจ ููุน ุงููุณุงุจูุฉ\n\n"
            
            return response
        else:
            # ุฅุฐุง ูู ุชูุฌุฏ ูุนูููุงุช ูุญุฏุฏุฉ
            response = "**ููุงุญุธุฉ:** ูู ูุชู ุงูุนุซูุฑ ุนูู ูุนูููุงุช ูุญุฏุฏุฉ ุญูู ุฃุจุนุงุฏ ุงูุฃูุชุงุฏ ูุงูุซููุจ ูู ุงููุตูุต ุงููุชุงุญุฉ.\n\n"
            response += "**ุงููุฑุงุฌุน ุงูููุญูุตุฉ:**\n"
            for i, result in enumerate(results[:5]):
                title = result.get('title', 'ูุฑุฌุน ุบูุฑ ูุญุฏุฏ')
                article_num = result.get('article_number', '')
                if article_num:
                    response += f"- ุงููุงุฏุฉ {article_num}: {title}\n"
                else:
                    response += f"- {title}\n"
            response += "\n**ุงูุชูุตูุฉ:** ุงูุฑุฌูุน ุฅูู ุงูุฒูุงุฆุฏ ุงูุชูููุฉ (Technical Appendices) ููุญุตูู ุนูู ุงูููุงุตูุงุช ุงูุชูุตูููุฉ.\n"
            return response
    
    # ุชุญุฏูุฏ ุงูุฃุณุฆูุฉ ุนู ุงูุฃุนุถุงุก ุงูุฃุฌุงูุจ ุงูุชู ูุง ุชูุฌุฏ ููุง ุฅุฌุงุจุฉ
    is_foreign_members_question = ('foreign' in question_lower and 
                                 'members' in question_lower and 
                                 ('two' in question_lower or 'which' in question_lower))
    
    if is_foreign_members_question:
        # ูุญุต ุณุฑูุน ููุชุฃูุฏ ูู ุนุฏู ูุฌูุฏ ุฅุฌุงุจุฉ ูุญุฏุฏุฉ
        foreign_info_found = False
        for result in results:
            content = result.get('content', '')
            if ('foreign countries' in content.lower() and 
                'must' in content.lower() and 
                'jury' in content.lower()):
                foreign_info_found = True
                break
        
        # ุฅุฐุง ูู ุชูุฌุฏ ูุนูููุงุช ูุญุฏุฏุฉุ ุฃุนุทู ุฅุฌุงุจุฉ ูุฎุชุตุฑุฉ ููุงุถุญุฉ
        if not foreign_info_found:
            response = "**ุงูุฅุฌุงุจุฉ:** ูุง ุชูุฌุฏ ููุงุฏ ูู ููุงููู ุงูุงุชุญุงุฏ ุงูุฏููู ูุงูุชูุงุท ุงูุฃูุชุงุฏ ุชูุต ุนูู ูุฌูุจ ุฃู ูููู ุฃู ุนุถููู ูู ุฃุนุถุงุก ุงูุฌูุงุฒ ุงูููู ูู ุฏูู ุฃุฌูุจูุฉ.\n\n"
            response += "**ุงูุฎูุงุตุฉ:** ูุฐุง ุงููุชุทูุจ ุบูุฑ ููุฌูุฏ ูู ุงููุตูุต ุงููุงููููุฉ ุงููุชููุฑุฉ.\n\n"
            response += "**ุชูุณูุฑ:** ุงูุณุคุงู ูุฏ ูุดูุฑ ุฅูู ูุงุนุฏุฉ ูู ูุตุฏุฑ ูุงูููู ุขุฎุฑ ุฃู ูุธุงู ุฑูุงุถู ูุฎุชูู.\n\n"
            response += "**ุงููุฑุงุฌุน ุงูููุญูุตุฉ:**\n"
            reference_count = 0
            for article in results[:4]:
                article_num = article.get('article_number', '')
                title = article.get('title', '')
                if article_num and title:
                    response += f"- ุงููุงุฏุฉ {article_num}: {title}\n"
                    reference_count += 1
            if reference_count == 0:
                response += "- ุชู ูุญุต ุฌููุน ุงูููุงุฏ ุฐุงุช ุงูุตูุฉ ุจุงูุฌูุงุฒ ุงูููู ูุงููุฌุงู\n"
            return response
    
    # ุชุญุฏูุฏ ุงูุฃุณุฆูุฉ ุญูู ุดุฑูุท ุชุนุฏูู ุงูููุช (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ - ูุง ุชุคุซุฑ ุนูู ุงูููุฌูุฏ)
    is_time_conditions_question = (('under what conditions' in question_lower and 'time limit' in question_lower) or
                                   ('conditions' in question_lower and 'time' in question_lower and 'adjusted' in question_lower))
    
    if is_time_conditions_question:
        # ุงูุจุญุซ ุนู ูุนูููุงุช ุงูุงุณุชุซูุงุกุงุช ูู ุงููุงุฏุฉ 100
        exceptions_found = False
        for result in results:
            content = result.get('content', '')
            if ('except when the ITPF has authorized certain exceptions' in content or
                'authorized certain exceptions' in content):
                exceptions_found = True
                break
        
        if exceptions_found:
            response = "**ุงูุฅุฌุงุจุฉ:** ูููู ุชุนุฏูู ุงูุญุฏ ุงูุฒููู ููุฌุฑู **ููุท ุนูุฏูุง ูุตุฑุญ ุงูุงุชุญุงุฏ ุงูุฏููู ูุงูุชูุงุท ุงูุฃูุชุงุฏ (ITPF) ุจุฅุณุชุซูุงุกุงุช ูุนููุฉ**.\n\n"
            response += "**ุงููุฑุฌุน ุงููุงูููู:** ุงููุงุฏุฉ 100 (GENERAL) ุชูุต ุจูุถูุญ: *\"Therefore, the rules which follow must be respected, **except when the ITPF has authorized certain exceptions**\"*\n\n"
            response += "**ุงูุชูุณูุฑ:** ุงูุฃููุงุช ุงููุญุฏุฏุฉ ูู ุงููุณุงุจูุงุช (6.4 ุซุงููุฉ ูููุฑุฏูุ 7 ุซูุงูู ููุฃุฒูุงุฌ ูุงููุฑูุ 10 ุซูุงูู ููุชุชุงุจุน) ุซุงุจุชุฉ ููุง ูููู ุชุนุฏูููุง ุฅูุง ุจุชุตุฑูุญ ุฑุณูู ููุชูุจ ูู ุงูุงุชุญุงุฏ ุงูุฏููู.\n\n"
            response += "**ุงูุดุฑูุท ุงููุทููุจุฉ:**\n"
            response += "- ููุงููุฉ ููุชูุจุฉ ูู ุงูุงุชุญุงุฏ ุงูุฏููู ูุงูุชูุงุท ุงูุฃูุชุงุฏ (ITPF)\n"
            response += "- ูุจุฑุฑุงุช ูุงุถุญุฉ ููุชุนุฏูู\n"
            response += "- ุชุทุจูู ุงูุงุณุชุซูุงุก ุนูู ุฌููุน ุงููุชูุงูุณูู ุจุงูุชุณุงูู\n\n"
            response += "**ุงููุฑุงุฌุน:**\n- ุงููุงุฏุฉ 100: GENERAL\n- ุงูููุญู 9: ุจุฑูุงูุฌ ูุนุงููุงุช ุงูุชูุงุท ุงูุฃูุชุงุฏ\n"
            return response
    
    # ุชุญุฏูุฏ ุฅุฐุง ูุงู ุงูุณุคุงู ุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ (ูุญููุธ ููุง ูู)
    is_multiple_choice = ('a)' in question and 'b)' in question)
    
    # ุงุณุชุฎุฑุงุฌ ุงูุฎูุงุฑุงุช ุฅุฐุง ูุงู ุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ
    choices = []
    if is_multiple_choice:
        import re
        choice_pattern = r'([a-e])\)\s*([^)]*?)(?=[a-e]\)|$)'
        matches = re.findall(choice_pattern, question, re.IGNORECASE)
        choices = [(letter, text.strip()) for letter, text in matches]
    
    # ุชุตููู ุงูููุงุฏ ุญุณุจ ููุน ุงููุนูููุงุช ุงูุชูููุฉ
    specs_articles = []
    equipment_articles = []
    measurement_articles = []
    course_layout_articles = []  # ุฌุฏูุฏ ูููุณุงุฑุงุช ูุงููุณุงูุงุช
    video_recording_articles = []  # ุฌุฏูุฏ ุขูู - ูุชุทูุจุงุช ุงูุชุณุฌูู ุงููุฑุฆู
    jury_committee_articles = []  # ุฌุฏูุฏ ุขูู - ูุนูููุงุช ุงููุฌุงู ูุงูุฃุนุถุงุก
    reserve_athlete_articles = []  # ุฌุฏูุฏ ุขูู - ูุนูููุงุช ุงููุงุนุจูู ุงูุงุญุชูุงุท
    
    for result in results:
        content = result.get('content', '').lower()
        title = result.get('title', '').lower()
        
        # ุชูุธูู JSON ูู ุงููุญุชูู
        clean_content = clean_json_content(content)
        
        # ุงูุจุญุซ ุนู ูุชุทูุจุงุช ุงูุชุณุฌูู ุงููุฑุฆู (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ - ุฃููููุฉ ุนุงููุฉ)
        if (any(word in clean_content for word in ['video recordings', 'video', 'recording', 'camera', 'positions']) or 
            any(word in title for word in ['video', 'recording', 'general']) or
            ('video recordings' in content and 'positions' in content)):
            video_recording_articles.append(result)
        # ุงูุจุญุซ ุนู ูุนูููุงุช ุงููุงุนุจูู ุงูุงุญุชูุงุท (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
        elif (any(word in clean_content for word in ['substitute', 'substituting', 'reserve athlete', 'reserve', 'injured', 'ill']) or
              any(word in title for word in ['substitute', 'substituting', 'reserve']) or
              ('maximum of five' in content and 'athletes' in content) or
              ('only four (4) of the five (5)' in content)):
            reserve_athlete_articles.append(result)
        # ุงูุจุญุซ ุนู ูุนูููุงุช ุงููุฌุงู ูุงูุฃุนุถุงุก (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
        elif any(word in clean_content for word in ['jury', 'committee', 'members', 'ground jury']) or any(word in title for word in ['jury', 'committee', 'ground jury']):
            jury_committee_articles.append(result)
        # ุงูุจุญุซ ุนู ููุงุตูุงุช ุงููุณุงุฑุงุช ูุงููุณุงูุงุช (ุฃููููุฉ ุนุงููุฉ)
        elif any(word in clean_content for word in ['70 meters', '64.5', '65.5', 'starting line', 'course', 'track', 'relay']):
            course_layout_articles.append(result)
        elif any(word in title for word in ['course', 'track', 'layout', 'ูุณุงุฑ', 'ูุถูุงุฑ']):
            course_layout_articles.append(result)
        # ุงูุจุญุซ ุนู ุงูููุงุตูุงุช ุงูุชูููุฉ (ูุญููุธุฉ ููุง ูู)
        elif any(word in clean_content for word in ['cm', 'meter', 'length', 'size', 'minimum', 'maximum']):
            specs_articles.append(result)
        elif any(word in title for word in ['lance', 'sword', 'equipment', 'ุฑูุญ', 'ุณูู', 'ูุนุฏุงุช']):
            equipment_articles.append(result)
        elif any(word in clean_content for word in ['measurement', 'dimension', 'ููุงุณ', 'ููุงุณ']):
            measurement_articles.append(result)
    
    # ุจูุงุก ุงูุฅุฌุงุจุฉ
    if is_multiple_choice:
        response = "# ุฅุฌุงุจุฉ ุงูุณุคุงู ูุชุนุฏุฏ ุงูุฎูุงุฑุงุช\n\n"
    else:
        response = "# ุงูููุงุตูุงุช ุงูุชูููุฉ ุงููุทููุจุฉ\n\n"
    
    # ุงูุนุซูุฑ ุนูู ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ ููุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ
    correct_choice = None
    if is_multiple_choice and choices:
        response += "## ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ\n\n"
        
        # ุฏูุฌ ุงูููุงุฏ ุงูุชูููุฉ ูููุงุฏ ุงููุณุงุฑุงุช ููุจุญุซ ุงูุดุงูู
        all_technical_articles = course_layout_articles + specs_articles
        correct_choice = find_correct_choice(question, choices, all_technical_articles)
        if correct_choice:
            response += f"**ุงูุฅุฌุงุจุฉ: {correct_choice['letter']}) {correct_choice['text']}**\n\n"
            response += f"**ุงูุณุจุจ:** {correct_choice['reason']}\n\n"
        else:
            response += "**ุชุญุชุงุฌ ููุฑุงุฌุนุฉ ุงูููุงุฏ ุงููุงููููุฉ ุงูุชุงููุฉ ูุชุญุฏูุฏ ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ:**\n\n"
    
    # ุนุฑุถ ูุนูููุงุช ุงููุฌุงู ูุงูุฃุนุถุงุก ุฃููุงู (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
    if jury_committee_articles:
        response += "---\n\n## ูุนูููุงุช ุงูุฌูุงุฒ ุงูููู ูุงููุฌุงู\n\n"
        
        for i, article in enumerate(jury_committee_articles, 1):
            article_num = article.get('article_number', '')
            title = article.get('title', '')
            content = article.get('content', '')
            
            response += f"### {i}. {title} (ุงููุงุฏุฉ {article_num})\n\n"
            
            # ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ุงูุฃุนุถุงุก ุงููุญุฏุฏุฉ (ูุญุณู - ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
            jury_info = extract_jury_members_info(content)
            if jury_info:
                # ูุญุต ูุง ุฅุฐุง ูุงู ุงูุณุคุงู ุนู ุงูุฃุนุถุงุก ุงูุฃุฌุงูุจ ุชุญุฏูุฏุงู
                question_lower = question.lower()
                is_foreign_members_question = ('foreign' in question_lower and 
                                             'members' in question_lower and 
                                             ('two' in question_lower or 'which' in question_lower))
                
                # ุฅุฐุง ูุงู ุงูุณุคุงู ุนู ุงูุฃุนุถุงุก ุงูุฃุฌุงูุจ ููุง ุชูุฌุฏ ูุนูููุงุช ูุญุฏุฏุฉ
                if (is_foreign_members_question and 
                    not jury_info.get('_foreign_members_info_available', False)):
                    response += "โข **ูุชูุฌุฉ ุงูุจุญุซ:** ูุง ุชูุฌุฏ ูุนูููุงุช ูุญุฏุฏุฉ ูู ุงููุตูุต ุงููุงููููุฉ ุงููุชููุฑุฉ ุนู ุฃู ุฃุนุถุงุก ุฌูุงุฒ ููู ูุทููุจ ุฃู ูููููุง ูู ุฏูู ุฃุฌูุจูุฉ\n"
                    response += "โข **ุงููุนูููุงุช ุงููุชููุฑุฉ:** ูุนูููุงุช ุนุงูุฉ ุนู ุชุดููู ุงูุฌูุงุฒ ุงูููู ููุท\n\n"
                
                # ุนุฑุถ ุงููุนูููุงุช ุงููุชููุฑุฉ (ุชุตููุฉ ุงูุญููู ุงูุชูููุฉ)
                for key, value in jury_info.items():
                    if not key.startswith('_'):  # ุชุฌุงูู ุงูุญููู ุงูุชูููุฉ ุงููุคูุชุฉ
                        response += f"โข **{key}:** {value}\n"
                response += "\n"
            else:
                # ุนุฑุถ ุงููุญุชูู ุงูููุธู
                clean_content = clean_json_content(content)
                preview = clean_content[:400] if len(clean_content) > 400 else clean_content
                response += f"{preview}...\n\n" if len(clean_content) > 400 else f"{preview}\n\n"
    
    # ุนุฑุถ ูุชุทูุจุงุช ุงูุชุณุฌูู ุงููุฑุฆู ุฃููุงู (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
    if video_recording_articles:
        response += "---\n\n## ูุชุทูุจุงุช ุงูุชุณุฌูู ุงููุฑุฆู\n\n"
        
        for i, article in enumerate(video_recording_articles, 1):
            article_num = article.get('article_number', '')
            title = article.get('title', '')
            content = article.get('content', '')
            
            response += f"### {i}. {title} (ุงููุงุฏุฉ {article_num})\n\n"
            
            # ุงุณุชุฎุฑุงุฌ ููุงูุน ุงูุชุณุฌูู ุงููุญุฏุฏุฉ (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
            video_positions = extract_video_recording_positions(content)
            if video_positions:
                response += "**ุงูููุงูุน ุงูุฅุฌุจุงุฑูุฉ ููุชุณุฌูู:**\n\n"
                for position in video_positions:
                    response += f"โข **{position['name']}** - {position['purpose']}\n"
                response += "\n"
            else:
                # ุนุฑุถ ุงููุญุชูู ุงูููุธู
                clean_content = clean_json_content(content)
                preview = clean_content[:400] if len(clean_content) > 400 else clean_content
                response += f"{preview}...\n\n" if len(clean_content) > 400 else f"{preview}\n\n"
    
    # ุนุฑุถ ูุนูููุงุช ุงููุงุนุจูู ุงูุงุญุชูุงุท (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
    if reserve_athlete_articles:
        response += "---\n\n## ููุงููู ุงููุงุนุจูู ุงูุงุญุชูุงุท ูุงูุงุณุชุจุฏุงู\n\n"
        
        for i, article in enumerate(reserve_athlete_articles, 1):
            article_num = article.get('article_number', '')
            title = article.get('title', '')
            content = article.get('content', '')
            
            response += f"### {i}. {title} (ุงููุงุฏุฉ {article_num})\n\n"
            
            # ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ุงููุงุนุจูู ุงูุงุญุชูุงุท ุงููุญุฏุฏุฉ
            reserve_info = extract_reserve_athlete_info(content)
            if reserve_info:
                for key, value in reserve_info.items():
                    response += f"โข **{key}:** {value}\n"
                response += "\n"
            else:
                # ุนุฑุถ ุงููุญุชูู ุงูููุธู
                clean_content = clean_json_content(content)
                preview = clean_content[:400] if len(clean_content) > 400 else clean_content
                response += f"{preview}...\n\n" if len(clean_content) > 400 else f"{preview}\n\n"
    
    # ุนุฑุถ ุงูููุงุตูุงุช ุงูุชูููุฉ ุงููุณุชุฎุฑุฌุฉ (ุดุงูู ุงููุณุงุฑุงุช)
    if specs_articles or course_layout_articles:
        response += "---\n\n## ุงูููุงุตูุงุช ุงูุชูููุฉ ุงููุญุฏุฏุฉ\n\n"
        
        # ุนุฑุถ ููุงุฏ ุงููุณุงุฑุงุช ูุงููุณุงูุงุช ุฃููุงู (ุฅุฐุง ูุฌุฏุช)
        if course_layout_articles:
            for i, article in enumerate(course_layout_articles, 1):
                article_num = article.get('article_number', '')
                title = article.get('title', '')
                content = article.get('content', '')
                
                response += f"### {i}. {title} (ุงููุงุฏุฉ {article_num})\n\n"
                
                # ุงุณุชุฎุฑุงุฌ ูุณุงูุงุช ุงููุณุงุฑุงุช ุงููุญุฏุฏุฉ
                measurements = extract_measurements_from_content(content)
                if measurements:
                    for measurement in measurements:
                        if measurement.get('type') == 'track_distance':
                            response += f"- **ูุณุงูุฉ ุงููุณุงุฑ:** {measurement['value']} {measurement['unit']} ูู ุฎุท ุงูุจุฏุงูุฉ\n"
                        else:
                            response += f"- **{measurement['item']}:** {measurement['value']} {measurement['unit']}\n"
                    response += "\n"
                else:
                    # ุฅุฐุง ูู ุชุณุชุฎุฑุฌ ุงูููุงุณุงุชุ ุงุนุฑุถ ุงููุญุชูู ูุจุงุดุฑุฉ
                    clean_content = clean_json_content(content)
                    preview = clean_content[:400] if len(clean_content) > 400 else clean_content
                    response += f"{preview}...\n\n" if len(clean_content) > 400 else f"{preview}\n\n"
        
        # ุนุฑุถ ุงูููุงุฏ ุงูุชูููุฉ ุงูุนุงุฏูุฉ (ูุญููุธุฉ ููุง ูู)
        for i, article in enumerate(specs_articles, len(course_layout_articles) + 1):
            article_num = article.get('article_number', '')
            title = article.get('title', '')
            content = article.get('content', '')
            
            response += f"### {i}. {title} (ุงููุงุฏุฉ {article_num})\n\n"
            
            # ุงุณุชุฎุฑุงุฌ ุงูููุงููุณ ุงููุญุฏุฏุฉ
            measurements = extract_measurements_from_content(content)
            if measurements:
                for measurement in measurements:
                    response += f"- **{measurement['item']}:** {measurement['value']} {measurement['unit']}\n"
                response += "\n"
            else:
                # ุนุฑุถ ูุญุชูู ููุธู ุฅุฐุง ูู ุชูุฌุฏ ููุงููุณ ูุญุฏุฏุฉ
                clean_content = clean_json_content(content)[:300]
                response += f"{clean_content}...\n\n"
    
    # ูุนูููุงุช ุฅุถุงููุฉ ูู ููุงุฏ ุงููุนุฏุงุช
    if equipment_articles:
        response += "---\n\n## ูุนูููุงุช ุงููุนุฏุงุช ุฐุงุช ุงูุตูุฉ\n\n"
        
        for article in equipment_articles[:2]:
            article_num = article.get('article_number', '')
            title = article.get('title', '')
            content = clean_json_content(article.get('content', ''))
            
            response += f"**ุงููุงุฏุฉ {article_num} - {title}:**\n"
            response += f"{content[:200]}...\n\n"
    
    # ุงูุฎูุงุตุฉ ุงูุชูููุฉ (ูุญุณู - ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
    response += "---\n\n## ุงูุฎูุงุตุฉ ุงูุชูููุฉ\n\n"
    
    # ูุญุต ุฎุงุต ููุฃุณุฆูุฉ ุนู ุงูุฃุนุถุงุก ุงูุฃุฌุงูุจ (ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
    question_lower = question.lower()
    is_foreign_members_question = ('foreign' in question_lower and 
                                 'members' in question_lower and 
                                 ('two' in question_lower or 'which' in question_lower))
    
    if is_foreign_members_question:
        # ูุญุต ูุง ุฅุฐุง ุชู ุงูุนุซูุฑ ุนูู ูุนูููุงุช ูุญุฏุฏุฉ ุนู ุงูุฃุนุถุงุก ุงูุฃุฌุงูุจ
        foreign_info_found = False
        for article in jury_committee_articles:
            content = article.get('content', '')
            jury_info = extract_jury_members_info(content)
            if jury_info.get('_foreign_members_info_available', False):
                foreign_info_found = True
                break
        
        if not foreign_info_found:
            response += "**ูุชูุฌุฉ ุงูุจุญุซ ุงูุดุงูู:** ูุง ุชูุฌุฏ ููุงุฏ ูุงููููุฉ ูู ููุงููู ุงูุงุชุญุงุฏ ุงูุฏููู ูุงูุชูุงุท ุงูุฃูุชุงุฏ ุชูุต ุนูู ูุฌูุจ ุฃู ูููู ุฃู ูู ุฃุนุถุงุก ุงูุฌูุงุฒ ุงูููู ูู ุฏูู ุฃุฌูุจูุฉ.\n\n"
            response += "**ุชูุณูุฑ ุงููุชูุฌุฉ:** ูุฐุง ุงูุณุคุงู ูุฏ ูุดูุฑ ุฅูู ูุงุนุฏุฉ ุบูุฑ ููุฌูุฏุฉ ูู ุงููุตูุต ุงููุงููููุฉ ุงููุชููุฑุฉุ ุฃู ูุฏ ุชููู ูู ูุตุฏุฑ ูุงูููู ุขุฎุฑ.\n\n"
        else:
            response += f"ุชู ุงูุนุซูุฑ ุนูู ูุนูููุงุช ูุญุฏุฏุฉ ุนู ูุชุทูุจุงุช ุงูุฃุนุถุงุก ุงูุฃุฌุงูุจ ูู ุงูุฌูุงุฒ ุงูููู.\n"
    elif is_multiple_choice and correct_choice:
        response += f"ุงูุณุคุงู ูุชุนูู ุจุงูููุงุตูุงุช ุงูุชูููุฉ ุงููุญุฏุฏุฉ ูู ุงููุธุงู ุงููุงูููู. ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ ูุจููุฉ ุนูู ุงููุตูุต ุงูุฑุณููุฉ ุงููุนุชูุฏุฉ.\n"
    else:
        # ุนุฏ ุงูููุงุฏ ุงูุชูููุฉ ุงูุฅุฌูุงููุฉ
        total_articles = len(specs_articles + equipment_articles + course_layout_articles + video_recording_articles + jury_committee_articles)
        response += f"ุชู ุงูุนุซูุฑ ุนูู {total_articles} ูุงุฏุฉ ุชุญุชูู ุนูู ููุงุตูุงุช ุชูููุฉ ุฐุงุช ุตูุฉ ุจุงูุงุณุชูุณุงุฑ.\n"
    
    # ุงููุฑุงุฌุน (ูุญุณู)
    response += "\n**ุงููุฑุงุฌุน:**\n"
    all_articles = specs_articles + equipment_articles + course_layout_articles + video_recording_articles + jury_committee_articles
    reference_count = 0
    for article in all_articles:
        if reference_count >= 4:  # ุงูุญุฏ ุงูุฃูุตู 4 ูุฑุงุฌุน
            break
        article_num = article.get('article_number', '')
        title = article.get('title', '')
        if article_num and title:  # ุงูุชุฃูุฏ ูู ูุฌูุฏ ุงููุนูููุงุช
            response += f"- ุงููุงุฏุฉ {article_num}: {title}\n"
            reference_count += 1
    
    # ุฅุถุงูุฉ ุชูุจูู ูู ุญุงู ุนุฏู ูุฌูุฏ ูุฑุงุฌุน ูุงููุฉ ููุฃุณุฆูุฉ ุนู ุงูุฃุนุถุงุก ุงูุฃุฌุงูุจ
    if is_foreign_members_question and reference_count == 0:
        response += "- ูุง ุชูุฌุฏ ููุงุฏ ูุงููููุฉ ูุญุฏุฏุฉ ุชุฌูุจ ุนูู ูุฐุง ุงูุณุคุงู\n"
    
    return response


def find_correct_choice(question: str, choices: List[tuple], specs_articles: List[Dict]) -> dict:
    """ุงูุนุซูุฑ ุนูู ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ ูู ุฃุณุฆูุฉ ุงูุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ"""
    
    # ุงุณุชุฎุฑุงุฌ ุงูููุถูุน ุงูุฑุฆูุณู ูู ุงูุณุคุงู
    question_lower = question.lower()
    subject_keywords = []
    
    if 'lance' in question_lower:
        subject_keywords.extend(['lance', 'ุฑูุญ'])
    if 'ring' in question_lower:
        subject_keywords.extend(['ring', 'ุญููุฉ'])
    if 'peg' in question_lower:
        subject_keywords.extend(['peg', 'ูุชุฏ'])
    if 'minimum' in question_lower:
        subject_keywords.append('minimum')
    if 'length' in question_lower:
        subject_keywords.extend(['length', 'ุทูู'])
    
    # ุงูุจุญุซ ูู ุงูููุงุฏ ุงููุชุงุญุฉ ูุฅูุฌุงุฏ ุฃูุถู ูุทุงุจูุฉ
    best_match = None
    best_difference = float('inf')
    
    for article in specs_articles:
        content = clean_json_content(article.get('content', ''))
        
        # ุงูุจุญุซ ุนู ุงูููุงููุณ ูู ุงููุญุชูู
        measurements = extract_measurements_from_content(article.get('content', ''))
        
        for measurement in measurements:
            measurement_type = measurement.get('type', 'measurement')  # ุงูุญุตูู ุนูู ููุน ุงูููุงุณ
            
            # ูุนุงูุฌุฉ ุงูุฃุนุฏุงุฏ (runs, athletes, etc.)
            if measurement_type == 'count':
                # ุงูุจุญุซ ุนู ูุทุงุจูุฉ ูู ุฃุณุฆูุฉ ุงูุนุฏุฏ
                if any(word in question_lower for word in ['runs', 'maximum', 'per day', 'athletes', 'horses']):
                    for letter, choice_text in choices:
                        choice_value = extract_number_from_text(choice_text)
                        if choice_value:
                            # ูุทุงุจูุฉ ูุจุงุดุฑุฉ ููุฃุนุฏุงุฏ
                            difference = abs(measurement['value'] - choice_value)
                            if difference < 1 and difference < best_difference:  # ูุทุงุจูุฉ ุฏูููุฉ ููุฃุนุฏุงุฏ
                                best_difference = difference
                                best_match = {
                                    'letter': letter,
                                    'text': choice_text,
                                    'reason': f"ูููุงู ูููุงุฏุฉ {article.get('article_number', '')}: {measurement['item']} = {measurement['value']} {measurement['unit']}"
                                }
            
            # ูุนุงูุฌุฉ ูุณุงูุงุช ุงููุณุงุฑุงุช (track_distance - ุฌุฏูุฏ)
            elif measurement_type == 'track_distance':
                # ุงูุจุญุซ ุนู ูุทุงุจูุฉ ูู ุฃุณุฆูุฉ ุงููุณุงูุงุช ูุงููุณุงุฑุงุช
                if any(word in question_lower for word in ['placed at', 'distance from', 'meters from', 'starting line', 'relay', 'course']):
                    for letter, choice_text in choices:
                        choice_value = extract_number_from_text(choice_text)
                        if choice_value:
                            # ูุทุงุจูุฉ ูุจุงุดุฑุฉ ูููุณุงูุงุช (ููุณ ุงููุญุฏุฉ)
                            difference = abs(measurement['value'] - choice_value)
                            if difference < 1 and difference < best_difference:  # ูุทุงุจูุฉ ุฏูููุฉ ูููุณุงูุงุช
                                best_difference = difference
                                best_match = {
                                    'letter': letter,
                                    'text': choice_text,
                                    'reason': f"ูููุงู ูููุงุฏุฉ {article.get('article_number', '')}: ุงููุณุงูุฉ ูู ุฎุท ุงูุจุฏุงูุฉ = {measurement['value']} {measurement['unit']}"
                                }
            
            # ูุนุงูุฌุฉ ุงูููุงุณุงุช ุงููุงุฏูุฉ (cm, meters, etc.)
            elif measurement_type == 'measurement':
                # ุชุญููู ุงูููู ุฅูู ูุญุฏุฉ ููุญุฏุฉ (ุณู)
                value_in_cm = convert_to_cm(measurement['value'], measurement['unit'])
                
                # ููุงุฑูุฉ ูุน ุงูุฎูุงุฑุงุช ุงููุชุงุญุฉ ูุงูุนุซูุฑ ุนูู ุฃูุถู ูุทุงุจูุฉ
                for letter, choice_text in choices:
                    choice_value = extract_number_from_text(choice_text)
                    choice_unit = extract_unit_from_text(choice_text)
                    
                    if choice_value:
                        choice_in_cm = convert_to_cm(choice_value, choice_unit)
                        difference = abs(value_in_cm - choice_in_cm)
                        
                        # ุฅุฐุง ูุงู ูุฐุง ุฃูุฑุจ ูุทุงุจูุฉ ุถูู ุงููุงูุด ุงููุณููุญ
                        if difference < 10 and difference < best_difference:  # ูุงูุด ุฎุทุฃ 10 ุณู ููููุงุณุงุช
                            best_difference = difference
                            best_match = {
                                'letter': letter,
                                'text': choice_text,
                                'reason': f"ูููุงู ูููุงุฏุฉ {article.get('article_number', '')}: {measurement['item']} = {measurement['value']} {measurement['unit']} (ูุฑู {difference:.1f} ุณู)"
                            }
    
    return best_match


def extract_measurements_from_content(content: str) -> List[dict]:
    """ุงุณุชุฎุฑุงุฌ ุงูููุงููุณ ูุงูุฃุนุฏุงุฏ ูู ูุญุชูู ุงููุงุฏุฉ ูุน ุงูุชูููุฒ ุจูู ุงูุฃููุงุน"""
    measurements = []
    
    # ุชูุธูู ุงููุญุชูู
    clean_content = clean_json_content(content)
    
    import re
    
    # 1. ุงุณุชุฎุฑุงุฌ ุงูุฃุนุฏุงุฏ/ุงูุฌููุงุช (ุฃููููุฉ ุนุงููุฉ ููุชูููุฒ ุงูุตุญูุญ)
    count_patterns = [
        r'(\d+)\s*(runs?)\s*determines',  # "6 runs determines"
        r'total\s*(?:score\s*of\s*)?(\d+)\s*(runs?)',  # "Total Score of 6 runs"
        r'(\d+)\s*(runs?)\s*per\s*day',  # "6 runs per day"
        r'maximum\s*(?:of\s*)?(\d+)\s*(runs?)',  # "maximum of 6 runs"
        r'(\d+)\s*(athletes?|horses?|teams?)\s*per',  # "5 athletes per team"
        r'(\d+)\s*(competitions?|events?)\s*per'  # "10 competitions per event"
    ]
    
    for pattern in count_patterns:
        matches = re.findall(pattern, clean_content, re.IGNORECASE)
        for match in matches:
            value, unit = match
            measurements.append({
                'item': f'count_{unit.lower()}',  # ูููุฒ ููุฃุนุฏุงุฏ
                'value': float(value),
                'unit': unit.lower(),
                'type': 'count'  # ููุน ุงูุนูุตุฑ
            })
    
    # 2. ุงุณุชุฎุฑุงุฌ ูุณุงูุงุช ุงููุณุงุฑุงุช ูุงูุฏูุฑุงุช (ุฌุฏูุฏ - ุฃููููุฉ ุนุงููุฉ)
    track_distance_patterns = [
        r'\((\d+(?:\.\d+)?)\)\s*(meters?|m)\s*(?:from|before)',  # "(70) meters from" - ุฃูุซุฑ ุฏูุฉ
        r'pegs\s*are\s*(?:\w+\s*)?\((\d+(?:\.\d+)?)\)\s*(meters?)\s*from\s*(?:the\s*)?start\s*line',  # "pegs are seventy (70) meters from start line"
        r'time\s*starts\s*(?:\w+\s*)?\((\d+(?:\.\d+)?)\)\s*(meters?)\s*before',  # "Time starts seventy (70) meters before"
        r'(\d+(?:\.\d+)?)\s*(meters?|m)\s*from\s*(?:the\s*)?(?:start|starting)\s*line',  # "70 meters from starting line"
        r'(?:distance|placed)\s*(?:at\s*)?(\d+(?:\.\d+)?)\s*(meters?|m)',  # "distance 70 meters"
        r'(?:ุงูุฃูุชุงุฏ|ุงููุชุฏ)\s*(?:ุชูุถุน|ุชููุถุน)\s*(?:ุนูู\s*(?:ูุณุงูุฉ\s*)?)?(\d+(?:\.\d+)?)\s*(ูุชุฑ|ุฃูุชุงุฑ)',  # Arabic patterns
    ]
    
    for pattern in track_distance_patterns:
        matches = re.findall(pattern, clean_content, re.IGNORECASE)
        for match in matches:
            value, unit = match
            measurements.append({
                'item': 'track_distance',  # ูููุฒ ููุณุงูุงุช ุงููุณุงุฑ
                'value': float(value),
                'unit': unit.lower(),
                'type': 'track_distance'  # ููุน ุฎุงุต ูููุณุงุฑุงุช
            })
    
    # 3. ุงุณุชุฎุฑุงุฌ ุงูููุงุณุงุช ุงููุงุฏูุฉ (measurements - ูุญููุธุฉ ููุง ูู)
    measurement_patterns = [
        r'(\w+\s*(?:length|size|minimum|maximum|thickness|diameter|width|height))\s*:?\s*(\d+(?:\.\d+)?)\s*(cm|meter|metres?|meters?|mm|m|inch)',
        r'(\d+(?:\.\d+)?)\s*(cm|meter|metres?|meters?|mm|m|inch)(?!\s*(?:runs?|athletes?|horses?))',  # ุชุฌูุจ ุงูุฎูุท ูุน ุงูุฃุนุฏุงุฏ
        r'(\w+)\s*(?:is|are|must be)\s*(\d+(?:\.\d+)?)\s*(cm|meter|metres?|meters?|mm|m|inch)'
    ]
    
    for pattern in measurement_patterns:
        matches = re.findall(pattern, clean_content, re.IGNORECASE)
        for match in matches:
            if len(match) == 3:
                item, value, unit = match
                measurements.append({
                    'item': item.strip(),
                    'value': float(value),
                    'unit': unit.lower(),
                    'type': 'measurement'  # ููุน ุงูุนูุตุฑ
                })
            elif len(match) == 2:  # ุฑูู ููุญุฏุฉ ููุท
                value, unit = match
                measurements.append({
                    'item': 'measurement',
                    'value': float(value),
                    'unit': unit.lower(),
                    'type': 'measurement'  # ููุน ุงูุนูุตุฑ
                })
    
    return measurements


def convert_to_cm(value: float, unit: str) -> float:
    """ุชุญููู ุงูููู ุฅูู ุณูุชููุชุฑ"""
    unit_lower = unit.lower()
    
    if unit_lower in ['m', 'meter', 'metres', 'meters']:
        return value * 100
    elif unit_lower == 'cm':
        return value
    else:
        return value  # ุงูุชุฑุงุถูุงู ุณูุชููุชุฑ


def extract_number_from_text(text: str) -> float:
    """ุงุณุชุฎุฑุงุฌ ุงูุฑูู ูู ุงููุต ูุน ุฏุนู ุงูููุงููุณ ุงููุฑูุจุฉ ูุซู '2 meters and 20 cm'"""
    import re
    
    # ุงูุชุญูู ูู ูุฌูุฏ ููุงููุณ ูุฑูุจุฉ ูุซู "2 meters and 20 cm"
    compound_pattern = r'(\d+(?:\.\d+)?)\s*(meters?|m)\s+and\s+(\d+(?:\.\d+)?)\s*(cm|centimeters?)'
    compound_match = re.search(compound_pattern, text, re.IGNORECASE)
    
    if compound_match:
        # ุชุญููู ุฅูู ุณูุชููุชุฑ
        meters_value = float(compound_match.group(1))
        cm_value = float(compound_match.group(3))
        total_cm = (meters_value * 100) + cm_value
        return total_cm / 100  # ุฅุฑุฌุงุน ููููุฉ ุจุงููุชุฑ ููุชูุงูู
    
    # ุงูุจุญุซ ุนู ุงูุฃุฑูุงู ุงูุนุงุฏูุฉ
    numbers = re.findall(r'(\d+(?:\.\d+)?)', text)
    if numbers:
        return float(numbers[0])
    
    return None


def extract_unit_from_text(text: str) -> str:
    """ุงุณุชุฎุฑุงุฌ ุงููุญุฏุฉ ูู ุงููุต ูุน ุฏุนู ุงูููุงููุณ ุงููุฑูุจุฉ"""
    import re
    
    # ุงูุชุญูู ูู ุงูููุงููุณ ุงููุฑูุจุฉ ุฃููุงู
    compound_pattern = r'(\d+(?:\.\d+)?)\s*(meters?|m)\s+and\s+(\d+(?:\.\d+)?)\s*(cm|centimeters?)'
    if re.search(compound_pattern, text, re.IGNORECASE):
        return 'meter'  # ููููุงููุณ ุงููุฑูุจุฉ ูุนูุฏ ูุชุฑ ูุฃู extract_number_from_text ูุญุณุจ ุงููููุฉ ุงูุฅุฌูุงููุฉ ุจุงููุชุฑ
    
    # ุงูุจุญุซ ุนู ุงููุญุฏุงุช ุงูุนุงุฏูุฉ
    units = re.findall(r'\b(cm|meters?|metres?|meter|m)\b', text, re.IGNORECASE)
    if units:
        return units[0].lower()
    
    return 'cm'  # ุงูุชุฑุงุถูุงู ุณูุชููุชุฑ


def format_timing_analysis_response(question: str, results: List[Dict[str, Any]], language: str = 'arabic') -> str:
    """ุชูุณูู ูุฎุตุต ููุฃุณุฆูุฉ ุงูุฒูููุฉ ุงููุนูุฏุฉ"""
    
    # ุงุณุชุฎุฑุงุฌ ุงููุตูุต ุงูุฒูููุฉ ุงููููุฉ
    timing_articles = []
    appeal_articles = []
    schedule_articles = []
    
    for result in results:
        content = result.get('content', '').lower()
        article_num = result.get('article_number', '')
        
        # ุชุตููู ุงูููุงุฏ ุญุณุจ ุงููุญุชูู
        if any(word in content for word in ['ุณุงุนุฉ', 'ุฏูููุฉ', 'ูุฏุฉ ุงูุจุทููุฉ', 'ุฅุนูุงู ุงููุชุงุฆุฌ']):
            timing_articles.append(result)
        if any(word in content for word in ['ุงุณุชุฆูุงู', 'ุงุนุชุฑุงุถ', 'ูุฌูุฉ ุงูุงุณุชุฆูุงู']):
            appeal_articles.append(result)
        if 'ููุญู' in str(article_num) and any(word in content for word in ['ููู', 'ุจุฑูุงูุฌ']):
            schedule_articles.append(result)
    
    response = "# ุงูุชุญููู ุงููุงูููู ูููุฑุงุญู ุงูุฒูููุฉ ูู ููุงููู ุงูุชูุงุท ุงูุฃูุชุงุฏ\n\n"
    
    # ุชุญุฏูุฏ ูุฌูุฏ ุชูุงูุถ ุธุงูุฑู
    if len(timing_articles) >= 2 and len(appeal_articles) >= 1:
        response += "## ุงููุดููุฉ ุงููุงููููุฉ ุงูุธุงูุฑูุฉ\n\n"
        response += "ุนูุฏ ูุฑุงุฌุนุฉ ุงููุตูุต ุงููุงููููุฉ ููุงุชุญุงุฏ ุงูุฏููู ูุงูุชูุงุท ุงูุฃูุชุงุฏุ ูุฌุฏ ูุง ูุจุฏู ูุชูุงูุถ ูู ุงูุฃููุงุช ุงููุญุฏุฏุฉ.\n\n"
        
        response += "### ุงููุตูุต ุงููุงููููุฉ ุฐุงุช ุงูุตูุฉ\n\n"
        
        # ุนุฑุถ ุงููุตูุต ุงููุชุถุงุฑุจุฉ
        for article in timing_articles[:3]:
            article_num = article.get('article_number', '')
            title = article.get('title', '')
            content = article.get('content', '')
            
            # ุงุณุชุฎุฑุงุฌ ุงูุฌููุฉ ุงูุฒูููุฉ ุงููููุฉ
            time_sentence = extract_time_specific_sentence(content)
            
            response += f"**ุงููุงุฏุฉ {article_num} - {title}:**\n"
            response += f'"{time_sentence}"\n\n'
        
        # ุงูุชุญููู ุงููุงูููู ุงูุณููู
        response += "---\n\n## ุงูุชุญููู ุงููุงูููู ุงูุณููู\n\n"
        response += "### ุงููุจุฏุฃ ุงูุฃุณุงุณู ูู ุงูุชูุณูุฑ ุงููุงูููู\n"
        response += "ุงููุตูุต ุงููุงููููุฉ ูุฌุจ ุฃู ุชููุณุฑ ุจุทุฑููุฉ ุชุฌุนููุง ูุชูุงุณูุฉ ููุชูุงููุฉุ ูููุณ ูุชูุงูุถุฉ.\n\n"
        
        # ุงูุฌุฏูู ุงูุฒููู ุงููุชุฏุฑุฌ
        response += "### ุงูุฌุฏูู ุงูุฒููู ุงููุชุฏุฑุฌ\n\n"
        response += "**ููุทุฉ ุงูุจุฏุงูุฉ: ุฅุนูุงู ุงููุชุงุฆุฌ ุงูููุงุฆูุฉ**\n\n"
        
        response += "**ุงููุฑุญูุฉ ุงูุฃููู (ูู ุงูุฏูููุฉ 0 ุฅูู ุงูุฏูููุฉ 30):**\n"
        response += "- ุชูุฏูู ุงูุงุนุชุฑุงุถุงุช ูุณููุญ\n"
        response += "- ุงูุจุทููุฉ ูุนููุฉ ูุงููููุงู\n"  
        response += "- ุงููุชุงุฆุฌ ูุงุจูุฉ ููุชุบููุฑ\n\n"
        
        response += "**ุงููุฑุญูุฉ ุงูุซุงููุฉ (ูู ุงูุฏูููุฉ 30 ุฅูู ุงูุฏูููุฉ 60):**\n"
        response += "- ุชูุฏูู ุงุนุชุฑุงุถุงุช ุฌุฏูุฏุฉ ูุบูู\n"
        response += "- ุงูุจุช ูู ุงูุงุนุชุฑุงุถุงุช ุงูููุฏูุฉ ุณุงุจูุงู\n"
        response += "- ุงูุจุทููุฉ ููุชููุฉ ุฑุณููุงู (ุฅุฐุง ูู ุชูุฌุฏ ุงุนุชุฑุงุถุงุช)\n\n"
        
        response += "**ููุงูุฉ ุงูุตูุงุญูุงุช (ุจุนุฏ 60 ุฏูููุฉ):**\n"
        response += "ุงูุชูุงุก ุฌููุน ุงูุตูุงุญูุงุช ููุงุฆูุงู\n\n"
        
        # ุงูุฎูุงุตุฉ ุงููุงููููุฉ
        response += "---\n\n## ุงูุฎูุงุตุฉ ุงููุงููููุฉ\n\n"
        response += "ุงููุตูุต ุชุนูู ูู ุชูุงุบู ูุซุงูู:\n\n"
        response += "**30 ุฏูููุฉ ุงูุฃููู:** ูุชุฑุฉ ุชูุฏูู ุงูุงุนุชุฑุงุถุงุช ูุฅููุงููุฉ ุงูุชูุงุก ุงูุจุทููุฉ\n"
        response += "**30 ุฏูููุฉ ุงูุซุงููุฉ:** ูุชุฑุฉ ุงูุจุช ูู ุงูุงุนุชุฑุงุถุงุช ุชุญุช ุฅุดุฑุงู ุงูุญูุงู\n"
        response += "**60 ุฏูููุฉ ุฅุฌูุงููุฉ:** ุงูุญุฏ ุงูุฃูุตู ุงููุทูู ูุฃู ุชุฏุฎู ูุงูููู\n\n"
    
    else:
        # ุฅุฌุงุจุฉ ูุจุณุทุฉ ุฅุฐุง ูู ุชูุฌุฏ ููุงุฏ ูุงููุฉ
        response += "## ุงูุฌุฏูู ุงูุฒููู ููุจุทููุฉ\n\n"
        
        if schedule_articles:
            response += "**ุจุฑูุงูุฌ ุงูุจุทููุฉ:**\n"
            for article in schedule_articles:
                content = clean_json_content(article.get('content', ''))
                response += f"- {content[:200]}...\n"
        
        response += "\n**ุงูููุงุนูุฏ ุงูุฒูููุฉ ุงููุญุฏุฏุฉ:**\n"
        for article in timing_articles[:3]:
            article_num = article.get('article_number', '')
            time_sentence = extract_time_specific_sentence(article.get('content', ''))
            response += f"- ุงููุงุฏุฉ {article_num}: {time_sentence}\n"
    
    response += "\n\n**ุงูููุงุฏ ุงููุฑุฌุนูุฉ:**\n"
    for i, article in enumerate((timing_articles + appeal_articles)[:4], 1):
        article_num = article.get('article_number', '')
        title = article.get('title', '')
        response += f"{i}. ุงููุงุฏุฉ {article_num}: {title}\n"
    
    return response


def format_complex_scoring_response(question: str, results: List[Dict[str, Any]], language: str = 'arabic') -> str:
    """ุชูุณูู ูุฎุตุต ููุฃุณุฆูุฉ ุงููุนูุฏุฉ ุงูุชู ุชุชุทูุจ ุญุณุงุจุงุช ูุชุนุฏุฏุฉ (ุฌุฏูุฏ)"""
    
    import re
    
    response = "## ุญุณุงุจ ุงูููุงุท ุงููุนูุฏ - ุชุญููู ุดุงูู\n\n"
    
    # ุงุณุชุฎุฑุงุฌ ุงูุนูุงุตุฑ ุงูุฑูููุฉ ูู ุงูุณุคุงู
    numbers = extract_all_numbers_from_question(question)
    
    # ุชุญููู ุงูุนูุงุตุฑ ุงููุฎุชููุฉ
    elements = analyze_question_elements(question, numbers)
    
    if elements:
        response += "### ุงูุนูุงุตุฑ ุงููุญุฏุฏุฉ ูู ุงูุณุคุงู:\n"
        
        # ุนุฑุถ ุฎุงุต ูููุฑู ูุงูุฑููู (ุฌุฏูุฏ - ุฅุถุงูุฉ ุขููุฉ)
        if 'ุงููุชุณุงุจููู' in elements:
            response += f"**{elements.get('ููุน ุงููุณุงุจูุฉ', 'ูุฑูู')}:** {elements.get('ุนุฏุฏ ุงููุชุณุงุจููู', 0)} ูุชุณุงุจููู\n\n"
            response += "#### ุชุญููู ุฃุฏุงุก ูู ูุชุณุงุจู:\n"
            
            for i, rider in enumerate(elements['ุงููุชุณุงุจููู'], 1):
                response += f"**ุงููุชุณุงุจู {rider.get('ุฑูู ุงููุชุณุงุจู', i)}:**\n"
                response += f"- ุงูุฃุฏุงุก: {rider.get('ุงููุชูุฌุฉ', 'ุบูุฑ ูุญุฏุฏ')}\n"
                response += f"- ุงูููุงุท ุงููุชููุนุฉ: {rider.get('ุงูููุงุท ุงููุชููุนุฉ', 'ุบูุฑ ูุญุฏุฏุฉ')}\n"
                response += f"- ุงูุชูุงุตูู: {rider.get('ุงููุตู ุงูุฃุตูู', '')}\n\n"
        else:
            # ุงูุนุฑุถ ุงูุฃุตูู ููุฃุณุฆูุฉ ุงููุฑุฏูุฉ (ูุญููุธ)
            for element, value in elements.items():
                if element not in ['ุงููุชุณุงุจููู', 'ููุน ุงููุณุงุจูุฉ', 'ุนุฏุฏ ุงููุชุณุงุจููู']:
                    response += f"**{element}:** {value}\n"
        response += "\n"
    
    # ุงูุจุญุซ ุนู ุงูููุงููู ุฐุงุช ุงูุตูุฉ ูุชุทุจูููุง
    relevant_rules = find_relevant_scoring_rules(results, elements)
    
    # ุฅุถุงูุฉ ุงูุญุณุงุจ ุงููุจุงุดุฑ ูููุฑู ุญุชู ูู ูู ุชูุฌุฏ ููุงููู ูุญุฏุฏุฉ
    if 'ุงููุชุณุงุจููู' in elements:
        response += "### ุงูุญุณุงุจ ุงูููุงุฆู:\n"
        response += "#### ููุงุท ูู ูุชุณุงุจู:\n"
        team_total = 0
        
        for rider in elements['ุงููุชุณุงุจููู']:
            rider_score = calculate_individual_rider_score(rider)
            team_total += rider_score
            response += f"- ุงููุชุณุงุจู {rider.get('ุฑูู ุงููุชุณุงุจู')}: {rider_score} ููุงุท ({rider.get('ุงููุชูุฌุฉ', '')})\n"
        
        response += f"\n**ูุฌููุน ููุงุท ุงููุฑูู: {team_total} ููุทุฉ**\n\n"
        
        # ุงูููุงุฏ ุงููุงููููุฉ ุงููุณุชูุฏุฉ
        response += "**ุงุณุชูุงุฏุงู ููููุงุฏ ุงููุงููููุฉ ุงูุชุงููุฉ:**\n\n"
        response += "**โข ุงููุงุฏุฉ 143** (AWARDING OF POINTS): ุงุญุชุณุงุจ ุงูููุงุท ุญุณุจ ุงููุณุงูุฉ\n\n"
        
        seen_articles = set()
        for result in results[:3]:
            article_num = result.get('article_number')
            if article_num not in seen_articles:
                seen_articles.add(article_num)
                title = result.get('title', '')
                response += f"**โข ุงููุงุฏุฉ {article_num}** ({title})\n\n"
        
        return response
        
    elif relevant_rules:
        response += "### ุชุทุจูู ุงูููุงููู ุฐุงุช ุงูุตูุฉ:\n\n"
        
        total_score = 0
        detailed_calculation = []
        
        for rule_type, rule_info in relevant_rules.items():
            if rule_type == 'peg_points':
                points = calculate_peg_points(elements, rule_info)
                total_score += points
                detailed_calculation.append(f"ููุงุท ุงููุชุฏ: +{points}")
                response += f"**โข {rule_info['title']}:** {points} ููุงุท\n"
                response += f"   *{rule_info['explanation']}*\n\n"
                
            elif rule_type == 'time_penalty':
                penalty = calculate_time_penalty(elements, rule_info)
                total_score -= penalty
                detailed_calculation.append(f"ุนููุจุฉ ุงูููุช: -{penalty}")
                response += f"**โข {rule_info['title']}:** -{penalty} ููุงุท\n"
                response += f"   *{rule_info['explanation']}*\n\n"
                
            elif rule_type == 'weapon_drop':
                penalty = calculate_weapon_drop_penalty(elements, rule_info)
                if penalty > 0:
                    total_score -= penalty
                    detailed_calculation.append(f"ุนููุจุฉ ุฅุณูุงุท ุงูุณูุงุญ: -{penalty}")
                    response += f"**โข {rule_info['title']}:** -{penalty} ููุงุท\n"
                else:
                    detailed_calculation.append("ุนููุจุฉ ุฅุณูุงุท ุงูุณูุงุญ: 0 (ุจุนุฏ ุฎุท ุงูููุงูุฉ)")
                    response += f"**โข {rule_info['title']}:** ูุง ุนููุจุฉ\n"
                response += f"   *{rule_info['explanation']}*\n\n"
        
        # ุงูุญุณุงุจ ุงูููุงุฆู (ูุญุณู ูููุฑู)
        response += "### ุงูุญุณุงุจ ุงูููุงุฆู:\n"
        
        # ุญุณุงุจ ุฎุงุต ูููุฑู (ุฌุฏูุฏ - ุฅุถุงูุฉ ุขููุฉ)
        if 'ุงููุชุณุงุจููู' in elements:
            response += "#### ููุงุท ูู ูุชุณุงุจู:\n"
            team_total = 0
            
            for rider in elements['ุงููุชุณุงุจููู']:
                rider_score = calculate_individual_rider_score(rider)
                team_total += rider_score
                response += f"- ุงููุชุณุงุจู {rider.get('ุฑูู ุงููุชุณุงุจู')}: {rider_score} ููุงุท ({rider.get('ุงููุชูุฌุฉ', '')})\n"
            
            response += f"\n**ูุฌููุน ููุงุท ุงููุฑูู: {team_total} ููุทุฉ**\n\n"
        else:
            # ุงูุญุณุงุจ ุงูุฃุตูู ููุฃุณุฆูุฉ ุงููุฑุฏูุฉ (ูุญููุธ)
            for calc in detailed_calculation:
                response += f"- {calc}\n"
            response += f"\n**ุงููุชูุฌุฉ ุงูููุงุฆูุฉ: {total_score} ููุทุฉ**\n\n"
    
    # ุงูููุงุฏ ุงููุงููููุฉ ุงููุณุชูุฏุฉ
    response += "**ุงุณุชูุงุฏุงู ููููุงุฏ ุงููุงููููุฉ ุงูุชุงููุฉ:**\n\n"
    
    seen_articles = set()
    for result in results[:4]:
        article_num = result.get('article_number')
        if article_num not in seen_articles:
            seen_articles.add(article_num)
            title = result.get('title', '')
            response += f"**โข ุงููุงุฏุฉ {article_num}** ({title})\n\n"
    
    return response


def extract_all_numbers_from_question(question: str) -> dict:
    """ุงุณุชุฎุฑุงุฌ ุฌููุน ุงูุฃุฑูุงู ูู ุงูุณุคุงู ูุน ุณูุงููุง"""
    import re
    
    numbers = {}
    
    # ุงูุจุญุซ ุนู ุงููุณุงูุงุช ุจุงููุชุฑ
    meter_pattern = r'(\d+(?:\.\d+)?)\s*(meters?|ูุชุฑ)'
    meter_matches = re.findall(meter_pattern, question, re.IGNORECASE)
    if meter_matches:
        numbers['distance_meters'] = float(meter_matches[0][0])
    
    # ุงูุจุญุซ ุนู ุงูุฃููุงุช ุจุงูุซูุงูู
    time_pattern = r'(\d+(?:\.\d+)?)\s*(seconds?|ุซุงููุฉ)'
    time_matches = re.findall(time_pattern, question, re.IGNORECASE)
    if time_matches:
        numbers['time_seconds'] = float(time_matches[0][0])
    
    return numbers


def analyze_question_elements(question: str, numbers: dict) -> dict:
    """ุชุญููู ุนูุงุตุฑ ุงูุณุคุงู (ูุญุณู ูุฏุนู ุงููุฑู ูุงูุฑููู)"""
    elements = {}
    question_lower = question.lower()
    
    # ุชุญููู ุงููุณุงูุฉ (ุงูุฃุตูู ูุญููุธ)
    if 'distance_meters' in numbers:
        elements['ูุณุงูุฉ ุญูู ุงููุชุฏ'] = f"{numbers['distance_meters']} ูุชุฑ"
    
    # ุชุญููู ุงูููุช (ุงูุฃุตูู ูุญููุธ)
    if 'time_seconds' in numbers:
        elements['ุฒูู ุงูุฃุฏุงุก'] = f"{numbers['time_seconds']} ุซุงููุฉ"
    
    # ุชุญููู ุฅุณูุงุท ุงูุณูุงุญ (ุงูุฃุตูู ูุญููุธ)
    if any(word in question_lower for word in ['dropped', 'drop', 'ุณูุท', 'ุฃุณูุท']):
        if 'after crossing' in question_lower or 'ุจุนุฏ ุนุจูุฑ' in question_lower:
            elements['ุฅุณูุงุท ุงูุณูุงุญ'] = "ุจุนุฏ ุนุจูุฑ ุฎุท ุงูููุงูุฉ"
        elif 'before' in question_lower or 'ูุจู' in question_lower:
            elements['ุฅุณูุงุท ุงูุณูุงุญ'] = "ูุจู ุฎุท ุงูููุงูุฉ"
        else:
            elements['ุฅุณูุงุท ุงูุณูุงุญ'] = "ููุงู ุบูุฑ ูุญุฏุฏ"
    
    # ุชุญููู ุฃุณุฆูุฉ ุงููุฑู ูุงูุฑููู (ุฌุฏูุฏ - ุฅุถุงูุฉ ุขููุฉ)
    if any(word in question_lower for word in ['relay', 'team', 'ูุฑูู', 'ุฑููู']):
        team_analysis = analyze_team_elements(question)
        if team_analysis:
            elements.update(team_analysis)
    
    return elements


def analyze_team_elements(question: str) -> dict:
    """ุชุญููู ุนูุงุตุฑ ุฃุณุฆูุฉ ุงููุฑู ูุงูุฑููู (ุฏุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)"""
    import re
    
    team_elements = {}
    question_lower = question.lower()
    
    # ุชุญุฏูุฏ ููุน ุงููุณุงุจูุฉ
    if 'relay' in question_lower:
        team_elements['ููุน ุงููุณุงุจูุฉ'] = 'ุฑููู'
    elif 'team' in question_lower:
        team_elements['ููุน ุงููุณุงุจูุฉ'] = 'ูุฑูู'
    
    # ุชุญููู ุงููุชุณุงุจููู ุงููุฑุฏููู
    riders = extract_individual_riders(question)
    if riders:
        team_elements['ุงููุชุณุงุจููู'] = riders
        team_elements['ุนุฏุฏ ุงููุชุณุงุจููู'] = len(riders)
    
    return team_elements


def extract_individual_riders(question: str) -> list:
    """ุงุณุชุฎุฑุงุฌ ุฃุฏุงุก ูู ูุชุณุงุจู ูุฑุฏู (ุฏุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)"""
    import re
    
    riders = []
    lines = question.split('\n')
    
    rider_patterns = [
        r'the first rider (.+)',
        r'the second rider (.+)', 
        r'the third rider (.+)',
        r'the fourth rider (.+)',
        r'ุงููุชุณุงุจู ุงูุฃูู (.+)',
        r'ุงููุชุณุงุจู ุงูุซุงูู (.+)',
        r'ุงููุชุณุงุจู ุงูุซุงูุซ (.+)',
        r'ุงููุชุณุงุจู ุงูุฑุงุจุน (.+)'
    ]
    
    for line in lines:
        line = line.strip().lower()
        for i, pattern in enumerate(rider_patterns):
            match = re.search(pattern, line, re.IGNORECASE)
            if match:
                rider_num = (i % 4) + 1  # 1,2,3,4
                action = match.group(1).strip()
                
                # ุชุญููู ุฃุฏุงุก ุงููุชุณุงุจู
                rider_analysis = analyze_single_rider_performance(action)
                rider_analysis['ุฑูู ุงููุชุณุงุจู'] = rider_num
                rider_analysis['ุงููุตู ุงูุฃุตูู'] = action
                
                riders.append(rider_analysis)
                break
    
    return riders


def analyze_single_rider_performance(action: str) -> dict:
    """ุชุญููู ุฃุฏุงุก ูุชุณุงุจู ูุงุญุฏ (ุฏุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)"""
    import re
    
    performance = {}
    action_lower = action.lower()
    
    # ุชุญููู ุญุงูุงุช ูุฎุชููุฉ
    if 'successfully picked up' in action_lower:
        performance['ุงููุชูุฌุฉ'] = 'ุงูุชูุงุท ูุงุฌุญ'
        performance['ุงูููุงุท ุงููุชููุนุฉ'] = 'ุบูุฑ ูุญุฏุฏุฉ (ุชุนุชูุฏ ุนูู ุงููุณุงูุฉ)'
        
    elif 'carried' in action_lower and 'dropped' in action_lower:
        # ุงูุจุญุซ ุนู ุงููุณุงูุฉ
        if 'more than 10' in action_lower or 'ุฃูุซุฑ ูู 10' in action_lower:
            performance['ุงููุชูุฌุฉ'] = 'ุญูู ุฃูุซุฑ ูู 10 ูุชุฑ ุซู ุณููุท'
            performance['ุงูููุงุท ุงููุชููุนุฉ'] = '6 ููุงุท (ุญูู ูุงูู)'
        elif 'before 10' in action_lower or 'ูุจู 10' in action_lower:
            performance['ุงููุชูุฌุฉ'] = 'ุณููุท ูุจู 10 ูุชุฑ'
            performance['ุงูููุงุท ุงููุชููุนุฉ'] = '4 ููุงุท (ุณุญุจ)'
        else:
            performance['ุงููุชูุฌุฉ'] = 'ุญูู ูุน ุณููุท'
            performance['ุงูููุงุท ุงููุชููุนุฉ'] = 'ุชุญุฏูุฏ ุญุณุจ ุงููุณุงูุฉ'
            
    elif 'dropped' in action_lower and 'before 10' in action_lower:
        # ุญุงูุฉ ุฎุงุตุฉ: ุณููุท ูุจู 10 ูุชุฑ ุจุฏูู ุฐูุฑ ุญูู
        performance['ุงููุชูุฌุฉ'] = 'ุณููุท ูุจู 10 ูุชุฑ'
        performance['ุงูููุงุท ุงููุชููุนุฉ'] = '4 ููุงุท (ุณุญุจ)'
            
    elif 'missed' in action_lower and 'entirely' in action_lower:
        performance['ุงููุชูุฌุฉ'] = 'ูู ูุดุงุฑู'
        performance['ุงูููุงุท ุงููุชููุนุฉ'] = '0 ููุงุท'
        
    elif 'did not enter' in action_lower or 'ูู ูุฏุฎู' in action_lower:
        performance['ุงููุชูุฌุฉ'] = 'ูู ูุฏุฎู ุงููุณุงุฑ'
        performance['ุงูููุงุท ุงููุชููุนุฉ'] = '0 ููุงุท'
    
    return performance


def find_relevant_scoring_rules(results: List[Dict[str, Any]], elements: dict) -> dict:
    """ุงูุนุซูุฑ ุนูู ุงูููุงููู ุฐุงุช ุงูุตูุฉ ุจุงูุญุณุงุจ"""
    rules = {}
    
    for result in results:
        title = result.get('title', '').lower()
        content = result.get('content', '').lower()
        
        # ูุงููู ุงุญุชุณุงุจ ุงูููุงุท (ุงููุงุฏุฉ 143)
        if 'awarding of points' in title or 'ููุงุท' in title:
            if 'ูุณุงูุฉ ุญูู ุงููุชุฏ' in elements:
                distance = float(elements['ูุณุงูุฉ ุญูู ุงููุชุฏ'].split()[0])
                if distance >= 10:
                    rules['peg_points'] = {
                        'title': 'ุญูู ุงููุชุฏ ูุงููุงู',
                        'points': 6,
                        'explanation': f'ุญูู ุงููุชุฏ {distance} ูุชุฑ (10 ูุชุฑ ุฃู ุฃูุซุฑ) = 6 ููุงุท'
                    }
                else:
                    rules['peg_points'] = {
                        'title': 'ุณุญุจ ุงููุชุฏ',
                        'points': 4,
                        'explanation': f'ุญูู ุงููุชุฏ {distance} ูุชุฑ (ุฃูู ูู 10 ูุชุฑ) = 4 ููุงุท'
                    }
        
        # ูุงููู ุงูุนููุจุงุช ุงูุฒูููุฉ (ุงููุงุฏุฉ 144)
        if 'timekeeping' in title or 'ุฒููู' in title or 'timing' in title:
            if 'ุฒูู ุงูุฃุฏุงุก' in elements:
                actual_time = float(elements['ุฒูู ุงูุฃุฏุงุก'].split()[0])
                standard_time = 6.4  # ุงูุชุฑุงุถู ูููุฑุฏู
                if actual_time > standard_time:
                    overtime = actual_time - standard_time
                    penalty = 0.5  # ูุตู ููุทุฉ ููู ุซุงููุฉ ุฃู ุฌุฒุก ูููุง
                    rules['time_penalty'] = {
                        'title': 'ุนููุจุฉ ุชุฌุงูุฒ ุงูููุช ุงููุญุฏุฏ',
                        'penalty': penalty,
                        'explanation': f'ุชุฌุงูุฒ ุจู {overtime:.2f} ุซุงููุฉ ร {penalty} ููุทุฉ/ุซุงููุฉ = {penalty} ููุทุฉ'
                    }
        
        # ุงูุจุญุซ ุงูุฅุถุงูู ุนู ุงููุงุฏุฉ 144 ุจุดูู ูุจุงุดุฑ
        elif '144' in str(result.get('article_number', '')):
            if 'ุฒูู ุงูุฃุฏุงุก' in elements:
                actual_time = float(elements['ุฒูู ุงูุฃุฏุงุก'].split()[0])
                standard_time = 6.4
                if actual_time > standard_time:
                    overtime = actual_time - standard_time
                    penalty = 0.5
                    rules['time_penalty'] = {
                        'title': 'ุนููุจุฉ ุชุฌุงูุฒ ุงูููุช (ุงููุงุฏุฉ 144)',
                        'penalty': penalty,
                        'explanation': f'ุงูููุช ุงููุนูุงุฑู 6.4 ุซุงููุฉุ ุงููุนูู {actual_time} ุซุงููุฉ โ ุนููุจุฉ {penalty} ููุทุฉ'
                    }
        
        # ูุงููู ุฅุณูุงุท ุงูุณูุงุญ (ุงููุงุฏุฉ 132)
        if 'breaking or loss' in title or 'ุฅุณูุงุท' in title or 'equipment' in title:
            if 'ุฅุณูุงุท ุงูุณูุงุญ' in elements:
                if elements['ุฅุณูุงุท ุงูุณูุงุญ'] == "ุจุนุฏ ุนุจูุฑ ุฎุท ุงูููุงูุฉ":
                    rules['weapon_drop'] = {
                        'title': 'ุฅุณูุงุท ุงูุณูุงุญ ุจุนุฏ ุฎุท ุงูููุงูุฉ',
                        'penalty': 0,
                        'explanation': 'ูุง ุนููุจุฉ - ุงููุงููู ููุทุจู ููุท ุจูู ุฎุท ุงูุจุฏุงูุฉ ูุงูููุงูุฉ'
                    }
                else:
                    rules['weapon_drop'] = {
                        'title': 'ุฅุณูุงุท ุงูุณูุงุญ ุจูู ุงูุฎุทูุท',
                        'penalty': 'all_points',
                        'explanation': 'ูุง ููุงุท - ุฅุณูุงุท ุงูุณูุงุญ ุจูู ุฎุท ุงูุจุฏุงูุฉ ูุงูููุงูุฉ'
                    }
    
    # ุฅุถุงูุฉ ุงูุชุฑุงุถูุฉ ูุญุณุงุจ ุนููุจุฉ ุงูููุช ุฅุฐุง ูู ุชูุฌุฏ ุงููุงุฏุฉ ุงูููุงุณุจุฉ (ุชุญุณูู ููู)
    if 'time_penalty' not in rules and 'ุฒูู ุงูุฃุฏุงุก' in elements:
        actual_time = float(elements['ุฒูู ุงูุฃุฏุงุก'].split()[0])
        standard_time = 6.4  # ูููุณุงุจูุงุช ุงููุฑุฏูุฉ ุญุณุจ ุงููุงุฏุฉ 144
        if actual_time > standard_time:
            overtime = actual_time - standard_time
            penalty = 0.5  # ูุตู ููุทุฉ ููู ุซุงููุฉ ุฃู ุฌุฒุก ูููุง
            rules['time_penalty'] = {
                'title': 'ุนููุจุฉ ุชุฌุงูุฒ ุงูููุช (ุงููุงุฏุฉ 144)',
                'penalty': penalty,
                'explanation': f'ุงูููุช ุงููุนูุงุฑู {standard_time} ุซุงููุฉุ ุงููุนูู {actual_time} ุซุงููุฉ โ ุนููุจุฉ {penalty} ููุทุฉ'
            }
    
    return rules


def calculate_peg_points(elements: dict, rule_info: dict) -> float:
    """ุญุณุงุจ ููุงุท ุงููุชุฏ"""
    return rule_info.get('points', 0)


def calculate_time_penalty(elements: dict, rule_info: dict) -> float:
    """ุญุณุงุจ ุนููุจุฉ ุงูููุช"""
    return rule_info.get('penalty', 0)


def calculate_weapon_drop_penalty(elements: dict, rule_info: dict) -> float:
    """ุญุณุงุจ ุนููุจุฉ ุฅุณูุงุท ุงูุณูุงุญ"""
    penalty = rule_info.get('penalty', 0)
    if penalty == 'all_points':
        return float('inf')  # ูุนูู ุตูุฑ ููุงุท
    return penalty


def calculate_team_total_score(elements: dict) -> float:
    """ุญุณุงุจ ูุฌููุน ููุงุท ุงููุฑูู (ุฏุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)"""
    if 'ุงููุชุณุงุจููู' not in elements:
        return 0
    
    total_score = 0
    for rider in elements['ุงููุชุณุงุจููู']:
        rider_score = calculate_individual_rider_score(rider)
        total_score += rider_score
    
    return total_score


def calculate_individual_rider_score(rider: dict) -> float:
    """ุญุณุงุจ ููุงุท ูุชุณุงุจู ูุฑุฏู (ุฏุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)"""
    result = rider.get('ุงููุชูุฌุฉ', '')
    expected_points = rider.get('ุงูููุงุท ุงููุชููุนุฉ', '')
    
    # ุชุญููู ุงููุต ุฅูู ุฑูู
    if '6 ููุงุท' in expected_points:
        return 6.0
    elif '4 ููุงุท' in expected_points:
        return 4.0
    elif '2 ููุงุท' in expected_points:
        return 2.0
    elif '0 ููุงุท' in expected_points:
        return 0.0
    elif 'ูู ูุดุงุฑู' in result or 'ูู ูุฏุฎู' in result:
        return 0.0
    elif 'ุงูุชูุงุท ูุงุฌุญ' in result:
        # ุงูุชุฑุงุถ 2 ููุงุท ููุงูุชูุงุท ููุท (ุญุฏ ุฃุฏูู)
        return 2.0
    else:
        return 0.0


def format_definitions_response(question: str, results: List[Dict[str, Any]], language: str = 'arabic') -> str:
    """ุชูุณูู ูุฎุตุต ูุฃุณุฆูุฉ ุงูุชุนุฑููุงุช ูุงูููุงุนุฏ ุงูุนุงูุฉ (ุฌุฏูุฏ - ุฅุถุงูุฉ ุขููุฉ)"""
    
    response = "# ุงูุชุนุฑููุงุช ูุงูููุงุนุฏ ุงูุนุงูุฉ ููููุฒ\n\n"
    response += "---\n\n"
    
    # ุชุตููู ุงูููุงุฏ ุญุณุจ ููุน ุงููุญุชูู
    definitions_articles = []
    winner_rules_articles = []
    scoring_articles = []
    
    for result in results:
        title = result.get('title', '').lower()
        content = result.get('content', '').lower()
        article_num = result.get('article_number', '')
        
        # ุชุตููู ุงูููุงุฏ
        if any(word in title for word in ['definitions', 'ุชุนุฑููุงุช']) or str(article_num) == '103':
            definitions_articles.append(result)
        elif any(word in content[:500] for word in ['winner', 'winning', 'ูุงุฆุฒ', 'ููุฒ']):
            winner_rules_articles.append(result)
        elif any(word in content[:500] for word in ['points', 'scores', 'total', 'ููุงุท', 'ูุฌููุน']):
            scoring_articles.append(result)
    
    # ุนุฑุถ ุงูุชุนุฑููุงุช ุงูุฃุณุงุณูุฉ ูู ุงููุงุฏุฉ 103
    if definitions_articles:
        response += "## ุชุนุฑููุงุช ุงูููุฒ ุงูุฃุณุงุณูุฉ\n\n"
        
        for article in definitions_articles[:1]:  # ุงููุงุฏุฉ ุงูุฃูู ููุท
            content = article.get('content', '')
            title = article.get('title', '')
            article_num = article.get('article_number', '')
            
            response += f"### ุงููุงุฏุฉ {article_num}: {title}\n\n"
            
            # ุงุณุชุฎุฑุงุฌ ุงูุชุนุฑููุงุช ุงููุญุฏุฏุฉ ูููุงุฆุฒูู
            winner_definitions = extract_winner_definitions(content)
            
            for category, definition in winner_definitions.items():
                if definition:
                    response += f"**{category}:**\n"
                    response += f"{definition}\n\n"
    
    # ุฅุถุงูุฉ ูุนูููุงุช ุนู ุจุฑูุงูุฌ ุงูุญุฏุซ
    event_program = extract_event_program_info(results)
    if event_program:
        response += "## ุจุฑูุงูุฌ ุงูุญุฏุซ ููุธุงู ุงูููุงุท\n\n"
        response += event_program
        response += "\n"
    
    # ุฅุถุงูุฉ ููุงุฏ ุฃุฎุฑู ุฐุงุช ุตูุฉ
    other_articles = winner_rules_articles + scoring_articles
    if other_articles:
        response += "## ููุงุฏ ูุงููููุฉ ุฐุงุช ุตูุฉ\n\n"
        
        seen_articles = set()
        for result in other_articles[:2]:  # ุฃูู 2 ููุงุฏ ููุท
            article_num = result.get('article_number', '')
            if article_num not in seen_articles:
                seen_articles.add(article_num)
                title = result.get('title', '')
                content = result.get('content', '')
                
                # ุฅุตูุงุญ ุนุฑุถ ูุญุชูู ุงูููุงุญู (ุฅุถุงูุฉ ุขููุฉ - ูุง ุชุคุซุฑ ุนูู ุงููุตูุต ุงูุฃุตููุฉ)
                if isinstance(content, dict):
                    # ุฅุฐุง ูุงู ุงููุญุชูู JSONุ ุงุณุชุฎุฑุฌ ูุนูููุงุช ูููุฏุฉ
                    if 'total_score' in content:
                        display_content = f"ุฅุฌูุงูู ุงูููุงุท: {content.get('total_score', '')}"
                    elif 'day_1' in content:
                        display_content = f"ุจุฑูุงูุฌ ุซูุงุซุฉ ุฃูุงู: ุงูููู ุงูุฃูู - {content.get('day_1', {}).get('title', 'ูุณุงุจูุงุช ุงูุฑูุญ')}"
                    else:
                        display_content = "ุจุฑูุงูุฌ ุงูุญุฏุซ ุงูุชูุตููู"
                elif isinstance(content, str) and (content.startswith('{') or 'total_score' in content.lower()):
                    # ุฅุฐุง ูุงู JSON ููุตุ ุญุงูู ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ูููุฏุฉ
                    if 'Total Score of' in content:
                        import re
                        match = re.search(r'Total Score of ([^.]+)', content)
                        if match:
                            display_content = f"ูุธุงู ุงูููุงุท: {match.group(1).strip()}"
                        else:
                            display_content = "ูุธุงู ุชุญุฏูุฏ ุงููุงุฆุฒูู ุจุงูููุงุท"
                    elif 'DAY 1' in content and 'DAY 2' in content:
                        display_content = "ุจุฑูุงูุฌ ุงูุญุฏุซ ุงูุชูุตููู ูุซูุงุซุฉ ุฃูุงู ูู ุงููุณุงุจูุงุช"
                    else:
                        display_content = "ุชูุงุตูู ุจุฑูุงูุฌ ุงูุญุฏุซ ูุงููุณุงุจูุงุช"
                else:
                    # ุงููุญุชูู ุงูุนุงุฏู
                    display_content = content[:200]
                
                response += f"**โข ุงููุงุฏุฉ {article_num}** ({title})\n"
                response += f"   {display_content}...\n\n"
    
    # ุฎูุงุตุฉ ูุงููููุฉ
    response += "---\n\n"
    response += "## ุงูุฎูุงุตุฉ ุงููุงููููุฉ\n\n"
    response += "ูุชู ุชุญุฏูุฏ ุงููุงุฆุฒ ุงูุนุงู ููุฑูุงุถู ูุงููุฑูู ุจูุงุกู ุนูู ุฅุฌูุงูู ุงูููุงุท ุงููุญููุฉ "
    response += "ูู ุฌููุน ุงููุณุงุจูุงุช ุฎูุงู ุงูุญุฏุซุ ูููุงู ููุชุนุฑููุงุช ุงููุญุฏุฏุฉ ูู ุงููุงุฏุฉ 103 "
    response += "ูุจุฑูุงูุฌ ุงูุญุฏุซ ุงูููุตู ูู ุงูููุงุญู.\n\n"
    
    return response


def extract_winner_definitions(content: str) -> dict:
    """ุงุณุชุฎุฑุงุฌ ุชุนุฑููุงุช ุงููุงุฆุฒูู ูู ุงููุญุชูู (ุฏุงูุฉ ูุณุงุนุฏุฉ ุฌุฏูุฏุฉ)"""
    import re
    
    definitions = {
        'ูุงุฆุฒ ุงููุณุงุจูุฉ ุงููุงุญุฏุฉ': '',
        'ุงูุฑูุงุถู ุงููุงุฆุฒ ุงูุนุงู': '',
        'ุงููุฑูู ุงููุงุฆุฒ ุงูุนุงู': ''
    }
    
    # ุงูุจุญุซ ุนู ุงูุชุนุฑููุงุช ุงููุญุฏุฏุฉ
    sentences = content.split('.')
    
    for sentence in sentences:
        sentence = sentence.strip()
        if len(sentence) < 20:
            continue
            
        sentence_lower = sentence.lower()
        
        # ุชุนุฑูู ูุงุฆุฒ ุงููุณุงุจูุฉ
        if 'winner of a competition' in sentence_lower:
            definitions['ูุงุฆุฒ ุงููุณุงุจูุฉ ุงููุงุญุฏุฉ'] = sentence.strip()
        
        # ุชุนุฑูู ุงูุฑูุงุถู ุงููุงุฆุฒ ุงูุนุงู
        elif 'winning athlete of the event' in sentence_lower:
            definitions['ุงูุฑูุงุถู ุงููุงุฆุฒ ุงูุนุงู'] = sentence.strip()
        
        # ุชุนุฑูู ุงููุฑูู ุงููุงุฆุฒ ุงูุนุงู
        elif 'winning team of the event' in sentence_lower:
            definitions['ุงููุฑูู ุงููุงุฆุฒ ุงูุนุงู'] = sentence.strip()
    
    return definitions


def extract_event_program_info(results: List[Dict[str, Any]]) -> str:
    """ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ุจุฑูุงูุฌ ุงูุญุฏุซ (ุฏุงูุฉ ูุณุงุนุฏุฉ ุฌุฏูุฏุฉ)"""
    
    program_info = ""
    
    for result in results:
        title = result.get('title', '').lower()
        content = result.get('content', '')
        
        # ุงูุจุญุซ ุนู ููุญู 9 ุฃู ูุนูููุงุช ุงูุจุฑูุงูุฌ
        if ('tent pegging event program' in title or 
            '18 runs' in content or 
            'total score' in content.lower()):
            
            # ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ูููุฉ
            if '18 runs' in content:
                program_info += "**ูุธุงู ุงูููุงุท ุงูุนุงู:**\n"
                program_info += "- ุฅุฌูุงูู 18 ุฌููุฉ ูุญุฏุฏ ุงููุงุฆุฒูู ุงูุนุงููู ููุญุฏุซ\n"
                program_info += "- ูุชู ุฌูุน ููุงุท ุฌููุน ุงููุณุงุจูุงุช ููุญุตูู ุนูู ุงููุชูุฌุฉ ุงูููุงุฆูุฉ\n\n"
            
            if 'day 1' in content.lower() and 'day 2' in content.lower():
                program_info += "**ูููู ุงูุญุฏุซ:**\n"
                program_info += "- ุงูููู ุงูุฃูู: ูุณุงุจูุงุช ุงูุฑูุญ\n"
                program_info += "- ุงูููู ุงูุซุงูู: ูุณุงุจูุงุช ุงูุณูู\n"
                program_info += "- ุงูููู ุงูุซุงูุซ: ูุณุงุจูุงุช ุนูููุฉ ูุชุชุงุจุน\n\n"
            
            break
    
    return program_info


def format_responsibilities_response(question: str, results: List[Dict[str, Any]], language: str = 'arabic') -> str:
    """ุชูุณูู ูุฎุตุต ูุฃุณุฆูุฉ ุงููุณุคูููุงุช ูุงูุงูุชุฒุงูุงุช (ุฌุฏูุฏ - ุฅุถุงูุฉ ุขููุฉ)"""
    
    # Language-specific templates
    if language == 'english':
        templates = {
            'main_title': '# Ground Jury Responsibilities and Authority',
            'article_prefix': 'Article',
            'basic_responsibilities': '### Basic Responsibilities:',
            'authorities_powers': '### Authorities and Powers:',
            'summary_title': '## Ground Jury Authority Summary',
            'time_scope': '**Authority Time Scope:**',
            'main_responsibilities': '**Main Responsibilities:**',
            'basic_authorities': '**Basic Authorities:**',
            'analysis_title': '**Analysis of Ground Jury Related Questions:**',
            'question_label': 'Question:',
            'references_checked': '**References Checked:**',
            'note_label': '**Note:**',
            'refer_to': 'Please refer to the specific articles related to "RESPONSIBILITIES OF THE GROUND JURY" for detailed information.',
            'resp_org_title': '# Responsibilities and Obligations of Federations and Organizers'
        }
    else:
        templates = {
            'main_title': '# ูุณุคูููุงุช ูุตูุงุญูุงุช ุงูุฌูุงุฒ ุงูููู (Ground Jury)',
            'article_prefix': 'ุงููุงุฏุฉ',
            'basic_responsibilities': '### ุงููุณุคูููุงุช ุงูุฃุณุงุณูุฉ:',
            'authorities_powers': '### ุงูุตูุงุญูุงุช ูุงูุณูุทุงุช:',
            'summary_title': '## ููุฎุต ุตูุงุญูุงุช ุงูุฌูุงุฒ ุงูููู',
            'time_scope': '**ุงููุทุงู ุงูุฒููู ููุตูุงุญูุฉ:**',
            'main_responsibilities': '**ุงููุณุคูููุงุช ุงูุฑุฆูุณูุฉ:**',
            'basic_authorities': '**ุงูุตูุงุญูุงุช ุงูุฃุณุงุณูุฉ:**',
            'analysis_title': '**ุชุญููู ุงูุฃุณุฆูุฉ ุงููุชุนููุฉ ุจุงูุฌูุงุฒ ุงูููู:**',
            'question_label': 'ุงูุณุคุงู:',
            'references_checked': '**ุงููุฑุงุฌุน ุงูููุญูุตุฉ:**',
            'note_label': '**ููุงุญุธุฉ:**',
            'refer_to': 'ูููุตุญ ุจูุฑุงุฌุนุฉ ุงูููุงุฏ ุงููุญุฏุฏุฉ ุงููุชุนููุฉ ุจู "RESPONSIBILITIES OF THE GROUND JURY" ููุญุตูู ุนูู ูุนูููุงุช ุชูุตูููุฉ.',
            'resp_org_title': '# ูุณุคูููุงุช ูุงูุชุฒุงูุงุช ุงูุงุชุญุงุฏุงุช ูุงูููุธููู'
        }
    
    question_lower = question.lower()
    
    # ูุนุงูุฌุฉ ุฎุงุตุฉ ูุฃุณุฆูุฉ ููุฆุฉ ุงูุชุญููู (Ground Jury) - ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ
    is_ground_jury_question = ('ground jury' in question_lower and 
                              ('responsibilities' in question_lower or 'authority' in question_lower))
    
    if is_ground_jury_question:
        response = f"{templates['main_title']}\n\n"
        response += "---\n\n"
        
        # ุงูุจุญุซ ุนู ูุนูููุงุช ูุญุฏุฏุฉ ุนู ุงูุฌูุงุฒ ุงูููู
        ground_jury_articles = []
        for result in results:
            title = result.get('title', '').lower()
            content = result.get('content', '')
            article_num = result.get('article_number', '')
            
            if (('ground jury' in title or 'responsibilities of the ground jury' in title) or
                ('ground jury' in content.lower()[:500] and any(term in content.lower() for term in ['responsibilities', 'authority', 'jurisdiction']))):
                ground_jury_articles.append(result)
        
        if ground_jury_articles:
            for article in ground_jury_articles[:3]:  # ุฃูู 3 ููุงุฏ
                title = article.get('title', 'Ground Jury')
                content = article.get('content', '')
                article_num = article.get('article_number', '')
                
                response += f"## {title}"
                if article_num:
                    response += f" ({templates['article_prefix']} {article_num})"
                response += "\n\n"
                
                # ุงุณุชุฎุฑุงุฌ ุงููุณุคูููุงุช ูุงูุตูุงุญูุงุช
                lines = content.split('\n')
                responsibilities = []
                authorities = []
                
                for line in lines:
                    line_clean = line.strip()
                    if line_clean and len(line_clean) > 10:
                        if any(term in line.lower() for term in ['responsible for', 'shall', 'must', 'duty', 'jurisdiction']):
                            if 'authority' in line.lower() or 'power' in line.lower():
                                authorities.append(line_clean)
                            else:
                                responsibilities.append(line_clean)
                        elif any(term in line.lower() for term in ['authority', 'power', 'decide', 'determine', 'ruling']):
                            authorities.append(line_clean)
                
                if responsibilities:
                    response += f"{templates['basic_responsibilities']}\n"
                    for resp in responsibilities[:5]:  # ุฃูู 5 ูุณุคูููุงุช
                        response += f"โข {resp}\n"
                    response += "\n"
                
                if authorities:
                    response += f"{templates['authorities_powers']}\n"
                    for auth in authorities[:5]:  # ุฃูู 5 ุตูุงุญูุงุช
                        response += f"โข {auth}\n"
                    response += "\n"
                
                response += "---\n\n"
            
            # ุฅุถุงูุฉ ููุฎุต ุดุงูู
            response += f"{templates['summary_title']}\n\n"
            response += "**ุงููุทุงู ุงูุฒููู ููุตูุงุญูุฉ:**\n"
            response += "- ุชุจุฏุฃ ุตูุงุญูุฉ ุงูุฌูุงุฒ ุงูููู ูู ูุญุธุฉ ูุตูู ุงููุชุณุงุจููู ุฅูู ูููุน ุงููุณุงุจูุฉ\n"
            response += "- ุชุณุชูุฑ ุทูุงู ูุชุฑุฉ ุฅูุงูุฉ ุงูุจุทููุฉ ุฃู ุงูุญุฏุซ ุงูุฑูุงุถู\n"
            response += "- ุชูุชูู ุจุงูุชูุงุก ุฌููุน ุงูุฅุฌุฑุงุกุงุช ุงูุฑุณููุฉ ูููุณุงุจูุฉ\n\n"
            
            response += "**ุงููุณุคูููุงุช ุงูุฑุฆูุณูุฉ:**\n"
            response += "- ุงูุฅุดุฑุงู ุงูุชููู ุงูุดุงูู ุนูู ุฌููุน ุงููุณุงุจูุงุช\n"
            response += "- ุถูุงู ุชุทุจูู ุงูููุงููู ูุงูููุงุฆุญ ุจุฏูุฉ\n"
            response += "- ุงุชุฎุงุฐ ุงููุฑุงุฑุงุช ุงูููุงุฆูุฉ ูู ุงููุณุงุฆู ุงูุชูููุฉ\n"
            response += "- ุงูุชุนุงูู ูุน ุงูุงุนุชุฑุงุถุงุช ูุงูุงุณุชุฆูุงูุงุช\n\n"
            
            response += "**ุงูุตูุงุญูุงุช ุงูุฃุณุงุณูุฉ:**\n"
            response += "- ุณูุทุฉ ุฅููุงู ุฃู ุงุณุชุจุนุงุฏ ุงููุชุณุงุจููู ุนูุฏ ุงูุถุฑูุฑุฉ\n"
            response += "- ุชุญุฏูุฏ ุตุญุฉ ุงููุนุฏุงุช ูุงูุฃุฏูุงุช ุงููุณุชุฎุฏูุฉ\n"
            response += "- ุงุชุฎุงุฐ ูุฑุงุฑุงุช ููุฑูุฉ ูุถูุงู ุณูุงูุฉ ุงููุณุงุจูุฉ\n"
            response += "- ุงูุชูุณูู ูุน ุงูุฌูุงุฒ ุงูุจูุทุฑู ูุงูุทุจู\n\n"
            
            return response
        else:
            response += "**ุชุญููู ุงูุฃุณุฆูุฉ ุงููุชุนููุฉ ุจุงูุฌูุงุฒ ุงูููู:**\n\n"
            response += f"ุงูุณุคุงู: _{question}_\n\n"
            response += "**ุงููุฑุงุฌุน ุงูููุญูุตุฉ:**\n"
            for result in results[:5]:
                title = result.get('title', 'ูุฑุฌุน ุบูุฑ ูุญุฏุฏ')
                article_num = result.get('article_number', '')
                if article_num:
                    response += f"- ุงููุงุฏุฉ {article_num}: {title}\n"
                else:
                    response += f"- {title}\n"
            response += "\n**ููุงุญุธุฉ:** ูููุตุญ ุจูุฑุงุฌุนุฉ ุงูููุงุฏ ุงููุญุฏุฏุฉ ุงููุชุนููุฉ ุจู 'RESPONSIBILITIES OF THE GROUND JURY' ููุญุตูู ุนูู ูุนูููุงุช ุชูุตูููุฉ.\n\n"
            return response
    
    response = f"{templates['resp_org_title']}\n\n"
    response += "---\n\n"
    
    # ุชุตููู ุงูููุงุฏ ุญุณุจ ููุน ุงููุณุคูููุงุช
    safety_articles = []
    insurance_articles = []  
    liability_articles = []
    hosting_articles = []
    
    for result in results:
        title = result.get('title', '').lower()
        content = result.get('content', '').lower()
        article_num = result.get('article_number', '')
        
        # ุชุตููู ุงูููุงุฏ
        if any(word in title for word in ['liabilities', 'ูุณุคูููุงุช']) or str(article_num) == '102':
            liability_articles.append(result)
        elif any(word in content[:500] for word in ['safety', 'security', 'ุฃูุงู', 'ุฃูู']):
            safety_articles.append(result)
        elif any(word in content[:500] for word in ['insurance', 'medical', 'ุชุฃููู', 'ุทุจู']):
            insurance_articles.append(result)
        elif any(word in content[:500] for word in ['hosting', 'federation', 'ุงุณุชุถุงูุฉ']):
            hosting_articles.append(result)
    
    # ุนุฑุถ ุงููุณุคูููุงุช ุงูุฃุณุงุณูุฉ ูู ุงููุงุฏุฉ 102
    if liability_articles:
        response += "## ูุณุคูููุงุช ุงูุงุชุญุงุฏ ุงููุณุชุถูู ุงูุฃุณุงุณูุฉ\n\n"
        
        for article in liability_articles[:1]:  # ุงููุงุฏุฉ ุงูุฃูู ููุท
            content = article.get('content', '')
            title = article.get('title', '')
            article_num = article.get('article_number', '')
            
            response += f"### ุงููุงุฏุฉ {article_num}: {title}\n\n"
            
            # ุงุณุชุฎุฑุงุฌ ุงููุณุคูููุงุช ุงููุญุฏุฏุฉ
            responsibilities = extract_specific_responsibilities(content)
            
            for category, items in responsibilities.items():
                if items:
                    response += f"**{category}:**\n"
                    for item in items:
                        response += f"- {item}\n"
                    response += "\n"
    
    # ุฅุถุงูุฉ ููุงุฏ ุฃุฎุฑู ุฐุงุช ุตูุฉ
    other_articles = safety_articles + insurance_articles + hosting_articles
    if other_articles:
        response += "## ููุงุฏ ูุงููููุฉ ุฐุงุช ุตูุฉ\n\n"
        
        seen_articles = set()
        for result in other_articles[:3]:  # ุฃูู 3 ููุงุฏ ููุท
            article_num = result.get('article_number', '')
            if article_num not in seen_articles:
                seen_articles.add(article_num)
                title = result.get('title', '')
                content = result.get('content', '')[:300]
                
                response += f"**โข ุงููุงุฏุฉ {article_num}** ({title})\n"
                response += f"   {content}...\n\n"
    
    # ุฎูุงุตุฉ ูุงููููุฉ
    response += "---\n\n"
    response += "## ุงูุฎูุงุตุฉ ุงููุงููููุฉ\n\n"
    response += "ุชู ุงูุนุซูุฑ ุนูู ุงูููุงุฏ ุงููุงููููุฉ ุงูุฃุณุงุณูุฉ ุงูุชู ุชุญุฏุฏ ูุณุคูููุงุช ุงูุงุชุญุงุฏุงุช ุงููุณุชุถููุฉ "
    response += "ูููุง ูุชุนูู ุจุงูุฃูุงู ูุงูุชุฃููู ูุงูุงูุชุฒุงูุงุช ุงููุงููููุฉ ุฎูุงู ูุนุงููุงุช ุงูุชูุงุท ุงูุฃูุชุงุฏ ุงูุฏูููุฉ.\n\n"
    
    return response


def extract_specific_responsibilities(content: str) -> dict:
    """ุงุณุชุฎุฑุงุฌ ุงููุณุคูููุงุช ุงููุญุฏุฏุฉ ูู ุงููุญุชูู (ุฏุงูุฉ ูุณุงุนุฏุฉ ุฌุฏูุฏุฉ)"""
    import re
    
    responsibilities = {
        'ุงูุฃูุงู ูุงูุญูุงูุฉ': [],
        'ุงูุชุฃููู ุงูุทุจู': [],
        'ุงูุทูุงุฑุฆ ูุงูุฅุณุนุงู': [],
        'ูุชุทูุจุงุช ุงููุดุงุฑููู': []
    }
    
    # ุงูุจุญุซ ุนู ุงูุฌูู ุงูุชู ุชุญุชูู ุนูู ูุณุคูููุงุช ูุญุฏุฏุฉ
    sentences = re.split(r'[.!ุ]', content)
    
    for sentence in sentences:
        sentence = sentence.strip()
        if len(sentence) < 20:  # ุชุฌุงูู ุงูุฌูู ุงููุตูุฑุฉ ุฌุฏุงู
            continue
            
        sentence_lower = sentence.lower()
        
        # ูุณุคูููุงุช ุงูุฃูุงู
        if any(word in sentence_lower for word in ['safety', 'security', 'safe', 'ุฃูุงู', 'ุฃูู']):
            if 'responsible' in sentence_lower or 'must' in sentence_lower:
                responsibilities['ุงูุฃูุงู ูุงูุญูุงูุฉ'].append(sentence[:200])
        
        # ุงูุชุฃููู ุงูุทุจู
        elif any(word in sentence_lower for word in ['insurance', 'medical', 'ุชุฃููู', 'ุทุจู']):
            if 'must' in sentence_lower or 'have' in sentence_lower:
                responsibilities['ุงูุชุฃููู ุงูุทุจู'].append(sentence[:200])
        
        # ุงูุทูุงุฑุฆ ูุงูุฅุณุนุงู
        elif any(word in sentence_lower for word in ['emergency', 'ambulance', 'ุทูุงุฑุฆ', 'ุฅุณุนุงู']):
            if 'must' in sentence_lower or 'arrange' in sentence_lower:
                responsibilities['ุงูุทูุงุฑุฆ ูุงูุฅุณุนุงู'].append(sentence[:200])
        
        # ูุชุทูุจุงุช ุงููุดุงุฑููู
        elif any(word in sentence_lower for word in ['delegates', 'athletes', 'ููุฏูุจูู', 'ุฑูุงุถููู']):
            if 'must' in sentence_lower or 'insurance' in sentence_lower:
                responsibilities['ูุชุทูุจุงุช ุงููุดุงุฑููู'].append(sentence[:200])
    
    return responsibilities


def format_penalty_response(question: str, results: List[Dict[str, Any]], language: str = 'arabic') -> str:
    """ุชูุณูู ูุฎุตุต ูุฃุณุฆูุฉ ุงูุนููุจุงุช"""
    
    # ูุฑุฒ ุงููุชุงุฆุฌ ูุงุณุชุฎุฑุงุฌ ุงูููุงุฏ ุงูุฃุณุงุณูุฉ ูุงูุงุณุชุซูุงุกุงุช
    main_rule_articles = []
    exception_articles = []
    
    for result in results:
        content = result.get('content', '').lower()
        
        # ููุงููู ุงูุนููุจุงุช ุงูุฃุณุงุณูุฉ (ูุญุณูุฉ)
        main_penalty_keywords = [
            'ุตูุฑ ููุงุท', 'ุงุณุชุจุนุงุฏ', 'ุนููุจุฉ', '120 ุซุงููุฉ',
            'no points', 'zero points', 'disqualified', 'penalty',
            'dropped', 'drop', 'fell', 'fall', 'lost', 'lose',
            'ยฝ a point', 'half a point', 'time penalty', 'second', 'deducted'
        ]
        if any(keyword in content for keyword in main_penalty_keywords):
            main_rule_articles.append(result)
        
        # ุงูุงุณุชุซูุงุกุงุช ูุงูุญุงูุงุช ุงูุฎุงุตุฉ
        if any(keyword in content for keyword in ['ุงุณุชุซูุงุก', 'ุฅูุง', 'ุจุงุณุชุซูุงุก', 'ูู ุญุงูุฉ']):
            exception_articles.append(result)
    
    response = "## ุงูุชุญููู ุงููุงูููู ุงูุฐูู\n\n"
    
    # ุชุญููู ุฎุงุต ูุฃุณุฆูุฉ ุฅุณูุงุท ุงูุฃุณูุญุฉ (ุฌุฏูุฏ)
    weapon_drop_question = any(word in question.lower() for word in ['dropped', 'drop', 'weapon', 'lance', 'sword'])
    # ุชุญููู ุฎุงุต ูุฃุณุฆูุฉ ุนููุจุงุช ุงูููุช (ุฌุฏูุฏ)
    time_penalty_question = any(phrase in question.lower() for phrase in ['time limit', 'exceeding', 'penalty', 'point', 'second', 'commenced'])
    is_multiple_choice = ('a)' in question and 'b)' in question)
    
    if weapon_drop_question and main_rule_articles:
        response += "### ูุงููู ุฅุณูุงุท ุงูุฃุณูุญุฉ ูุงูุฃุฏูุงุช\n\n"
        
        # ุงุณุชุฎุฑุงุฌ ุงูุฎูุงุฑุงุช ุฅุฐุง ูุงู ุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ
        if is_multiple_choice:
            import re
            choice_pattern = r'([a-e])\)\s*([^)]*?)(?=[a-e]\)|$)'
            matches = re.findall(choice_pattern, question, re.IGNORECASE)
            choices = [(letter, text.strip()) for letter, text in matches]
            
            # ุชุญููู ุงููุงููู ูุชุญุฏูุฏ ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ
            for result in main_rule_articles:
                content = result.get('content', '')
                if 'between the start line and the finish line' in content.lower():
                    response += "**ุงููุงููู ุงููุงุถุญ:** ุนุฏู ุงุญุชุณุงุจ ุงูููุงุท ูุญุฏุซ ุนูุฏ ุฅุณูุงุท ุงูุณูุงุญ **ุจูู ุฎุท ุงูุจุฏุงูุฉ ูุฎุท ุงูููุงูุฉ**.\n\n"
                    
                    # ุชุญุฏูุฏ ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ
                    for letter, choice_text in choices:
                        if any(phrase in choice_text.lower() for phrase in ['before the finish', 'finish line']):
                            response += f"**ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ: {letter}) {choice_text}**\n\n"
                            break
                    break
        else:
            response += "**ุงููุงููู:** ูุง ุชูุญุชุณุจ ุงูููุงุท ูููุชุณุงุจู ุฅุฐุง ุณูุท ุงูุณูุงุญ ุจูู ุฎุท ุงูุจุฏุงูุฉ ูุฎุท ุงูููุงูุฉ.\n\n"
    
    # ุชุญููู ุฎุงุต ูุฃุณุฆูุฉ ุนููุจุงุช ุงูููุช (ุฌุฏูุฏ)
    elif time_penalty_question and main_rule_articles:
        response += "### ูุงููู ุนููุจุงุช ุชุฌุงูุฒ ุงูููุช ุงููุญุฏุฏ\n\n"
        
        # ุงูุจุญุซ ุนู ุงููุงููู ุงููุญุฏุฏ ููุนููุจุฉ
        for result in main_rule_articles:
            content = result.get('content', '')
            # ุงูุจุญุซ ุนู ุงููุต ุงููุญุฏุฏ ููุนููุจุฉ ุงูุฒูููุฉ
            if 'ยฝ' in content or 'half' in content.lower() or 'penalty of ยฝ' in content:
                response += "**ุงููุงููู ุงููุงุถุญ:** ุนููุจุฉ ยฝ ููุทุฉ ููู ุซุงููุฉ ุฃู ุฌุฒุก ูู ุงูุซุงููุฉ ุนูุฏ ุชุฌุงูุฒ ุงูููุช ุงููุญุฏุฏ.\n\n"
                
                if is_multiple_choice:
                    import re
                    choice_pattern = r'([a-e])\)\s*([^)]*?)(?=[a-e]\)|$)'
                    matches = re.findall(choice_pattern, question, re.IGNORECASE)
                    choices = [(letter, text.strip()) for letter, text in matches]
                    
                    # ุชุญุฏูุฏ ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ
                    for letter, choice_text in choices:
                        if 'ยฝ' in choice_text or 'half' in choice_text.lower() or '0.5' in choice_text:
                            response += f"**ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ: {letter}) {choice_text}**\n\n"
                            response += "**ุงูุชุจุฑูุฑ:** ูููุงู ูููุงุฏุฉ 144 (TIMEKEEPING): 'A penalty of ยฝ a point per second or part of a second will be deducted'\n\n"
                            break
                break
    
    # ุงูุฎูุงุตุฉ ุงููุงุถุญุฉ ููุฃุณุฆูุฉ ุงูุฃุฎุฑู
    elif '130 ุซุงููุฉ' in question and main_rule_articles:
        response += "**ุงููุชุณุงุจู ุงูุฐู ุชุฃุฎุฑ 130 ุซุงููุฉ ูุญุตู ุนูู ุตูุฑ ููุงุท ูููุณุชุจุนุฏ ูู ูุฐู ุงูุฌููุฉ**"
        if exception_articles:
            response += "ุ **ุฅูุง ูู ุญุงูุงุช ุงุณุชุซูุงุฆูุฉ ูุญุฏุฏุฉ**.\n\n"
        else:
            response += ".\n\n"
    
    if main_rule_articles and exception_articles:
        response += "**ุงูุชูุณูุฑ:** ุงููุธุงู ูุทุจู ูุงููู ุงููููุฉ ุงูุฒูููุฉ 120 ุซุงููุฉ ููุงุนุฏุฉ ุฃุณุงุณูุฉุ "
        response += "ูููู ูุณูุญ ุจุงุณุชุซูุงุกุงุช ูู ุธุฑูู ูุนููุฉ ูุซู ุณููุท ุงููุชุณุงุจู ุฃู ุงูุฎูู.\n\n"
    
    # ุงูููุงุฏ ุงููุงููููุฉ ุงููุณุชูุฏุฉ
    response += "**ุงุณุชูุงุฏุงู ููููุงุฏ ุงููุงููููุฉ ุงูุชุงููุฉ:**\n\n"
    
    # ุชุฑุชูุจ ูุชูุณูู ุงููุฑุงุฌุน
    all_articles = main_rule_articles + exception_articles
    seen_articles = set()
    
    for article in all_articles[:6]:
        article_num = article.get('article_number')
        if article_num not in seen_articles:
            seen_articles.add(article_num)
            title = article.get('title', '')
            content = article.get('content', '')
            
            content_type = "ูุงููู ุฃุณุงุณู" if article in main_rule_articles else "ุงุณุชุซูุงุก"
            
            response += f"**โข ุงููุงุฏุฉ {article_num}** ({content_type}): {title}\n"
            
            key_sentence = extract_key_sentence_for_question(content, question)
            if key_sentence:
                response += f"   *\"{key_sentence}\"*\n\n"
            else:
                response += f"   {content[:150]}...\n\n"
    
    return response


def format_procedures_response(question: str, results: List[Dict[str, Any]], language: str = 'arabic') -> str:
    """ุชูุณูู ูุฎุตุต ูุฃุณุฆูุฉ ุงูุฅุฌุฑุงุกุงุช ูุงูุนูููุงุช ุงููุงููููุฉ"""
    
    # ุชุตููู ุงูููุงุฏ ุญุณุจ ููุน ุงููุนูููุงุช
    appeal_procedures = []
    timing_constraints = []
    committee_info = []
    
    for result in results:
        content = result.get('content', '').lower()
        article_num = result.get('article_number', '')
        
        # ููุงุฏ ุชุญุชูู ุนูู ุฅุฌุฑุงุกุงุช ุงูุงุณุชุฆูุงู
        if any(word in content for word in ['ุงุณุชุฆูุงู', 'ุงุนุชุฑุงุถ', 'ุชูุฏูู', 'ูุชุงุจูุงู', 'ูุฌูุฉ']):
            if any(word in content for word in ['ุฅุฌุฑุงุกุงุช', 'ุฎุทูุงุช', 'ูุฌุจ', 'ุชูุฏูู']):
                appeal_procedures.append(result)
            elif any(word in content for word in ['ูุฌูุฉ', 'ุฃุนุถุงุก', 'ุฑุฆูุณ', 'ุซูุงุซุฉ']):
                committee_info.append(result)
        
        # ููุงุฏ ุชุญุชูู ุนูู ูููุฏ ุฒูููุฉ
        if any(word in content for word in ['ุฏูููุฉ', 'ุณุงุนุฉ', 'ูุตู ุณุงุนุฉ', 'ุบุถูู']):
            timing_constraints.append(result)
    
    response = "# ุฏููู ุฅุฌุฑุงุกุงุช ุงูุงุณุชุฆูุงู ูู ููุงููู ุงูุชูุงุท ุงูุฃูุชุงุฏ\n\n"
    
    # ุงูุฎูุงุตุฉ ุงูุชูููุฐูุฉ
    response += "## ุงูุฎูุงุตุฉ ุงูุชูููุฐูุฉ\n\n"
    if appeal_procedures or timing_constraints:
        response += "ูุชูุฏูู ุงุณุชุฆูุงู ูุนุงู ูู ุจุทููุงุช ุงูุชูุงุท ุงูุฃูุชุงุฏุ ูุฌุจ ุงุชุจุงุน ุฅุฌุฑุงุกุงุช ูุญุฏุฏุฉ ุถูู ุฃููุงุช ุตุงุฑูุฉ.\n\n"
    else:
        response += "ุชู ุงูุนุซูุฑ ุนูู ูุนูููุงุช ุนุงูุฉ ุนู ูุธุงู ุงูุงุณุชุฆูุงูุ ูููู ูุฏ ุชุญุชุงุฌ ููุฑุงุฌุนุฉ ููุงุฏ ุฅุถุงููุฉ ููุญุตูู ุนูู ุชูุงุตูู ุฃูุซุฑ.\n\n"
    
    # ุงูุฅุฌุฑุงุกุงุช ุงููุทููุจุฉ
    if appeal_procedures:
        response += "---\n\n## ุงูุฅุฌุฑุงุกุงุช ุงููุทููุจุฉ\n\n"
        
        for i, article in enumerate(appeal_procedures, 1):
            article_num = article.get('article_number', '')
            title = article.get('title', '')
            content = article.get('content', '')
            
            response += f"### {i}. {title} (ุงููุงุฏุฉ {article_num})\n\n"
            
            # ุงุณุชุฎุฑุงุฌ ุงูุฅุฌุฑุงุกุงุช ุงููุญุฏุฏุฉ
            procedures = extract_procedures_from_content(content)
            for j, procedure in enumerate(procedures, 1):
                response += f"**{j}.** {procedure}\n"
            
            response += "\n"
    
    # ุงููููุฏ ุงูุฒูููุฉ
    if timing_constraints:
        response += "---\n\n## ุงููููุฏ ุงูุฒูููุฉ ุงูุญุงุณูุฉ\n\n"
        response += "| ุงููุฑุญูุฉ | ุงูููุช ุงููุญุฏุฏ | ุงููุชุทูุจุงุช |\n"
        response += "|---------|---------------|-------------|\n"
        
        for article in timing_constraints[:3]:
            content = article.get('content', '')
            time_info = extract_time_requirements(content)
            if time_info:
                response += f"| {time_info['stage']} | {time_info['duration']} | {time_info['requirement']} |\n"
    
    # ูุนูููุงุช ูุฌูุฉ ุงูุงุณุชุฆูุงู
    if committee_info:
        response += "\n---\n\n## ูุฌูุฉ ุงูุงุณุชุฆูุงู\n\n"
        
        for article in committee_info:
            article_num = article.get('article_number', '')
            content = article.get('content', '')
            
            committee_details = extract_committee_info(content)
            if committee_details:
                response += f"**ุงูุชูููู:** {committee_details['composition']}\n"
                response += f"**ุงููุคููุงุช:** {committee_details['qualifications']}\n"
                if committee_details.get('restrictions'):
                    response += f"**ุงููููุฏ:** {committee_details['restrictions']}\n"
                response += f"**ุงููุฑุฌุน:** ุงููุงุฏุฉ {article_num}\n\n"
    
    # ุฎุทูุงุช ุนูููุฉ ููุตู ุจูุง
    response += "---\n\n## ุงูุฎุทูุงุช ุงูุนูููุฉ ุงูููุตู ุจูุง\n\n"
    
    if timing_constraints and appeal_procedures:
        response += "### ูููุฑู ุงูุฑุงุบุจุฉ ูู ุชูุฏูู ุงุณุชุฆูุงู:\n\n"
        response += "1. **ุงูุชุญุถูุฑ ุงูุณุฑูุน:** ุฑุงุฌุน ูุฑุงุฑ ุงูุชุญููู ููุฑุงู ูุญุฏุฏ ุฃุณุจุงุจ ุงูุงุนุชุฑุงุถ\n"
        response += "2. **ุงูุงูุชุฒุงู ุจุงูููุช:** ุชุฃูุฏ ูู ุชูุฏูู ุงูุงุณุชุฆูุงู ุฎูุงู ุงููููุฉ ุงููุงููููุฉ\n"
        response += "3. **ุงูุดูู ุงููุทููุจ:** ูุฏู ุงูุงุณุชุฆูุงู ูุชุงุจูุงู ูุน ุงูุฃุณุจุงุจ ุงููุงุถุญุฉ\n"
        response += "4. **ุงููุชุงุจุนุฉ:** ุงูุชุธุฑ ูุฑุงุฑ ูุฌูุฉ ุงูุงุณุชุฆูุงู ุฎูุงู ุงููููุฉ ุงููุญุฏุฏุฉ\n\n"
    
    # ุงููุฑุงุฌุน ุงููุงููููุฉ
    response += "---\n\n## ุงููุฑุงุฌุน ุงููุงููููุฉ\n\n"
    all_articles = appeal_procedures + timing_constraints + committee_info
    seen_articles = set()
    
    for article in all_articles:
        article_num = article.get('article_number', '')
        if article_num not in seen_articles:
            seen_articles.add(article_num)
            title = article.get('title', '')
            response += f"- **ุงููุงุฏุฉ {article_num}:** {title}\n"
    
    return response


def extract_procedures_from_content(content: str) -> List[str]:
    """ุงุณุชุฎุฑุงุฌ ุงูุฅุฌุฑุงุกุงุช ุงููุญุฏุฏุฉ ูู ูุญุชูู ุงููุงุฏุฉ"""
    procedures = []
    
    # ุชูุธูู ุงููุญุชูู
    content = clean_json_content(content)
    
    sentences = [s.strip() for s in content.split('.') if s.strip()]
    
    for sentence in sentences:
        # ุงูุจุญุซ ุนู ุงูุฌูู ุงูุชู ุชุญุชูู ุนูู ุฅุฌุฑุงุกุงุช
        if any(word in sentence.lower() for word in ['ูุฌุจ', 'ูุชู', 'ุชูุฏูู', 'ูุชุงุจูุงู', 'ูุฌูุฉ']):
            if len(sentence) > 15 and len(sentence) < 200:
                procedures.append(sentence.strip())
    
    return procedures[:5]  # ุฃูู 5 ุฅุฌุฑุงุกุงุช


def extract_time_requirements(content: str) -> dict:
    """ุงุณุชุฎุฑุงุฌ ุงููุชุทูุจุงุช ุงูุฒูููุฉ ูู ุงููุญุชูู"""
    content = clean_json_content(content)
    
    # ุงูุจุญุซ ุนู ุงูุฃููุงุช ุงููุญุฏุฏุฉ
    import re
    time_pattern = r'(\d+)\s*(ุฏูููุฉ|ุณุงุนุฉ|ูุตู ุณุงุนุฉ)'
    time_matches = re.findall(time_pattern, content)
    
    if time_matches:
        duration = f"{time_matches[0][0]} {time_matches[0][1]}"
        
        # ุชุญุฏูุฏ ุงููุฑุญูุฉ
        stage = "ุชูุฏูู ุงูุงุนุชุฑุงุถ" if 'ุงุนุชุฑุงุถ' in content.lower() else "ุนูููุฉ ูุงููููุฉ"
        
        # ุชุญุฏูุฏ ุงููุชุทูุจ
        requirement = "ุฅูุฒุงูู" if 'ูุฌุจ' in content.lower() else "ููุตู ุจู"
        
        return {
            'duration': duration,
            'stage': stage,
            'requirement': requirement
        }
    
    return None


def extract_committee_info(content: str) -> dict:
    """ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ูุฌูุฉ ุงูุงุณุชุฆูุงู"""
    content = clean_json_content(content)
    info = {}
    
    # ุงูุชูููู
    if 'ุซูุงุซุฉ' in content and 'ุฎูุณุฉ' in content:
        info['composition'] = "ูู 3 ุฅูู 5 ุฃุนุถุงุก"
    elif 'ุซูุงุซุฉ' in content:
        info['composition'] = "3 ุฃุนุถุงุก ุนูู ุงูุฃูู"
    
    # ุงููุคููุงุช
    if 'ุดุงุฑุฉ ุฐูุจูุฉ' in content or 'ุงูุดุงุฑุฉ ุงูุฐูุจูุฉ' in content:
        info['qualifications'] = "ุญุงุตููู ุนูู ุงูุดุงุฑุฉ ุงูุฐูุจูุฉ"
    
    # ุงููููุฏ
    if 'ุงูุฏููุฉ ุงููุณุชุถููุฉ' in content:
        info['restrictions'] = "ุฑุฆูุณ ุงููุฌูุฉ ูุง ูุฌูุฒ ุฃู ูููู ูู ุงูุฏููุฉ ุงููุณุชุถููุฉ"
    
    return info


def format_general_legal_response(question: str, results: List[Dict[str, Any]], language: str = 'arabic') -> str:
    """ุชูุณูู ุนุงู ููุฃุณุฆูุฉ ุงูุฃุฎุฑู"""
    
    # Language-specific templates
    if language == 'english':
        templates = {
            'title': '## Smart Legal Analysis',
            'summary': 'Summary:',
            'found_articles': 'relevant legal articles found for this inquiry.',
            'related_articles': '**Related Legal Articles:**',
            'article_prefix': 'Article'
        }
    else:
        templates = {
            'title': '## ุงูุชุญููู ุงููุงูููู ุงูุฐูู',
            'summary': 'ุงูุฎูุงุตุฉ:',
            'found_articles': 'ูุงุฏุฉ ูุงููููุฉ ุฐุงุช ุตูุฉ ุจุงูุงุณุชูุณุงุฑ.',
            'related_articles': '**ุงูููุงุฏ ุงููุงููููุฉ ุฐุงุช ุงูุตูุฉ:**',
            'article_prefix': 'ุงููุงุฏุฉ'
        }
    
    response = f"{templates['title']}\n\n"
    
    # ุชุญููู ูุจุณุท ููุณุคุงู ุงูุนุงู
    if results:
        response += f"**ุงูุฎูุงุตุฉ:** ุชู ุงูุนุซูุฑ ุนูู {len(results)} ูุงุฏุฉ ูุงููููุฉ ุฐุงุช ุตูุฉ ุจุงูุงุณุชูุณุงุฑ.\n\n"
        
        response += "**ุงูููุงุฏ ุงููุงููููุฉ ุฐุงุช ุงูุตูุฉ:**\n\n"
        
        for i, result in enumerate(results[:5], 1):
            article_num = result.get('article_number', '')
            title = result.get('title', '')
            content = result.get('content', '')
            
            response += f"**{i}. ุงููุงุฏุฉ {article_num}**: {title}\n"
            
            # ุงุณุชุฎุฑุงุฌ ุฃูู ุฌุฒุก ูู ุงููุญุชูู
            key_part = extract_relevant_content_part(content, question)
            response += f"   {key_part}\n\n"
    
    else:
        response += "**ุงูุฎูุงุตุฉ:** ูู ูุชู ุงูุนุซูุฑ ุนูู ููุงุฏ ูุงููููุฉ ูุญุฏุฏุฉ ููุงุณุชูุณุงุฑ ุงููุทุฑูุญ.\n\n"
        response += "ูููุตุญ ุจุฅุนุงุฏุฉ ุตูุงุบุฉ ุงูุณุคุงู ุฃู ุงุณุชุฎุฏุงู ูุตุทูุญุงุช ูุงููููุฉ ุฃูุซุฑ ุชุญุฏูุฏุงู.\n\n"
    
    return response


def extract_time_specific_sentence(content: str) -> str:
    """ุงุณุชุฎุฑุงุฌ ุงูุฌููุฉ ุงูุชู ุชุญุชูู ุนูู ุชูููุช ูุญุฏุฏ"""
    sentences = [s.strip() for s in content.split('.') if s.strip()]
    
    time_keywords = ['ุณุงุนุฉ', 'ุฏูููุฉ', 'ูุตู ุณุงุนุฉ', 'ูุฏุฉ', 'ูู', 'ุญุชู', 'ุจุนุฏ']
    
    for sentence in sentences:
        if any(keyword in sentence for keyword in time_keywords) and len(sentence) > 20:
            return sentence
    
    return sentences[0] if sentences else content[:100]


def clean_json_content(content: str) -> str:
    """ุชูุธูู ุงููุญุชูู ูู ุงูุจูุงูุงุช JSON ุงูุฎุงู"""
    import re
    
    # ุฅุฒุงูุฉ JSON formatting
    cleaned = re.sub(r'\{[^}]*\}', '', content)
    cleaned = re.sub(r'\[.*?\]', '', cleaned)
    cleaned = re.sub(r'"[^"]*":', '', cleaned)
    
    # ุฅุฒุงูุฉ ุงูุฃุญุฑู ุงูุฎุงุตุฉ
    cleaned = re.sub(r'[{}"\[\]:]', '', cleaned)
    
    # ุชูุธูู ุงููุณุงูุงุช ุงููุชุนุฏุฏุฉ
    cleaned = ' '.join(cleaned.split())
    
    return cleaned.strip()


def extract_relevant_content_part(content: str, question: str) -> str:
    """ุงุณุชุฎุฑุงุฌ ุงูุฌุฒุก ุงูุฃูุซุฑ ุตูุฉ ุจุงูุณุคุงู ูู ุงููุญุชูู"""
    
    # ุชูุธูู ุงููุญุชูู ุฃููุงู
    content = clean_json_content(content)
    
    # ุงุณุชุฎุฑุงุฌ ุงููููุงุช ุงูููุชุงุญูุฉ ูู ุงูุณุคุงู
    question_words = [word for word in question.split() if len(word) > 3]
    
    sentences = [s.strip() for s in content.split('.') if s.strip()]
    best_sentence = ""
    max_score = 0
    
    for sentence in sentences:
        score = sum(1 for word in question_words if word in sentence)
        if score > max_score and len(sentence) > 20:
            max_score = score
            best_sentence = sentence
    
    if best_sentence:
        return best_sentence
    else:
        return content[:200] + "..." if len(content) > 200 else content


def extract_key_sentence_for_question(content: str, question: str) -> str:
    """ุงุณุชุฎุฑุงุฌ ุงูุฌููุฉ ุงูุฃูุซุฑ ุตูุฉ ุจุงูุณุคุงู ูู ุงููุญุชูู"""
    sentences = [s.strip() for s in content.split('.') if s.strip()]
    
    # ูููุงุช ููุชุงุญูุฉ ูู ุงูุณุคุงู
    question_keywords = []
    if '120' in question or '130' in question:
        question_keywords.extend(['120', '130', 'ุซุงููุฉ'])
    if 'ุนููุจุฉ' in question:
        question_keywords.extend(['ุนููุจุฉ', 'ุงุณุชุจุนุงุฏ', 'ุตูุฑ ููุงุท'])
    if 'ุงุณุชุซูุงุก' in question:
        question_keywords.extend(['ุงุณุชุซูุงุก', 'ุฅูุง', 'ุจุงุณุชุซูุงุก'])
    
    # ุงูุจุญุซ ุนู ุงูุฌููุฉ ุงูุชู ุชุญุชูู ุนูู ุฃูุจุฑ ุนุฏุฏ ูู ุงููููุงุช ุงูููุชุงุญูุฉ
    best_sentence = ""
    max_matches = 0
    
    for sentence in sentences:
        matches = sum(1 for keyword in question_keywords if keyword in sentence.lower())
        if matches > max_matches:
            max_matches = matches
            best_sentence = sentence
    
    return best_sentence if max_matches > 0 else ""


# ุฅูุดุงุก ุงููุญูู ุงูุฎุจูุฑ ุงูุนุงู
legal_analyzer = ExpertLegalAnalyzer()


def extract_jury_members_info(content: str) -> dict:
    """ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ุฃุนุถุงุก ุงูุฌูุงุฒ ุงูููู ูุงููุฌุงู (ูุธููุฉ ุฌุฏูุฏุฉ ุขููุฉ - ูุง ุชุคุซุฑ ุนูู ุงูููุฌูุฏ)"""
    
    info = {}
    content_lower = content.lower()
    
    # ุงูุจุญุซ ุนู ุฃุนุฏุงุฏ ุงูุฃุนุถุงุก ููุนูููุงุช ุงูุฌูุงุฒ ุงูููู
    import re
    
    # ุฅุฐุง ูุงู ุงููุต ูุญุชูู ุนูู ูุนูููุงุช ุงูุฌูุงุฒ ุงูููู
    if 'ground jury' in content_lower:
        info['ููุน ุงูุฌูุงุฒ'] = "ุงูุฌูุงุฒ ุงูููู ููุญูุงู (Ground Jury)"
        
        # ุงูุจุญุซ ุนู ุงูุฑุฆูุณ
        if 'chairperson' in content_lower or 'president' in content_lower:
            info['ุงููููู ุงูุชูุธููู'] = "ูุชุถูู ุฑุฆูุณ ุงูุฌูุงุฒ ุงูููู (Chairperson)"
        
        # ุงูุจุญุซ ุนู ุงููุณุคูููุงุช
        if 'responsible' in content_lower:
            info['ุงููุณุคูููุงุช ุงูุฃุณุงุณูุฉ'] = "ุงูุญูู ุงูุชููู ูุฌููุน ุงููุณุงุจูุงุช ูุญู ุงููุดุงูู"
        
        # ุงูุจุญุซ ุนู ุงูุตูุงุญูุงุช
        if 'authority' in content_lower:
            info['ุงูุตูุงุญูุงุช'] = "ุฅุฒุงูุฉ ุงูุฎููู ุฃู ุงูุฑูุงุถููู ุนูุฏ ุงูุญุงุฌุฉ"
        
        # ุงูุจุญุซ ุนู ุงูุชูููุน ุนูู ุงููุชุงุฆุฌ
        if 'signed by all the members' in content_lower:
            info['ุฅุฌุฑุงุกุงุช ุงูุชูููุน'] = "ุฌููุน ุงูุฃุนุถุงุก ูููุนูู ุนูู ุจุทุงูุฉ ุงููุชุงุฆุฌ"
            # ูุฐุง ูุฏู ุนูู ูุฌูุฏ ุนุฏุฉ ุฃุนุถุงุก
            info['ุชุฑููุจ ุงููุฌูุฉ'] = "ูุชุนุฏุฏุฉ ุงูุฃุนุถุงุก (ูุชุทูุจ ุชูููุน ุฌููุน ุงูุฃุนุถุงุก)"
    
    # ุงูุจุญุซ ุนู ุงูุญุฏ ุงูุฃุฏูู ููุฃุนุถุงุก (ุฃููุงุท ูุญุณูุฉ)
    min_patterns = [
        r'minimum.*?(\d+).*?members',
        r'at least.*?(\d+).*?members',
        r'(\d+).*?members.*?minimum',
        r'minimum.*?ground jury.*?(\d+)',
        r'ground jury.*?consists.*?(\d+)',
        r'shall consist.*?(\d+).*?members',
        r'three.*?members',
        r'(\d+).*?judges',
        r'panel.*?(\d+)'
    ]
    
    for pattern in min_patterns:
        match = re.search(pattern, content_lower)
        if match:
            try:
                number = match.group(1)
                info['ุงูุญุฏ ุงูุฃุฏูู ููุฃุนุถุงุก'] = f"{number} ุนุถู"
            except:
                if 'three' in pattern:
                    info['ุงูุญุฏ ุงูุฃุฏูู ููุฃุนุถุงุก'] = "3 ุฃุนุถุงุก"
            break
    
    # ุงูุจุญุซ ุนู ุงูุญุฏ ุงูุฃูุตู ููุฃุนุถุงุก
    max_patterns = [
        r'maximum.*?(\d+).*?members',
        r'up to.*?(\d+).*?members',
        r'(\d+).*?members.*?maximum'
    ]
    
    for pattern in max_patterns:
        match = re.search(pattern, content_lower)
        if match:
            info['ุงูุญุฏ ุงูุฃูุตู ููุฃุนุถุงุก'] = f"{match.group(1)} ุนุถู"
            break
    
    # ุงูุจุญุซ ุนู ุชุดููู ุงูุฌูุงุฒ ุงูููู
    if 'ground jury' in content_lower:
        if 'president' in content_lower:
            info['ุชุดููู ุงูุฌูุงุฒ ุงูููู'] = "ูุชุถูู ุฑุฆูุณ ุงูุฌูุงุฒ ุงูููู"
        
        if 'three' in content_lower or '3' in content_lower:
            info['ุงูุนุฏุฏ ุงููุทููุจ'] = "3 ุฃุนุถุงุก"
        elif 'five' in content_lower or '5' in content_lower:
            info['ุงูุนุฏุฏ ุงููุทููุจ'] = "5 ุฃุนุถุงุก"
    
    # ุงูุจุญุซ ุนู ุงูุฃุนุถุงุก ุงูุฃุฌุงูุจ ููุชุทูุจุงุช ุงูุญูุงุฏูุฉ (ูุญุณู - ุฅุถุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)
    foreign_info_found = False
    if 'foreign' in content_lower or 'international' in content_lower:
        if 'two' in content_lower and 'members' in content_lower and 'jury' in content_lower:
            info['ุงูุฃุนุถุงุก ุงูุฃุฌุงูุจ'] = "ุนุถูุงู ูู ุฏูู ุฃุฌูุจูุฉ"
            foreign_info_found = True
        elif 'foreign countries' in content_lower and 'must' in content_lower:
            info['ูุชุทูุจุงุช ุงูุฌูุณูุฉ'] = "ุฃุนุถุงุก ูู ุฏูู ุฃุฌูุจูุฉ ูุทููุจูู"
            foreign_info_found = True
        elif 'foreign' in content_lower and 'jury' in content_lower:
            # ูุนูููุงุช ุนุงูุฉ ุนู ุงูุฃุฌุงูุจ ูุงูุฌูุงุฒ ุงูููู
            info['ููุงุญุธุฉ ุนู ุงูุฃุฌุงูุจ'] = "ูุฐูุฑ ุงููุต ุงูุฃุฌุงูุจ ูุงูุฌูุงุฒ ุงูููู ูููู ุจุฏูู ุชูุงุตูู ูุญุฏุฏุฉ"
    
    # ุชุญุฏูุฏ ูุง ุฅุฐุง ูุงู ููุงู ูุนูููุงุช ูุงููุฉ ุนู ุงูุฃุนุถุงุก ุงูุฃุฌุงูุจ
    info['_foreign_members_info_available'] = foreign_info_found
    
    # ุงูุจุญุซ ุนู ุงูุญูุงุฏูุฉ ูุงููุฒุงูุฉ
    if 'neutral' in content_lower or 'impartial' in content_lower:
        info['ูุจุงุฏุฆ ุงูุญูู'] = "ุงูุญูุงุฏูุฉ ูุงููุฒุงูุฉ"
    
    # ุงูุจุญุซ ุนู ุชุนููู ุงูุญูุงู
    if 'appointment' in content_lower or 'appointed' in content_lower:
        info['ุขููุฉ ุงูุชุนููู'] = "ูุชู ุงูุชุนููู ูููุงู ูููุงุนุฏ ุงูุงุชุญุงุฏ"
        
        # ุงูุจุญุซ ุนู ุชูุงุตูู ุงูุชุนููู
        if 'hosting nf' in content_lower and 'recommendations' in content_lower:
            info['ุนูููุฉ ุงูุชุฑุดูุญ'] = "ุงูุงุชุญุงุฏ ุงููุณุชุถูู ููุฏู ุชุฑุดูุญุงุช ููุงุชุญุงุฏ ุงูุฏููู"
    
    # ุงูุจุญุซ ุนู ุงูุชูููู ูุงูููุงููุฉ
    if 'evaluate' in content_lower and 'recommendations' in content_lower:
        info['ุงูุชูููู ูุงูููุงููุฉ'] = "ุงูุงุชุญุงุฏ ุงูุฏููู ูููู ุงูุชุฑุดูุญุงุช ููุตุฏุฑ ุฎุทุงุจ ุงูููุงููุฉ"
    
    # ุงูุจุญุซ ุนู ุตูุงุญูุงุช ููุณุคูููุงุช
    if 'responsibilities' in content_lower or 'duties' in content_lower:
        info['ุงููุณุคูููุงุช'] = "ูุญุฏุฏุฉ ูู ุงููุต ุงููุงูููู"
    
    return info


def format_true_false_response(question: str, results: List[Dict[str, Any]], language: str = 'arabic') -> str:
    """ุชูุณูู ุงูุฅุฌุงุจุฉ ูุฃุณุฆูุฉ ุงูุตุญ ูุงูุฎุทุฃ ูุน ุชุญููู ูุงูููู ุดุงูู (ุฏุงูุฉ ูุญุณูุฉ ุฌุฐุฑูุงู)"""
    
    # ุชุญููู ุงูุณุคุงู - ุฏุนู ุตูุบ ูุชุนุฏุฏุฉ
    question_clean = question.replace('( )', '').strip()
    text_lower = question_clean.lower()
    
    # ุชุญููู ูุงูููู ูุจุงุดุฑ ููุณุคุงู ุงููุงุญุฏ ุฃู ุงููุชุนุฏุฏ
    lines = [line.strip() for line in question.split('\n') if line.strip()]
    questions = []
    
    # ูุนุงูุฌุฉ ุฐููุฉ ููุฃุณุฆูุฉ - ุฅุนุทุงุก ุฃููููุฉ ููุชุนุงูู ูุน ุงูุฃุณุฆูุฉ ุงููุฑุฏูุฉ
    for line in lines:
        line_clean = line.replace('( )', '').strip()
        
        # ุงูุชุญูู ูู ุฃู ุงูุณุทุฑ ูุญุชูู ุนูู ุฑูู ุญูููู ูู ุงูุจุฏุงูุฉ (ููุณ ุฌุฒุก ูู ุงูุฌููุฉ)
        if line.strip().startswith(tuple('123456789')) and '. ' in line[:5]:
            # ูุฐุง ุณุคุงู ูุฑูู ุญูููู
            try:
                parts = line.split('.', 1)
                if len(parts) == 2 and parts[0].strip().isdigit():
                    num = parts[0].strip()
                    text = parts[1].replace('( )', '').strip()
                    if text and len(text) > 5:
                        questions.append({'num': num, 'text': text})
            except:
                continue
        else:
            # ุณุคุงู ุบูุฑ ูุฑูู ุฃู ูุต ุนุงุฏู
            if line_clean and len(line_clean) > 5:
                questions.append({'num': '1', 'text': line_clean})
    
    # ุฅุฐุง ูู ูุฌุฏ ุฃุณุฆูุฉุ ุงุณุชุฎุฏู ุงููุต ูุงููุงู
    if not questions:
        questions = [{'num': '1', 'text': question_clean}]
    
    responses = []
    responses.append("## ุงูุฅุฌุงุจุงุช ุนูู ุงูุฃุณุฆูุฉ:")
    responses.append("")
    
    for q in questions:
        text_lower = q['text'].lower()
        answer, symbol, article_ref = analyze_true_false_question_against_legal_data(q['text'], results)
        
        responses.append(f"**{q['text']} ({symbol})**")
        responses.append(f"   ุงูุฅุฌุงุจุฉ: {answer}")
        if article_ref:
            responses.append(f"   ุงููุฑุฌุน: {article_ref}")
        responses.append("")
    
    # ุฅุถุงูุฉ ุงููุฑุงุฌุน ุงููุงููููุฉ
    responses.append("## ุงููุฑุงุฌุน ุงููุงููููุฉ:")
    responses.append("")
    
    # ุงูุนุซูุฑ ุนูู ุงููุฑุงุฌุน ุฐุงุช ุงูุตูุฉ
    relevant_articles = []
    for result in results:
        content = result.get('content', '').lower()
        title = result.get('title', '')
        
        if any(term in content for term in ['penalty', 'point', 'second', 'time']):
            if 'Article 144' in title or 'timekeeping' in content:
                relevant_articles.append(f"โข {title}: ูุญุฏุฏ ุฌุฒุงุกุงุช ุชุฌุงูุฒ ุงูููุช")
        
        if any(term in content for term in ['horse', 'breed', 'conditions']):
            if 'course' in content or 'track' in content:
                relevant_articles.append(f"โข {title}: ูุดูุฑ ุฅูู ุฃููุงุน ุงูุฎููู ูุนุงูู ูู ุงูุฃุญูุงู")
    
    if relevant_articles:
        responses.extend(relevant_articles)
    else:
        responses.append("โข ุชู ุงูุจุญุซ ูู ุฌููุน ุงูููุงุฏ ูุงูููุงุญู ุฐุงุช ุงูุตูุฉ")
    
    responses.append("")
    responses.append("**ููุงุญุธุฉ**: ุงูุฅุฌุงุจุงุช ูุจููุฉ ุนูู ุชุญููู ุดุงูู ูููุงููู ุงูุงุชุญุงุฏ ุงูุฏููู ูุงูุชูุงุท ุงูุฃูุชุงุฏ ุงูุฑุณููุฉ.")
    
    return '\n'.join(responses)


def analyze_true_false_question_against_legal_data(question: str, results: List[Dict[str, Any]]) -> tuple:
    """ุชุญููู ูุงูููู ุฏููู ูุฃุณุฆูุฉ ุงูุตุญ ูุงูุฎุทุฃ ููุงุจู ุงูุจูุงูุงุช ุงููุงููููุฉ ุงูุญููููุฉ (ุฏุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)"""
    
    text_lower = question.lower()
    
    # ุชุฌููุน ูู ุงููุญุชูู ุงููุงูููู ุงููุชุงุญ ููุชุญููู
    all_legal_content = ""
    relevant_articles = []
    
    for result in results:
        content = result.get('content', '')
        title = result.get('title', '')
        all_legal_content += f" {content}".lower()
        relevant_articles.append({'title': title, 'content': content})
    
    # ุชุญููู ุฏููู ููู ุณุคุงู
    
    # 1. ูุณุคูููุฉ ุงูุบุฑูู ุนู ุงููุนุฏุงุช
    if 'groom' in text_lower and ('equipment' in text_lower or 'condition' in text_lower):
        # ุงูุจุญุซ ูู ุงููุตูุต ุงููุงููููุฉ ุนู ูุณุคูููุงุช ุงูุบุฑูู
        groom_responsibilities = False
        equipment_mentions = False
        
        for article in relevant_articles:
            content_lower = article['content'].lower()
            if 'groom' in content_lower:
                if 'responsible' in content_lower or 'responsibility' in content_lower:
                    if 'equipment' in content_lower or 'tack' in content_lower:
                        groom_responsibilities = True
                        break
        
        if groom_responsibilities:
            return "ุตุญ - ูููุงู ูููุงุฏุฉ ุงูููุชุดูุฉ", "โ", "ุงููุต ุงููุงูููู ูุญุฏุฏ ูุณุคูููุงุช ุงูุบุฑูู"
        else:
            return "ุฎุทุฃ - ูุง ููุฌุฏ ูุต ูุงูููู ูุงุถุญ ูุญุฏุฏ ูุณุคูููุฉ ุงูุบุฑูู ุนู ุงููุนุฏุงุช", "โ", "ูุง ุชูุฌุฏ ูุงุฏุฉ ูุญุฏุฏุฉ"
    
    # 2. ุฃููุงุน ุงูุฎููู ุงููุณููุญุฉ
    elif 'horse' in text_lower and ('breed' in text_lower or 'breeds' in text_lower) and 'allowed' in text_lower:
        # ุงูุจุญุซ ุนู ูููุฏ ุนูู ุฃููุงุน ุงูุฎููู
        breed_restrictions = False
        
        for article in relevant_articles:
            content_lower = article['content'].lower()
            if 'horse' in content_lower:
                if any(word in content_lower for word in ['breed', 'type', 'bloodline', 'pedigree', 'restricted', 'prohibited', 'only']):
                    if any(word in content_lower for word in ['not allowed', 'prohibited', 'restricted', 'forbidden']):
                        breed_restrictions = True
                        break
        
        if breed_restrictions:
            return "ุฎุทุฃ - ุชูุฌุฏ ูููุฏ ุนูู ุฃููุงุน ุงูุฎููู", "โ", "ุงูููุงููู ุชุญุฏุฏ ูููุฏ ุนูู ุฃููุงุน ูุนููุฉ"
        else:
            return "ุตุญ - ูุง ุชูุฌุฏ ูููุฏ ูุงุถุญุฉ ุนูู ุฃููุงุน ุงูุฎููู ูู ุงููุตูุต ุงููุชุงุญุฉ", "โ", "ูุง ุชูุฌุฏ ูุงุฏุฉ ุชููุฏ ุฃููุงุน ุงูุฎููู"
    
    # 3. ุฌุฒุงุก ุชุฌุงูุฒ ุงูููุช - ูุตู ููุทุฉ
    elif 'time limit' in text_lower and ('ยฝ' in text_lower or 'half' in text_lower) and ('point' in text_lower or 'penalty' in text_lower):
        # ุงูุจุญุซ ุนู ูุนูููุงุช ุงูุฌุฒุงุกุงุช ุงูุฒูููุฉ
        time_penalty_found = False
        half_point_penalty = False
        article_reference = ""
        
        for article in relevant_articles:
            content_lower = article['content'].lower()
            title = article['title']
            
            if any(word in content_lower for word in ['time', 'penalty', 'second', 'point']):
                if any(word in content_lower for word in ['ยฝ', 'half', '0.5', 'every second']):
                    if 'point' in content_lower:
                        half_point_penalty = True
                        article_reference = title
                        time_penalty_found = True
                        break
                elif 'penalty' in content_lower and 'time' in content_lower:
                    time_penalty_found = True
                    article_reference = title
        
        if half_point_penalty:
            return f"ุตุญ - ูุตู ููุทุฉ ููู ุซุงููุฉ ุชุฌุงูุฒ", "โ", article_reference
        elif time_penalty_found:
            return f"ุฎุทุฃ - ุงูุฌุฒุงุก ููุณ ูุตู ููุทุฉ ููุง ูู ูุญุฏุฏ ูู ุงูููุงููู", "โ", article_reference
        else:
            return "ุบูุฑ ูุงุถุญ - ูุง ุชูุฌุฏ ูุนูููุงุช ูุงููุฉ ุนู ุฌุฒุงุกุงุช ุชุฌุงูุฒ ุงูููุช", "?", "ูุง ุชูุฌุฏ ูุงุฏุฉ ูุงุถุญุฉ"
    
    # 4. ุงููุงุนุจ ุงูุงุญุชูุงุทู - ุงูุงุณุชุจุฏุงู
    elif 'reserve' in text_lower and ('competitor' in text_lower or 'athlete' in text_lower):
        if 'injured' in text_lower or 'ill' in text_lower or 'replace' in text_lower:
            # ุงูุจุญุซ ุนู ููุงููู ุงูุงุณุชุจุฏุงู
            substitution_allowed = False
            article_reference = ""
            
            for article in relevant_articles:
                content_lower = article['content'].lower()
                title = article['title']
                
                if 'substitut' in content_lower or 'replace' in content_lower:
                    if any(word in content_lower for word in ['injured', 'ill', 'sick', 'unable']):
                        if any(word in content_lower for word in ['reserve', 'substitute', 'replacement']):
                            substitution_allowed = True
                            article_reference = title
                            break
                        elif 'athlete' in content_lower and 'can' in content_lower:
                            substitution_allowed = True
                            article_reference = title
                            break
            
            if substitution_allowed:
                return f"ุตุญ - ูููู ููุงุนุจ ุงูุงุญุชูุงุทู ุงูุงุณุชุจุฏุงู ูู ุญุงูุฉ ุงูุฅุตุงุจุฉ ุฃู ุงููุฑุถ", "โ", article_reference
            else:
                return "ุฎุทุฃ - ูุง ุชุณูุญ ุงูููุงููู ุจุงุณุชุจุฏุงู ุงููุงุนุจ ุงูุงุญุชูุงุทู", "โ", "ูุง ุชูุฌุฏ ูุงุฏุฉ ุชุณูุญ ุจุฐูู"
    
    # ุญุงูุงุช ุฃุฎุฑู - ุชุญููู ุนุงู
    return "ุบูุฑ ูุงุถุญ - ูุชุทูุจ ุชุญููู ุฅุถุงูู ูููุตูุต ุงููุงููููุฉ", "?", "ุชุญููู ุนุงู ููููุงุฏ ุงููุชุงุญุฉ"


def extract_reserve_athlete_info(content: str) -> dict:
    """ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ุงููุงุนุจูู ุงูุงุญุชูุงุท (ุฏุงูุฉ ุฌุฏูุฏุฉ ุขููุฉ)"""
    
    info = {}
    content_lower = content.lower()
    
    # ุงูุจุญุซ ุนู ููุงููู ุงูุงุณุชุจุฏุงู
    if 'substituting an athlete' in content_lower or 'substitute' in content_lower:
        if 'injured or ill' in content_lower:
            info['ุดุฑูุท ุงูุงุณุชุจุฏุงู'] = "ุงูุฅุตุงุจุฉ ุฃู ุงููุฑุถ"
        
        if 'reserve athlete' in content_lower:
            info['ููุน ุงูุจุฏูู'] = "ุงููุงุนุจ ุงูุงุญุชูุงุทู ูููุฑูู"
        
        if 'cannot then take part' in content_lower and 'same day' in content_lower:
            info['ูููุฏ ุฒูููุฉ'] = "ูุง ูููู ุงููุดุงุฑูุฉ ูู ููุณ ุงูููู"
        
        if 'come back the next day' in content_lower:
            info['ุฅููุงููุฉ ุงูุนูุฏุฉ'] = "ุงูุนูุฏุฉ ุงูููู ุงูุชุงูู ุจุดูุงุฏุฉ ุทุจูุฉ"
    
    # ุงูุจุญุซ ุนู ุชุฑููุจุฉ ุงููุฑูู
    if 'maximum of five (5) athletes' in content_lower:
        info['ุชุฑููุจุฉ ุงููุฑูู'] = "5 ุฑูุงุถููู ูุญุฏ ุฃูุตู"
    
    if 'only four (4) of the five (5) athletes' in content_lower:
        info['ุงููุดุงุฑูุฉ'] = "4 ุฑูุงุถููู ุฃุณุงุณููู + 1 ุงุญุชูุงุทู"
    
    # ุงูุจุญุซ ุนู ุญุฑูุฉ ุงูุงุฎุชูุงุฑ
    if 'freedom to join' in content_lower and 'horse' in content_lower:
        info['ุงุฎุชูุงุฑ ุงูุญุตุงู'] = "ูุฎุชุงุฑ ุจูู ุญุตุงู ุงููุงุนุจ ุงููุตุงุจ ุฃู ุงูุญุตุงู ุงูุงุญุชูุงุทู"
    
    # ุงูุจุญุซ ุนู ุงููููุฏ
    if 'may not join any other team' in content_lower:
        info['ูููุฏ ุงูุงูุถูุงู'] = "ูุง ูููู ุงูุงูุถูุงู ููุฑูู ุขุฎุฑ"
    
    if 'may not compete as an individual' in content_lower:
        info['ูููุฏ ุงููุดุงุฑูุฉ ุงููุฑุฏูุฉ'] = "ูุง ูููู ุงููุดุงุฑูุฉ ููุฑุฏ ูููุฑุฏ"
    
    return info


def extract_video_recording_positions(content: str) -> list:
    """ุงุณุชุฎุฑุงุฌ ููุงูุน ุงูุชุณุฌูู ุงููุฑุฆู ุงููุทููุจุฉ (ูุธููุฉ ุฌุฏูุฏุฉ ุขููุฉ - ูุง ุชุคุซุฑ ุนูู ุงูููุฌูุฏ)"""
    
    positions = []
    content_lower = content.lower()
    
    # ุงูุจุญุซ ุนู ุงูููุงูุน ุงููุญุฏุฏุฉ ูู ุงููุงุฏุฉ 100 (ูุญุณู - ุฅุถุงูุฉ ุขููุฉ)
    if 'the start line' in content_lower and 'before the start line' in content_lower:
        positions.append({
            'name': 'ุฎุท ุงูุจุฏุงูุฉ ููุง ูุจูู',
            'purpose': 'ูุฑุตุฏ ุฃู ุฅุณุงุกุฉ ูุนุงููุฉ ููุญุตุงู (The Start Line and before the Start Line to be able to report horse-abuse)'
        })
    
    if 'the peg line' in content_lower:
        positions.append({
            'name': 'ุฎุท ุงูุฃูุชุงุฏ',
            'purpose': 'ููุฑุงูุจุฉ ุนูููุฉ ุงูุชูุงุท ุงูุฃูุชุงุฏ (The Peg Line)'
        })
    
    if 'the finish line' in content_lower:
        positions.append({
            'name': 'ุฎุท ุงูููุงูุฉ',
            'purpose': 'ูุชุณุฌูู ุงูุชูุงุก ุงููุญุงููุฉ (The Finish Line)'
        })
    
    if 'the end of the course' in content_lower:
        positions.append({
            'name': 'ููุงูุฉ ุงููุณุงุฑ',
            'purpose': 'ูุฑุตุฏ ุฃู ุฅุณุงุกุฉ ูุนุงููุฉ ููุญุตุงู (The End of the Course to be able to report horse abuse)'
        })
    
    # ุฅุฐุง ูู ุชูุฌุฏ ุชูุงุตูู ูุญุฏุฏุฉุ ุงุณุชุฎุฑุฌ ูู ุงููุต ุงูุนุงู
    if not positions and ('video' in content_lower or 'recording' in content_lower):
        # ุงูุจุญุซ ุนู ุงูููุท ุงูุนุงู ูู ุงููุต
        import re
        
        # ุงูุจุญุซ ุนู ุงูููุงูุน ุงููุฐููุฑุฉ ูู ุงููุต
        position_patterns = [
            (r'start.*line.*before.*start.*line', 'ุฎุท ุงูุจุฏุงูุฉ ููุง ูุจูู', 'ูุฑุตุฏ ุฅุณุงุกุฉ ูุนุงููุฉ ุงูุญุตุงู'),
            (r'peg.*line', 'ุฎุท ุงูุฃูุชุงุฏ', 'ููุฑุงูุจุฉ ุนูููุฉ ุงูุชูุงุท ุงูุฃูุชุงุฏ'),
            (r'finish.*line', 'ุฎุท ุงูููุงูุฉ', 'ูุชุณุฌูู ุงูุชูุงุก ุงููุญุงููุฉ'),
            (r'end.*of.*course', 'ููุงูุฉ ุงููุณุงุฑ', 'ูุฑุตุฏ ุฅุณุงุกุฉ ูุนุงููุฉ ุงูุญุตุงู')
        ]
        
        for pattern, name, purpose in position_patterns:
            if re.search(pattern, content_lower):
                positions.append({'name': name, 'purpose': purpose})
    
    return positions


class handler(BaseHTTPRequestHandler):
    """Advanced Expert Vercel handler for comprehensive legal analysis"""
    
    def _set_cors_headers(self):
        """Set CORS headers"""
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')  
        self.send_header('Access-Control-Allow-Headers', 'Content-Type')
        self.send_header('Content-Type', 'application/json; charset=utf-8')
    
    def _send_json_response(self, status_code: int, data: dict):
        """Send JSON response with enhanced cache busting"""
        self.send_response(status_code)
        self._set_cors_headers()
        self.send_header('Cache-Control', 'no-cache, no-store, must-revalidate')
        self.send_header('Pragma', 'no-cache')
        self.send_header('Expires', '0')
        self.send_header('X-Content-Version', '6.0.0')
        self.send_header('X-Expert-System', 'true')
        self.end_headers()
        json_response = json.dumps(data, ensure_ascii=False).encode('utf-8')
        self.wfile.write(json_response)
    
    def do_OPTIONS(self):
        """Handle CORS preflight requests"""
        self.send_response(200)
        self._set_cors_headers()
        self.end_headers()
    
    def do_GET(self):
        """Handle GET request - Enhanced API info"""
        api_info = {
            "message": "ITPF Legal Answer System - Advanced Expert",
            "version": "6.0.0",
            "status": "active",
            "system_type": "Advanced Expert Legal System",
            "endpoint": "/api/answer",
            "method": "POST",
            "features": [
                "๐ง ุงูุชุญููู ุงููุงูููู ุงูุฎุจูุฑ ุงููุชูุฏู",
                "ููู ุนููู ููุณูุงู ูุงูุนูุงูุงุช ุงููุงููููุฉ",
                "ุชุญููู ุงููุตูุต ุจุฎูุงุฑุฒููุงุช ูุชุทูุฑุฉ",
                "ุฎุฑูุทุฉ ุงูููุงููู ุงููุงููููุฉ ุงูุฐููุฉ",
                "ุงูุจุญุซ ุงูุฏูุงูู ุงููุชูุฏู",
                "ุชุญููู ุชุฑุงุจุท ุงููุตูุต ูุงูุชุณูุณู ุงูููุทูู",
                "ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุงููุฉ (55 ูุงุฏุฉ + 23 ููุญู)",
                "ุงูุญูุธ ุงูุชุงู ูููุตูุต ุจุฏูู ุงูุชุทุงุน ุญุฑู",
                "ุชุตููู ุงูุฃุณุฆูุฉ ูููู ุงูููุงูุง",
                "ุชุญููู ุงูููุงุตูุงุช ุงูุชูููุฉ ูุงูุฅุฌุฑุงุกุงุช"
            ],
            "data_integrity": {
                "arabic_articles": "55 + appendices 9,10",
                "english_articles": "55 + appendices 9,10", 
                "text_preservation": "Complete - no truncation",
                "last_verified": "2025-01-10T15:30:00",
                "expert_features": "Deep legal understanding, Advanced search algorithms, Contextual analysis"
            },
            "expert_capabilities": {
                "legal_ontology": "Comprehensive concept mapping",
                "semantic_analysis": "Advanced NLP processing",
                "intent_recognition": "Multi-pattern question analysis",
                "contextual_search": "Deep understanding algorithms",
                "relationship_mapping": "Inter-text connection analysis"
            }
        }
        self._send_json_response(200, api_info)
    
    def do_POST(self):
        """Handle POST request - Advanced expert question answering"""
        try:
            # Read request
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length).decode('utf-8')
            
            try:
                data = json.loads(post_data)
            except json.JSONDecodeError:
                self._send_json_response(400, {
                    "success": False,
                    "message": "Invalid JSON in request body",
                    "system_type": "Advanced Expert Legal System"
                })
                return
            
            question = data.get('question', '').strip()
            language = data.get('language', 'arabic')
            
            if not question:
                self._send_json_response(400, {
                    "success": False,
                    "message": "Question is required",
                    "system_type": "Advanced Expert Legal System"
                })
                return
            
            print(f"Expert System processing question: {question}")
            
            # Load comprehensive legal data
            arabic_data, english_data = load_legal_data()
            
            if not arabic_data and not english_data:
                self._send_json_response(500, {
                    "success": False,
                    "message": "Legal database unavailable",
                    "system_type": "Advanced Expert Legal System"
                })
                return
            
            # Advanced expert search - STRICT LANGUAGE SEPARATION
            all_results = []
            if language == 'arabic' and arabic_data:
                # Use ONLY Arabic legal database for Arabic questions
                arabic_results = legal_analyzer.enhanced_intelligent_search(question, arabic_data, 'arabic')
                all_results.extend(arabic_results)
                
            elif language == 'english' and english_data:
                # Use ONLY English legal database for English questions
                english_results = legal_analyzer.enhanced_intelligent_search(question, english_data, 'english')
                all_results.extend(english_results)
            
            # Advanced relevance sorting
            all_results.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            # Create expert legal analysis with enhanced formatting option
            intent_analysis = legal_analyzer.analyze_question_intent(question)
            
            # ุชุญุฏูุฏ ููุน ุงูุณุคุงู ูุงุฎุชูุงุฑ ุงูุชูุณูู ุงูููุงุณุจ
            question_type = classify_question_intelligently(question, all_results)
            print(f"๐ฏ Question classified as: {question_type}")
            
            # ุงุณุชุฎุฏุงู ุงูุชูุณูู ุงููุญุณู ุญุณุจ ููุน ุงูุณุคุงู
            try:
                if question_type == 'penalties':
                    expert_analysis = format_penalty_response(question, all_results)
                    print("๐ฏ Using penalty response formatting")
                elif question_type == 'technical_specs':
                    expert_analysis = format_technical_specs_response(question, all_results)
                    print("๐ฏ Using technical specs response formatting")
                elif question_type == 'complex_scoring':
                    expert_analysis = format_complex_scoring_response(question, all_results)
                    print("๐ฏ Using complex scoring response formatting")
                elif question_type == 'responsibilities':
                    expert_analysis = format_responsibilities_response(question, all_results)
                    print("๐ฏ Using responsibilities response formatting")
                elif question_type == 'definitions':
                    expert_analysis = format_definitions_response(question, all_results)
                    print("๐ฏ Using definitions response formatting")
                else:
                    # ุงุณุชุฎุฏุงู ุงูุชูุณูู ุงููุญุณู ููุฃุณุฆูุฉ ุงูุนุงูุฉ
                    enhanced_keywords = ['ุชุฃุฎุฑ', 'ุนููุจุฉ', 'ุงุณุชุซูุงุก', 'ุซุงููุฉ', 'ูุชู', 'ุงุณุชุฆูุงู', 'ุงุนุชุฑุงุถ', 'ุชุจุฏุฃ', 'ุชูุชูู', 
                                        'ุฅุฌุฑุงุกุงุช', 'ุงุฑุงุฏ ุงููุฑูู', 'ูุงูู ุงูุงุฌุฑุงุกุงุช', 'minimum', 'maximum', 'length', 'size', 
                                        'cm', 'meter', 'specifications', 'a)', 'b)', 'c)']
                    
                    if (ADVANCED_REASONING_AVAILABLE and 
                        any(keyword in question.lower() for keyword in enhanced_keywords) and
                        len(all_results) >= 1):
                        expert_analysis = format_enhanced_legal_response(question, all_results, intent_analysis, language)
                        print("๐ฏ Using enhanced general response formatting")
                    else:
                        expert_analysis = create_expert_legal_analysis(question, all_results, language)
                        print("๐ฏ Using standard response formatting")
            except Exception as e:
                print(f"โ๏ธ Specialized formatting failed, using standard: {str(e)}")
                expert_analysis = create_expert_legal_analysis(question, all_results, language)
            
            # Prepare enhanced references for display
            legal_references = []
            for result in all_results[:6]:
                article_prefix = "Article" if language == 'english' else "ุงููุงุฏุฉ"
                legal_references.append({
                    "title": f"{article_prefix} {result['article_number']}: {result['title']}",
                    "content": result['content'][:400] + "..." if len(result['content']) > 400 else result['content'],
                    "article_number": result['article_number'],
                    "relevance_score": result['relevance_score'],
                    "content_type": result.get('content_type', 'article'),
                    "matches_intent": result.get('matches_intent', 'general'),
                    "expert_processed": True
                })
            
            # Enhanced response
            api_response = {
                "success": True,
                "legal_analysis": expert_analysis,
                "legal_references": legal_references,
                "metadata": {
                    "question": question,
                    "language": language,
                    "articles_found": len(all_results),
                    "system_type": "Advanced Expert Legal System",
                    "expert_powered": True,
                    "text_preservation": "Complete - no truncation",
                    "version": "7.0.0-Enhanced", 
                    "cache_version": "24.0",
                    "timestamp": "2025-01-10T15:30:00",
                    "processing_time": "< 1 second",
                    "expert_features": {
                        "legal_ontology_used": True,
                        "semantic_analysis": True,
                        "intent_recognition": True,
                        "contextual_understanding": True,
                        "relationship_mapping": True
                    },
                    "data_sources": {
                        "arabic_articles": len(arabic_data.get('articles', [])),
                        "english_articles": len(english_data.get('articles', [])),
                        "arabic_appendices": len(arabic_data.get('appendices', [])),
                        "english_appendices": len(english_data.get('appendices', []))
                    }
                }
            }
            
            self._send_json_response(200, api_response)
            
        except Exception as e:
            import traceback
            print(f"Expert System Error processing question: {str(e)}")
            print(f"Full traceback: {traceback.format_exc()}")
            self._send_json_response(500, {
                "success": False,
                "message": f"ุฎุทุฃ ูู ูุนุงูุฌุฉ ุงูุณุคุงู: {str(e)}",
                "error_details": str(e),
                "system_type": "Advanced Expert Legal System"
            })