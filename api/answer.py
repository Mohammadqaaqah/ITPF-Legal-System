#!/usr/bin/env python3
"""
ITPF Legal System - Complete DeepSeek Integration
Ù†Ø¸Ø§Ù… ITPF Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…Ø¹ ØªÙƒØ§Ù…Ù„ DeepSeek ÙƒØ§Ù…Ù„ ÙˆÙ…ØªÙ‚Ø¯Ù…
"""

import json
import os
import re
import requests
from typing import Dict, Any, List, Tuple
from http.server import BaseHTTPRequestHandler

class ITTPFLegalSystem:
    """Ù†Ø¸Ø§Ù… ITPF Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¹ DeepSeek"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        self.arabic_data = {}
        self.english_data = {}
        self.deepseek_api_key = None
        self.deepseek_url = "https://api.deepseek.com/v1/chat/completions"
        
        # ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self._load_databases()
        
        # ØªÙ‡ÙŠØ¦Ø© Ù…ÙØ§ØªÙŠØ­ DeepSeek
        self._initialize_deepseek()
    
    def _load_databases(self):
        """ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"""
        try:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            arabic_file = os.path.join(script_dir, 'arabic_legal_rules_complete_authentic.json')
            with open(arabic_file, 'r', encoding='utf-8') as f:
                self.arabic_data = json.load(f)
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©  
            english_file = os.path.join(script_dir, 'english_legal_rules_complete_authentic.json')
            with open(english_file, 'r', encoding='utf-8') as f:
                self.english_data = json.load(f)
                
            print(f"âœ… Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù…Ù„Ø© - Ø¹Ø±Ø¨ÙŠ: {len(self.arabic_data['articles'])} Ù…Ø§Ø¯Ø© + {len(self.arabic_data['appendices'])} Ù…Ù„Ø­Ù‚")
            print(f"âœ… Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù…Ù„Ø© - Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ: {len(self.english_data['articles'])} Ù…Ø§Ø¯Ø© + {len(self.english_data['appendices'])} Ù…Ù„Ø­Ù‚")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
    
    def _initialize_deepseek(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…ÙØ§ØªÙŠØ­ DeepSeek API"""
        potential_keys = ['DEEPSEEK_API_KEY', 'DEEPSEEK_API_KEY_1', 'DEEPSEEK_API_KEY_2', 'DEEPSEEK_API_KEY_3']
        
        for key_name in potential_keys:
            value = os.environ.get(key_name)
            if value and len(value) > 20:
                self.deepseek_api_key = value
                print(f"ğŸ”‘ DeepSeek API Key Ø¬Ø§Ù‡Ø²: {key_name}")
                break
        
        if not self.deepseek_api_key:
            print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙØ§ØªÙŠØ­ DeepSeek API!")
    
    def search_legal_content(self, question: str, language: str) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ"""
        data = self.arabic_data if language == 'arabic' else self.english_data
        results = []
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©
        keywords = self._extract_keywords(question, language)
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        for article in data['articles']:
            score = self._calculate_relevance(question, keywords, article['content'], language)
            if score > 0:
                results.append({
                    'type': 'article',
                    'article_number': article['article_number'],
                    'title': article.get('title', f'Ø§Ù„Ù…Ø§Ø¯Ø© {article["article_number"]}'),
                    'content': article['content'][:500],  # Ø£ÙˆÙ„ 500 Ø­Ø±Ù
                    'score': score
                })
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù„Ø§Ø­Ù‚
        for appendix in data['appendices']:
            score = self._calculate_relevance(question, keywords, str(appendix['content']), language)
            if score > 0:
                results.append({
                    'type': 'appendix', 
                    'appendix_number': appendix['appendix_number'],
                    'title': appendix.get('title', f'Ù…Ù„Ø­Ù‚ {appendix["appendix_number"]}'),
                    'content': str(appendix['content'])[:500],
                    'score': score
                })
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„ØµÙ„Ø©
        results.sort(key=lambda x: x['score'], reverse=True)
        
        return results[:10]  # Ø£ÙØ¶Ù„ 10 Ù†ØªØ§Ø¦Ø¬
    
    def _extract_keywords(self, text: str, language: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        if language == 'arabic':
            # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø¹Ø±Ø¨ÙŠØ©
            legal_terms = ['ÙØ±ÙŠÙ‚', 'Ù…ØªØ³Ø§Ø¨Ù‚', 'Ù†Ù‚Ø§Ø·', 'Ø¬Ø²Ø§Ø¡', 'Ù…Ø³Ø§Ø¨Ù‚Ø©', 'Ø®ÙŠÙ„', 'Ø±Ù…Ø­', 'Ø³ÙŠÙ', 'ÙˆØªØ¯', 'Ø­ÙƒØ§Ù…', 'Ù‚Ø§Ù†ÙˆÙ†', 'Ù…Ø§Ø¯Ø©']
        else:
            legal_terms = ['team', 'rider', 'points', 'penalty', 'competition', 'horse', 'lance', 'sword', 'peg', 'judge', 'rule', 'article']
        
        words = re.findall(r'\b\w+\b', text.lower())
        keywords = [word for word in words if len(word) > 2]
        keywords.extend([term for term in legal_terms if term in text.lower()])
        
        return list(set(keywords))
    
    def _calculate_relevance(self, question: str, keywords: List[str], content: str, language: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„ØµÙ„Ø©"""
        score = 0.0
        content_lower = content.lower()
        question_lower = question.lower()
        
        # ØªØ·Ø§Ø¨Ù‚ Ù…Ø¨Ø§Ø´Ø± Ù…Ø¹ Ø§Ù„Ø³Ø¤Ø§Ù„
        if any(word in content_lower for word in question_lower.split() if len(word) > 2):
            score += 10.0
            
        # ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        for keyword in keywords:
            if keyword in content_lower:
                score += 5.0
        
        # ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… (Ù…Ù‡Ù… Ù„Ù„Ù…ÙˆØ§Ø¯ ÙˆØ§Ù„Ø¬Ø²Ø§Ø¡Ø§Øª)
        numbers_in_question = re.findall(r'\d+', question)
        numbers_in_content = re.findall(r'\d+', content)
        common_numbers = set(numbers_in_question) & set(numbers_in_content)
        score += len(common_numbers) * 15.0
        
        return score
    
    def generate_deepseek_response(self, question: str, legal_context: List[Dict[str, Any]], language: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ø°ÙƒÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DeepSeek"""
        
        if not self.deepseek_api_key:
            return self._generate_fallback_response(question, legal_context, language)
        
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù„Ù€ DeepSeek
            context_text = ""
            for item in legal_context[:5]:  # Ø£ÙØ¶Ù„ 5 Ù†ØªØ§Ø¦Ø¬
                if item['type'] == 'article':
                    context_text += f"Ø§Ù„Ù…Ø§Ø¯Ø© {item['article_number']}: {item['title']}\n{item['content']}\n\n"
                else:
                    context_text += f"Ù…Ù„Ø­Ù‚ {item['appendix_number']}: {item['title']}\n{item['content']}\n\n"
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù„Ù„ØºØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
            if language == 'arabic':
                system_prompt = """Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ù„Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø£ÙˆØªØ§Ø¯ (ITPF). 
                
Ù…Ù‡Ù…ØªÙƒ:
1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¨Ø¹Ù…Ù‚
2. ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø­Ø¯Ø¯Ø© ÙˆØ¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…ØªØ§Ø­Ø©
3. ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ÙˆØ§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ù…Ø­Ø¯Ø¯
4. Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·

Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
- Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©
- Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¹Ù…Ù„ÙŠ ÙˆÙ…Ø­Ø¯Ø¯
- Ø§Ø°ÙƒØ± Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯ ÙˆØ§Ù„Ù…Ù„Ø§Ø­Ù‚ Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
- ØªØ¬Ù†Ø¨ Ø®Ù„Ø· Ø§Ù„Ù„ØºØ§Øª"""
                
                user_prompt = f"""Ø§Ù„Ø³Ø¤Ø§Ù„: {question}

Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©:
{context_text}

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…Ø­Ø¯Ø¯ ÙˆÙ…ÙØµÙ„ Ù„Ù„Ø³Ø¤Ø§Ù„ØŒ Ù…Ø¹ Ø°ÙƒØ± Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©."""
                
            else:
                system_prompt = """You are a legal expert specialized in the International Tent Pegging Federation (ITPF) rules.

Your task:
1. Analyze the legal question thoroughly  
2. Provide specific and practical answers based on available laws
3. Avoid general answers and focus on the specific scenario
4. Answer in English only

Instructions:
- Use only the available legal references
- Provide practical and specific legal analysis
- Mention relevant article and appendix numbers
- Avoid mixing languages"""
                
                user_prompt = f"""Question: {question}

Available Legal References:
{context_text}

Required: Specific and detailed legal analysis of the question, citing relevant legal articles."""
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¥Ù„Ù‰ DeepSeek
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.3,
                "max_tokens": 800
            }
            
            headers = {
                "Authorization": f"Bearer {self.deepseek_api_key}",
                "Content-Type": "application/json"
            }
            
            print(f"ğŸ¤– Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ DeepSeek API...")
            
            response = requests.post(self.deepseek_url, json=payload, headers=headers, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    ai_response = result['choices'][0]['message']['content']
                    print(f"âœ… DeepSeek Ù†Ø¬Ø­: {len(ai_response)} Ø­Ø±Ù")
                    return ai_response
                else:
                    print(f"âŒ Ø§Ø³ØªØ¬Ø§Ø¨Ø© DeepSeek ØºÙŠØ± ØµØ­ÙŠØ­Ø©: {result}")
                    return self._generate_fallback_response(question, legal_context, language)
            else:
                print(f"âŒ Ø®Ø·Ø£ DeepSeek API {response.status_code}: {response.text}")
                return self._generate_fallback_response(question, legal_context, language)
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ DeepSeek: {str(e)}")
            return self._generate_fallback_response(question, legal_context, language)
    
    def _generate_fallback_response(self, question: str, legal_context: List[Dict[str, Any]], language: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¹Ù†Ø¯ ÙØ´Ù„ DeepSeek"""
        if language == 'arabic':
            response = "## Ø§Ù„Ø®Ù„Ø§ØµØ© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©\n\n"
            response += "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…ØªØ§Ø­Ø©:\n\n"
            
            for i, item in enumerate(legal_context[:3], 1):
                if item['type'] == 'article':
                    response += f"**{i}. Ø§Ù„Ù…Ø§Ø¯Ø© {item['article_number']}**: {item['title']}\n"
                    response += f"   {item['content'][:200]}...\n\n"
                else:
                    response += f"**{i}. Ù…Ù„Ø­Ù‚ {item['appendix_number']}**: {item['title']}\n"
                    response += f"   {item['content'][:200]}...\n\n"
            
            return response
        else:
            response = "## Legal Summary\n\n"
            response += "Based on analysis of available laws:\n\n"
            
            for i, item in enumerate(legal_context[:3], 1):
                if item['type'] == 'article':
                    response += f"**{i}. Article {item['article_number']}**: {item['title']}\n"
                    response += f"   {item['content'][:200]}...\n\n"
                else:
                    response += f"**{i}. Appendix {item['appendix_number']}**: {item['title']}\n"
                    response += f"   {item['content'][:200]}...\n\n"
            
            return response

    def process_question(self, question: str, language: str = 'arabic') -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ
        legal_context = self.search_legal_content(question, language)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒÙŠØ©
        ai_response = self.generate_deepseek_response(question, legal_context, language)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        references = []
        for item in legal_context[:6]:
            ref = {
                'type': item['type'],
                'number': item.get('article_number') or item.get('appendix_number'),
                'title': item['title'], 
                'content': item['content'][:300],
                'relevance_score': item['score']
            }
            references.append(ref)
        
        return {
            'success': True,
            'legal_analysis': ai_response,
            'legal_references': references,
            'metadata': {
                'question': question,
                'language': language,
                'references_found': len(legal_context),
                'deepseek_used': bool(self.deepseek_api_key),
                'articles_count': len(self.arabic_data['articles']),
                'appendices_count': len(self.arabic_data['appendices'])
            }
        }

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø«ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ
itpf_system = ITTPFLegalSystem()

def handler(event, context):
    """Ù…Ø¹Ø§Ù„Ø¬ Vercel Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    try:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø·Ù„Ø¨
        if hasattr(event, 'get_json'):
            data = event.get_json()
        else:
            data = json.loads(event.get('body', '{}'))
        
        question = data.get('question', '')
        language = data.get('language', 'arabic')
        
        if not question:
            return {
                'statusCode': 400,
                'headers': {'Content-Type': 'application/json; charset=utf-8'},
                'body': json.dumps({'error': 'Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø·Ù„ÙˆØ¨'}, ensure_ascii=False)
            }
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„
        result = itpf_system.process_question(question, language)
        
        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json; charset=utf-8',
                'Access-Control-Allow-Origin': '*',
                'Cache-Control': 'no-cache'
            },
            'body': json.dumps(result, ensure_ascii=False, indent=2)
        }
        
    except Exception as e:
        return {
            'statusCode': 500,
            'headers': {'Content-Type': 'application/json; charset=utf-8'},
            'body': json.dumps({'error': str(e)}, ensure_ascii=False)
        }

# Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø­Ù„ÙŠ
if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø­Ù„ÙŠØ§Ù‹
    test_question = "ÙØ±ÙŠÙ‚ Ø­ØµÙ„ Ø¹Ù„Ù‰ 15 Ù†Ù‚Ø·Ø© Ø¬Ø²Ø§Ø¡ØŒ Ù…Ø§ Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØŸ"
    result = itpf_system.process_question(test_question, 'arabic')
    print(json.dumps(result, ensure_ascii=False, indent=2))