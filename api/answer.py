#!/usr/bin/env python3
"""
ITPF Legal System - Complete DeepSeek Integration
Ù†Ø¸Ø§Ù… ITPF Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…Ø¹ ØªÙƒØ§Ù…Ù„ DeepSeek ÙƒØ§Ù…Ù„ ÙˆÙ…ØªÙ‚Ø¯Ù…
"""

import json
import os
import re
import requests
from typing import Dict, Any, List, Tuple
from http.server import BaseHTTPRequestHandler

class ITTPFLegalSystem:
    """Ù†Ø¸Ø§Ù… ITPF Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¹ DeepSeek"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        self.arabic_data = {}
        self.english_data = {}
        self.deepseek_api_key = None
        self.deepseek_url = "https://api.deepseek.com/v1/chat/completions"
        
        # ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self._load_databases()
        
        # ØªÙ‡ÙŠØ¦Ø© Ù…ÙØ§ØªÙŠØ­ DeepSeek
        self._initialize_deepseek()
    
    def _load_databases(self):
        """ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"""
        try:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            arabic_file = os.path.join(script_dir, 'arabic_legal_rules_complete_authentic.json')
            with open(arabic_file, 'r', encoding='utf-8') as f:
                self.arabic_data = json.load(f)
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©  
            english_file = os.path.join(script_dir, 'english_legal_rules_complete_authentic.json')
            with open(english_file, 'r', encoding='utf-8') as f:
                self.english_data = json.load(f)
                
            print(f"âœ… Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù…Ù„Ø© - Ø¹Ø±Ø¨ÙŠ: {len(self.arabic_data['articles'])} Ù…Ø§Ø¯Ø© + {len(self.arabic_data['appendices'])} Ù…Ù„Ø­Ù‚")
            print(f"âœ… Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù…Ù„Ø© - Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ: {len(self.english_data['articles'])} Ù…Ø§Ø¯Ø© + {len(self.english_data['appendices'])} Ù…Ù„Ø­Ù‚")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
    
    def _initialize_deepseek(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…ÙØ§ØªÙŠØ­ DeepSeek API Ù…Ù† Ø¨ÙŠØ¦Ø© Vercel"""
        # Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© ÙÙŠ Ø¨ÙŠØ¦Ø© Vercel
        potential_keys = [
            'DEEPSEEK_API_KEY',
            'DEEPSEEK_API_KEY_1', 
            'DEEPSEEK_API_KEY_2',
            'DEEPSEEK_API_KEY_3',
            'deepseek_api_key',
            'DEEPSEEK_TOKEN',
            'deepseek_token'
        ]
        
        print("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…ÙØ§ØªÙŠØ­ DeepSeek ÙÙŠ Ø¨ÙŠØ¦Ø© Vercel...")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© ÙƒÙ„ Ù…ÙØªØ§Ø­ Ù…Ù† Ø§Ù„Ø¨ÙŠØ¦Ø©
        for key_name in potential_keys:
            try:
                value = os.environ.get(key_name, '').strip()
                if value and len(value) > 20 and value.startswith('sk-'):
                    self.deepseek_api_key = value
                    print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ DeepSeek ØµØ­ÙŠØ­: {key_name}")
                    print(f"ğŸ”‘ Ø·ÙˆÙ„ Ø§Ù„Ù…ÙØªØ§Ø­: {len(value)} - Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„Ø£ÙˆÙ„: {value[:12]}...")
                    return
                elif value:
                    print(f"âš ï¸ Ù…ÙØªØ§Ø­ ØºÙŠØ± ØµØ­ÙŠØ­ ÙÙŠ {key_name}: Ø·ÙˆÙ„={len(value)}, ÙŠØ¨Ø¯Ø£ Ø¨Ù€ sk-={value.startswith('sk-') if value else False}")
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {key_name}: {str(e)}")
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø¬Ù…ÙŠØ¹ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù„Ù„ØªØ´Ø®ÙŠØµ (ÙÙ‚Ø· ÙÙŠ Ø§Ù„ØªØ·ÙˆÙŠØ±)
        all_env_vars = {k: v[:10] + "..." if len(v) > 10 else v for k, v in os.environ.items() if 'deepseek' in k.lower() or 'api' in k.lower()}
        if all_env_vars:
            print(f"ğŸ” Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©: {list(all_env_vars.keys())}")
        else:
            print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…ÙØ§ØªÙŠØ­ API ÙÙŠ Ø¨ÙŠØ¦Ø© Vercel!")
            
        if not self.deepseek_api_key:
            print("âŒ ØªØ¹Ø°Ø± Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ DeepSeek API ØµØ­ÙŠØ­ ÙÙŠ Ø¨ÙŠØ¦Ø© Vercel!")
            print("ğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¶Ø§ÙØ© Ù…ÙØªØ§Ø­ DeepSeek ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Environment Variables ÙÙŠ Vercel")
    
    def search_legal_content(self, question: str, language: str) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ"""
        data = self.arabic_data if language == 'arabic' else self.english_data
        results = []
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©
        keywords = self._extract_keywords(question, language)
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        for article in data['articles']:
            score = self._calculate_relevance(question, keywords, article['content'], language)
            if score > 0:
                results.append({
                    'type': 'article',
                    'article_number': article['article_number'],
                    'title': article.get('title', f'Ø§Ù„Ù…Ø§Ø¯Ø© {article["article_number"]}'),
                    'content': article['content'][:500],  # Ø£ÙˆÙ„ 500 Ø­Ø±Ù
                    'score': score
                })
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù„Ø§Ø­Ù‚
        for appendix in data['appendices']:
            score = self._calculate_relevance(question, keywords, str(appendix['content']), language)
            if score > 0:
                results.append({
                    'type': 'appendix', 
                    'appendix_number': appendix['appendix_number'],
                    'title': appendix.get('title', f'Ù…Ù„Ø­Ù‚ {appendix["appendix_number"]}'),
                    'content': str(appendix['content'])[:500],
                    'score': score
                })
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„ØµÙ„Ø©
        results.sort(key=lambda x: x['score'], reverse=True)
        
        return results[:10]  # Ø£ÙØ¶Ù„ 10 Ù†ØªØ§Ø¦Ø¬
    
    def _extract_keywords(self, text: str, language: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        if language == 'arabic':
            # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø¹Ø±Ø¨ÙŠØ©
            legal_terms = ['ÙØ±ÙŠÙ‚', 'Ù…ØªØ³Ø§Ø¨Ù‚', 'Ù†Ù‚Ø§Ø·', 'Ø¬Ø²Ø§Ø¡', 'Ù…Ø³Ø§Ø¨Ù‚Ø©', 'Ø®ÙŠÙ„', 'Ø±Ù…Ø­', 'Ø³ÙŠÙ', 'ÙˆØªØ¯', 'Ø­ÙƒØ§Ù…', 'Ù‚Ø§Ù†ÙˆÙ†', 'Ù…Ø§Ø¯Ø©']
        else:
            legal_terms = ['team', 'rider', 'points', 'penalty', 'competition', 'horse', 'lance', 'sword', 'peg', 'judge', 'rule', 'article']
        
        words = re.findall(r'\b\w+\b', text.lower())
        keywords = [word for word in words if len(word) > 2]
        keywords.extend([term for term in legal_terms if term in text.lower()])
        
        return list(set(keywords))
    
    def _calculate_relevance(self, question: str, keywords: List[str], content: str, language: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„ØµÙ„Ø©"""
        score = 0.0
        content_lower = content.lower()
        question_lower = question.lower()
        
        # ØªØ·Ø§Ø¨Ù‚ Ù…Ø¨Ø§Ø´Ø± Ù…Ø¹ Ø§Ù„Ø³Ø¤Ø§Ù„
        if any(word in content_lower for word in question_lower.split() if len(word) > 2):
            score += 10.0
            
        # ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        for keyword in keywords:
            if keyword in content_lower:
                score += 5.0
        
        # ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… (Ù…Ù‡Ù… Ù„Ù„Ù…ÙˆØ§Ø¯ ÙˆØ§Ù„Ø¬Ø²Ø§Ø¡Ø§Øª)
        numbers_in_question = re.findall(r'\d+', question)
        numbers_in_content = re.findall(r'\d+', content)
        common_numbers = set(numbers_in_question) & set(numbers_in_content)
        score += len(common_numbers) * 15.0
        
        return score
    
    def generate_deepseek_response(self, question: str, legal_context: List[Dict[str, Any]], language: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ø°ÙƒÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DeepSeek"""
        
        # Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙØªØ§Ø­ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ØªØ§Ø­Ø§Ù‹
        if not self.deepseek_api_key:
            self._initialize_deepseek()
        
        if not self.deepseek_api_key:
            print("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ù…ÙØ§ØªÙŠØ­ DeepSeek Ù…Ù† Ø§Ù„Ø¨ÙŠØ¦Ø©...")
            return self._generate_fallback_response(question, legal_context, language)
        
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù„Ù€ DeepSeek
            context_text = ""
            for item in legal_context[:5]:  # Ø£ÙØ¶Ù„ 5 Ù†ØªØ§Ø¦Ø¬
                if item['type'] == 'article':
                    context_text += f"Ø§Ù„Ù…Ø§Ø¯Ø© {item['article_number']}: {item['title']}\n{item['content']}\n\n"
                else:
                    context_text += f"Ù…Ù„Ø­Ù‚ {item['appendix_number']}: {item['title']}\n{item['content']}\n\n"
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù„Ù„ØºØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
            if language == 'arabic':
                system_prompt = """Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ù„Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø£ÙˆØªØ§Ø¯ (ITPF). 

## Ù…Ù‡Ù…ØªÙƒ:
1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¨Ø¹Ù…Ù‚ ÙˆØ¯Ù‚Ø©
2. ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø­Ø¯Ø¯Ø© ÙˆØ¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…ØªØ§Ø­Ø©
3. ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ÙˆØ§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ù…Ø­Ø¯Ø¯
4. Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø· Ù…Ø¹ Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ù‡Ù†ÙŠ

## Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©:
- Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©
- Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¹Ù…Ù„ÙŠ ÙˆÙ…Ø­Ø¯Ø¯
- Ø§Ø°ÙƒØ± Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯ ÙˆØ§Ù„Ù…Ù„Ø§Ø­Ù‚ Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© Ø¨ÙˆØ¶ÙˆØ­
- ØªØ¬Ù†Ø¨ Ø®Ù„Ø· Ø§Ù„Ù„ØºØ§Øª Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹
- Ø§Ù†ØªØ¨Ù‡ Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆØ§Ù„Ø®ØµÙˆÙ…Ø§Øª (6 Ù†Ù‚Ø§Ø· Ù„Ù„Ø­Ù…Ù„ØŒ 4 Ù„Ù„Ù†Ø²Ø¹ØŒ 2 Ù„Ù„Ø·Ø¹Ù†)
- Ø§Ù†ØªØ¨Ù‡ Ù„Ø¬Ø¯ÙˆÙ„ Ø®ØµÙˆÙ…Ø§Øª Ø§Ù„ÙˆÙ‚Øª (0.5 Ù†Ù‚Ø·Ø© Ù„ÙƒÙ„ Ø«Ø§Ù†ÙŠØ© ØªØ¬Ø§ÙˆØ²)

## ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¯Ù‚ÙŠÙ‚:

### ğŸ” **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…:**

#### **1ï¸âƒ£ [Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø£ÙˆÙ„]:**
**Ø§Ù„Ù…Ø§Ø¯Ø© [Ø±Ù‚Ù…]: [Ø§Ø³Ù… Ø§Ù„Ù…Ø§Ø¯Ø©]**
- âœ… Ø£Ùˆ âŒ [Ø§Ù„ØªØ­Ù„ÙŠÙ„]
- ğŸ“Š [Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø¥Ù† ÙˆØ¬Ø¯Øª]

#### **2ï¸âƒ£ [Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø«Ø§Ù†ÙŠ]:**
**Ø§Ù„Ù…Ø§Ø¯Ø© [Ø±Ù‚Ù…]: [Ø§Ø³Ù… Ø§Ù„Ù…Ø§Ø¯Ø©]**  
- âš–ï¸ [Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ]

### ğŸ¯ **Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:**
- **Ø§Ù„Ø­ÙƒÙ…:** [Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯]
- **Ø§Ù„Ø£Ø³Ø§Ø³ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ:** Ø§Ù„Ù…ÙˆØ§Ø¯ [Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯]"""
                
                user_prompt = f"""Ø§Ù„Ø³Ø¤Ø§Ù„: {question}

Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©:
{context_text}

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…Ø­Ø¯Ø¯ ÙˆÙ…ÙØµÙ„ Ù„Ù„Ø³Ø¤Ø§Ù„ØŒ Ù…Ø¹ Ø°ÙƒØ± Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©."""
                
            else:
                system_prompt = """You are a legal expert specialized in the International Tent Pegging Federation (ITPF) rules.

## Your task:
1. Analyze the legal question thoroughly and accurately
2. Provide specific and practical answers based on available laws
3. Avoid general answers and focus on the specific scenario
4. Answer in English only with professional organization

## Specific Instructions:
- Use only the available legal references
- Provide practical and specific legal analysis
- Mention relevant article and appendix numbers clearly
- Avoid mixing languages completely
- Pay attention to scoring system and penalties (6 points for carry, 4 for lift, 2 for hit)
- Pay attention to time penalty table (0.5 points per second over limit)

## Required Answer Format:
Use this exact formatting:

### ğŸ” **Organized Legal Analysis:**

#### **1ï¸âƒ£ [First Section Title]:**
**Article [number]: [Article Name]**
- âœ… or âŒ [Analysis]
- ğŸ“Š [Details if applicable]

#### **2ï¸âƒ£ [Second Section Title]:**
**Article [number]: [Article Name]**  
- âš–ï¸ [Legal Application]

### ğŸ¯ **Final Decision:**
- **Ruling:** [Specific Decision]
- **Legal Basis:** Articles [article numbers]"""
                
                user_prompt = f"""Question: {question}

Available Legal References:
{context_text}

Required: Specific and detailed legal analysis of the question, citing relevant legal articles."""
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¥Ù„Ù‰ DeepSeek
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.3,
                "max_tokens": 800
            }
            
            headers = {
                "Authorization": f"Bearer {self.deepseek_api_key}",
                "Content-Type": "application/json"
            }
            
            print(f"ğŸ¤– Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ DeepSeek API...")
            
            response = requests.post(self.deepseek_url, json=payload, headers=headers, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    ai_response = result['choices'][0]['message']['content']
                    print(f"âœ… DeepSeek Ù†Ø¬Ø­: {len(ai_response)} Ø­Ø±Ù")
                    return ai_response
                else:
                    print(f"âŒ Ø§Ø³ØªØ¬Ø§Ø¨Ø© DeepSeek ØºÙŠØ± ØµØ­ÙŠØ­Ø©: {result}")
                    return self._generate_fallback_response(question, legal_context, language)
            else:
                print(f"âŒ Ø®Ø·Ø£ DeepSeek API {response.status_code}: {response.text}")
                return self._generate_fallback_response(question, legal_context, language)
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ DeepSeek: {str(e)}")
            return self._generate_fallback_response(question, legal_context, language)
    
    def _generate_fallback_response(self, question: str, legal_context: List[Dict[str, Any]], language: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¹Ù†Ø¯ ÙØ´Ù„ DeepSeek"""
        if language == 'arabic':
            response = "## Ø§Ù„Ø®Ù„Ø§ØµØ© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©\n\n"
            response += "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…ØªØ§Ø­Ø©:\n\n"
            
            for i, item in enumerate(legal_context[:3], 1):
                if item['type'] == 'article':
                    response += f"**{i}. Ø§Ù„Ù…Ø§Ø¯Ø© {item['article_number']}**: {item['title']}\n"
                    response += f"   {item['content'][:200]}...\n\n"
                else:
                    response += f"**{i}. Ù…Ù„Ø­Ù‚ {item['appendix_number']}**: {item['title']}\n"
                    response += f"   {item['content'][:200]}...\n\n"
            
            return response
        else:
            response = "## Legal Summary\n\n"
            response += "Based on analysis of available laws:\n\n"
            
            for i, item in enumerate(legal_context[:3], 1):
                if item['type'] == 'article':
                    response += f"**{i}. Article {item['article_number']}**: {item['title']}\n"
                    response += f"   {item['content'][:200]}...\n\n"
                else:
                    response += f"**{i}. Appendix {item['appendix_number']}**: {item['title']}\n"
                    response += f"   {item['content'][:200]}...\n\n"
            
            return response

    def process_question(self, question: str, language: str = 'arabic') -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ
        legal_context = self.search_legal_content(question, language)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒÙŠØ©
        ai_response = self.generate_deepseek_response(question, legal_context, language)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        references = []
        for item in legal_context[:6]:
            ref = {
                'type': item['type'],
                'number': item.get('article_number') or item.get('appendix_number'),
                'title': item['title'], 
                'content': item['content'][:300],
                'relevance_score': item['score']
            }
            references.append(ref)
        
        return {
            'success': True,
            'legal_analysis': ai_response,
            'legal_references': references,
            'metadata': {
                'question': question,
                'language': language,
                'references_found': len(legal_context),
                'deepseek_used': bool(self.deepseek_api_key),
                'articles_count': len(self.arabic_data['articles']),
                'appendices_count': len(self.arabic_data['appendices'])
            }
        }

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø«ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ
itpf_system = ITTPFLegalSystem()

from http.server import BaseHTTPRequestHandler
import json

class handler(BaseHTTPRequestHandler):
    """Ù…Ø¹Ø§Ù„Ø¬ Vercel Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªØ·ÙˆØ±"""
    
    def do_OPTIONS(self):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© CORS preflight"""
        self.send_response(200)
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type')
        self.end_headers()
    
    def do_POST(self):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ø§Øª POST"""
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            content_length = int(self.headers.get('Content-Length', 0))
            if content_length > 0:
                post_data = self.rfile.read(content_length)
                data = json.loads(post_data.decode('utf-8'))
            else:
                data = {}
            
            question = data.get('question', '')
            language = data.get('language', 'arabic')
            
            if not question:
                self.send_error_response({'error': 'Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø·Ù„ÙˆØ¨'}, 400)
                return
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªØ·ÙˆØ±
            result = itpf_system.process_question(question, language)
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
            self.send_success_response(result)
            
        except Exception as e:
            self.send_error_response({'error': str(e)}, 500)
    
    def send_success_response(self, data):
        """Ø¥Ø±Ø³Ø§Ù„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù†Ø§Ø¬Ø­Ø©"""
        self.send_response(200)
        self.send_header('Content-Type', 'application/json; charset=utf-8')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Cache-Control', 'no-cache')
        self.end_headers()
        
        response_json = json.dumps(data, ensure_ascii=False, indent=2)
        self.wfile.write(response_json.encode('utf-8'))
    
    def send_error_response(self, error_data, status_code):
        """Ø¥Ø±Ø³Ø§Ù„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø®Ø·Ø£"""
        self.send_response(status_code)
        self.send_header('Content-Type', 'application/json; charset=utf-8')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        
        response_json = json.dumps(error_data, ensure_ascii=False)
        self.wfile.write(response_json.encode('utf-8'))

# Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø­Ù„ÙŠ
if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø­Ù„ÙŠØ§Ù‹
    test_question = "ÙØ±ÙŠÙ‚ Ø­ØµÙ„ Ø¹Ù„Ù‰ 15 Ù†Ù‚Ø·Ø© Ø¬Ø²Ø§Ø¡ØŒ Ù…Ø§ Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØŸ"
    result = itpf_system.process_question(test_question, 'arabic')
    print(json.dumps(result, ensure_ascii=False, indent=2))