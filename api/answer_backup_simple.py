"""
ITPF Legal Answer System - Simplified Smart Version
Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¨Ø³Ø· Ù„Ù„Ø®Ù„Ø§ØµØ© Ø§Ù„Ø°ÙƒÙŠØ© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§Ù…Ù„Ø©
"""

import json
import os
from typing import Dict, Any, List
from http.server import BaseHTTPRequestHandler


def load_legal_data():
    """Load complete legal data - simplified and fast"""
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        
        # Load Arabic data
        arabic_data = {"articles": [], "appendices": []}
        for i in range(1, 4):
            arabic_file = os.path.join(script_dir, f'arabic_data_part{i}.json')
            try:
                with open(arabic_file, 'r', encoding='utf-8') as f:
                    part_data = json.load(f)
                    if i == 1:
                        arabic_data["appendices"] = part_data.get("appendices", [])
                    arabic_data["articles"].extend(part_data.get("articles", []))
            except Exception as e:
                print(f"Error loading Arabic part {i}: {str(e)}")
        
        # Load English data  
        english_data = {"articles": [], "appendices": []}
        for i in range(1, 4):
            english_file = os.path.join(script_dir, f'english_data_part{i}.json')
            try:
                with open(english_file, 'r', encoding='utf-8') as f:
                    part_data = json.load(f)
                    if i == 1:
                        english_data["appendices"] = part_data.get("appendices", [])
                    if 'chapters' in part_data:
                        for chapter in part_data['chapters']:
                            english_data["articles"].extend(chapter.get('articles', []))
                    else:
                        english_data["articles"].extend(part_data.get("articles", []))
            except Exception as e:
                print(f"Error loading English part {i}: {str(e)}")
        
        print(f"Data loaded - Arabic: {len(arabic_data['articles'])} articles, {len(arabic_data['appendices'])} appendices")
        print(f"Data loaded - English: {len(english_data['articles'])} articles, {len(english_data['appendices'])} appendices")
        
        return arabic_data, english_data
    except Exception as e:
        print(f"Error loading legal data: {str(e)}")
        return {}, {}


def simple_search(question: str, data: dict, language: str) -> List[Dict[str, Any]]:
    """Fast simple search without complex processing"""
    results = []
    question_lower = question.lower()
    
    # Search keywords
    search_terms = []
    if 'Ù…Ù„Ø­Ù‚' in question_lower or 'appendix' in question_lower:
        search_terms.extend(['Ù…Ù„Ø­Ù‚', 'appendix'])
        if '9' in question:
            search_terms.extend(['9', 'ØªØ³Ø¹Ø©'])
        if '10' in question:
            search_terms.extend(['10', 'Ø¹Ø´Ø±Ø©'])
    
    # Add question words as search terms
    search_terms.extend(question_lower.split())
    
    # Search in articles
    for article in data.get('articles', []):
        content = article.get('content', '').lower()
        title = article.get('title', '').lower()
        
        score = 0
        for term in search_terms:
            if term in content:
                score += 2
            if term in title:
                score += 3
        
        if score > 0:
            results.append({
                'article_number': article.get('article_number', 0),
                'title': article.get('title', ''),
                'content': article.get('content', ''),
                'relevance_score': score
            })
    
    # Search in appendices
    for appendix in data.get('appendices', []):
        content = str(appendix.get('content', '')).lower()
        title = appendix.get('title', '').lower()
        
        score = 0
        for term in search_terms:
            if term in content:
                score += 3
            if term in title:
                score += 4
        
        if score > 0:
            results.append({
                'article_number': f"Ù…Ù„Ø­Ù‚ {appendix.get('appendix_number', '')}",
                'title': appendix.get('title', ''),
                'content': str(appendix.get('content', ''))[:500] + "...",
                'relevance_score': score
            })
    
    # Sort by relevance and return top 5
    results.sort(key=lambda x: x['relevance_score'], reverse=True)
    return results[:5]


def create_smart_summary(question: str, results: List[Dict[str, Any]]) -> str:
    """Create smart summary without AI dependency"""
    
    if not results:
        return """ðŸ§  **Ø§Ù„Ø®Ù„Ø§ØµØ© Ø§Ù„Ø°ÙƒÙŠØ©:**

Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ù…Ø·Ø§Ø¨Ù‚ Ù„Ø³Ø¤Ø§Ù„Ùƒ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©.

**Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø°ÙƒÙŠ:**
ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ø®ØªÙ„ÙØ© Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„.

**Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©:**
- 55 Ù…Ø§Ø¯Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨Ø§Ù„Ù„ØºØªÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
- Ø§Ù„Ù…Ù„Ø­Ù‚ 9: Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø¨Ø·ÙˆÙ„Ø© Ù„Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø£ÙˆØªØ§Ø¯
- Ø§Ù„Ù…Ù„Ø­Ù‚ 10: Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨Ø·ÙˆÙ„Ø§Øª Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø£ÙˆØªØ§Ø¯ Ù„Ø£ÙƒØ«Ø± Ù…Ù† 10 Ø¯ÙˆÙ„"""
    
    # Get the most relevant result
    main_result = results[0]
    article_num = main_result['article_number']
    title = main_result['title']
    content = main_result['content']
    
    # Extract key sentence from content
    sentences = content.split('.')
    key_sentence = sentences[0].strip() if sentences else content[:200]
    
    # Identify question type
    question_lower = question.lower()
    if 'Ù…Ø§ Ù‡ÙŠ' in question_lower or 'Ù…Ø§ Ù‡Ùˆ' in question_lower:
        question_type = "ØªØ¹Ø±ÙŠÙÙŠ"
    elif 'ÙƒÙŠÙ' in question_lower:
        question_type = "Ø¥Ø¬Ø±Ø§Ø¦ÙŠ"  
    elif 'Ù…ØªÙ‰' in question_lower:
        question_type = "Ø²Ù…Ù†ÙŠ"
    else:
        question_type = "Ø¹Ø§Ù…"
    
    # Build references
    references = []
    for result in results[:3]:
        ref_num = result['article_number']
        ref_content = result['content'][:100] + "..." if len(result['content']) > 100 else result['content']
        references.append(f"â€¢ Ø§Ø³ØªÙ†Ø§Ø¯Ø§Ù‹ Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø±Ù‚Ù… {ref_num}: \"{ref_content}\"")
    
    smart_summary = f"""ðŸ§  **Ø§Ù„Ø®Ù„Ø§ØµØ© Ø§Ù„Ø°ÙƒÙŠØ©:**

{key_sentence}

**Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚:**
Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙÙ‡Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø£ÙˆØªØ§Ø¯ØŒ ÙŠØªØ¶Ø­ Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ù† Ø§Ù„Ù†ÙˆØ¹ {question_type} ÙˆÙŠØªØ¹Ù„Ù‚ Ø¨Ù€{title}. Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù„Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ù„Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø£ÙˆØªØ§Ø¯ Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø£Ø³Ø³ Ø´Ø§Ù…Ù„Ø© ØªØ¶Ù…Ù† Ø§Ù„Ø¹Ø¯Ø§Ù„Ø© ÙˆØ§Ù„ÙˆØ¶ÙˆØ­ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø±ÙŠØ§Ø¶Ø©ØŒ Ø­ÙŠØ« ØªØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ø¹ Ø§Ù„Ù…Ù„Ø§Ø­Ù‚ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© Ù„ØªÙˆÙÙŠØ± Ø¥Ø·Ø§Ø± ØªÙ†Ø¸ÙŠÙ…ÙŠ Ù…Ø­ÙƒÙ… ÙˆÙ…Ø±Ù†.

**Ø§Ù„Ø£Ø³Ø³ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©:**
{chr(10).join(references)}

**Ø§Ù„Ø®Ù„Ø§ØµØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:**
Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙŠØ¸Ù‡Ø± Ø§Ù„ØªØ±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø®ØªÙ„ÙØ©ØŒ Ù…Ù…Ø§ ÙŠØ¹ÙƒØ³ Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø£ÙˆØªØ§Ø¯ Ø§Ù„ØªÙŠ ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø±ÙˆÙ†Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ÙŠØ©ØŒ Ù„Ø¶Ù…Ø§Ù† Ø±ÙŠØ§Ø¶Ø© Ø¹Ø§Ø¯Ù„Ø© ÙˆÙ…Ù†Ø¸Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¯ÙˆÙ„ÙŠ."""
    
    return smart_summary


class handler(BaseHTTPRequestHandler):
    """Simplified Vercel handler for fast performance"""
    
    def _set_cors_headers(self):
        """Set CORS headers"""
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')  
        self.send_header('Access-Control-Allow-Headers', 'Content-Type')
        self.send_header('Content-Type', 'application/json; charset=utf-8')
    
    def _send_json_response(self, status_code: int, data: dict):
        """Send JSON response with cache busting"""
        self.send_response(status_code)
        self._set_cors_headers()
        self.send_header('Cache-Control', 'no-cache, no-store, must-revalidate')
        self.send_header('Pragma', 'no-cache')
        self.send_header('Expires', '0')
        self.send_header('X-Content-Version', '5.0.0')
        self.end_headers()
        json_response = json.dumps(data, ensure_ascii=False).encode('utf-8')
        self.wfile.write(json_response)
    
    def do_OPTIONS(self):
        """Handle CORS preflight requests"""
        self.send_response(200)
        self._set_cors_headers()
        self.end_headers()
    
    def do_GET(self):
        """Handle GET request - API info"""
        api_info = {
            "message": "ITPF Legal Answer System - Smart & Simple",
            "version": "5.0.0",
            "status": "active",
            "system_type": "Smart Summary System",
            "endpoint": "/api/answer",
            "method": "POST",
            "features": [
                "ðŸ§  Ø§Ù„Ø®Ù„Ø§ØµØ© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ù…Ø¨Ø³Ø·Ø©",
                "Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹ ÙˆØ§Ù„Ø¯Ù‚ÙŠÙ‚", 
                "Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙƒØ§Ù…Ù„Ø©",
                "Ø§Ù„Ù…Ù„Ø­Ù‚ÙŠÙ† 9 Ùˆ 10 Ù…ØªØ§Ø­ÙŠÙ†",
                "55 Ù…Ø§Ø¯Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨ÙƒÙ„Ø§ Ø§Ù„Ù„ØºØªÙŠÙ†",
                "Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙÙˆØ±ÙŠØ© Ø¨Ø¯ÙˆÙ† timeout",
                "Ø§Ù„ØªÙÙƒÙŠÙƒ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø£Ø³Ø¦Ù„Ø©",
                "Ø§Ù„Ø§Ø³ØªÙ†Ø§Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù„Ù„Ù†ØµÙˆØµ"
            ],
            "data_integrity": {
                "arabic_articles": "55 + appendices 9,10",
                "english_articles": "55 + appendices 9,10", 
                "text_preservation": "Complete - no truncation",
                "last_verified": "2025-01-10T12:00:00"
            }
        }
        self._send_json_response(200, api_info)
    
    def do_POST(self):
        """Handle POST request - Fast question answering"""
        try:
            # Read request
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length).decode('utf-8')
            
            try:
                data = json.loads(post_data)
            except json.JSONDecodeError:
                self._send_json_response(400, {
                    "success": False,
                    "message": "Invalid JSON in request body"
                })
                return
            
            question = data.get('question', '').strip()
            language = data.get('language', 'arabic')
            
            if not question:
                self._send_json_response(400, {
                    "success": False,
                    "message": "Question is required"
                })
                return
            
            print(f"Processing question: {question}")
            
            # Load data - fast
            arabic_data, english_data = load_legal_data()
            
            if not arabic_data and not english_data:
                self._send_json_response(500, {
                    "success": False,
                    "message": "Legal database unavailable"
                })
                return
            
            # Fast search
            all_results = []
            if language in ['both', 'arabic'] and arabic_data:
                arabic_results = simple_search(question, arabic_data, 'arabic')
                all_results.extend(arabic_results)
                
            if language in ['both', 'english'] and english_data:
                english_results = simple_search(question, english_data, 'english')
                all_results.extend(english_results)
            
            # Sort by relevance
            all_results.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            # Create smart summary
            smart_analysis = create_smart_summary(question, all_results)
            
            # Prepare references for display
            legal_references = []
            for result in all_results[:5]:
                legal_references.append({
                    "title": f"Ø§Ù„Ù…Ø§Ø¯Ø© {result['article_number']}: {result['title']}",
                    "content": result['content'][:300] + "..." if len(result['content']) > 300 else result['content'],
                    "article_number": result['article_number'],
                    "relevance_score": result['relevance_score'],
                    "ai_processed": False
                })
            
            # Response
            api_response = {
                "success": True,
                "legal_analysis": smart_analysis,
                "legal_references": legal_references,
                "metadata": {
                    "question": question,
                    "language": language,
                    "articles_found": len(all_results),
                    "system_type": "Smart Summary System",
                    "ai_powered": False,
                    "text_preservation": "Complete - no truncation",
                    "version": "5.0.0", 
                    "cache_version": "22.0",
                    "timestamp": "2025-01-10T15:00:00",
                    "processing_time": "< 1 second",
                    "data_sources": {
                        "arabic_articles": len(arabic_data.get('articles', [])),
                        "english_articles": len(english_data.get('articles', [])),
                        "arabic_appendices": len(arabic_data.get('appendices', [])),
                        "english_appendices": len(english_data.get('appendices', []))
                    }
                }
            }
            
            self._send_json_response(200, api_response)
            
        except Exception as e:
            import traceback
            print(f"Error processing question: {str(e)}")
            print(f"Full traceback: {traceback.format_exc()}")
            self._send_json_response(500, {
                "success": False,
                "message": f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„: {str(e)}",
                "error_details": str(e),
                "system_type": "Smart Summary System"
            })